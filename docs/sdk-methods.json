{
  "sdk_name": "elevenlabs",
  "introspection_version": "1.0",
  "sync_client": {
    "name": "ElevenLabs",
    "methods_count": 453,
    "methods": [
      {
        "path": "client.audio_isolation.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "preview_b_64",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Removes background noise from audio.\n\nParameters\n----------\naudio : core.File\n    See core.File for more documentation\n\nfile_format : typing.Optional[AudioIsolationConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\npreview_b_64 : typing.Optional[str]\n    Optional preview image base64 for tracking this generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_isolation/client.py",
        "source_line": 31
      },
      {
        "path": "client.audio_isolation.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Removes background noise from audio.\n\nParameters\n----------\naudio : core.File\n    See core.File for more documentation\n\nfile_format : typing.Optional[AudioIsolationStreamRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_isolation/client.py",
        "source_line": 66
      },
      {
        "path": "client.audio_isolation.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "preview_b_64",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Removes background noise from audio.\n\nParameters\n----------\naudio : core.File\n    See core.File for more documentation\n\nfile_format : typing.Optional[AudioIsolationConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\npreview_b_64 : typing.Optional[str]\n    Optional preview image base64 for tracking this generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 26
      },
      {
        "path": "client.audio_isolation.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Removes background noise from audio.\n\nParameters\n----------\naudio : core.File\n    See core.File for more documentation\n\nfile_format : typing.Optional[AudioIsolationStreamRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 100
      },
      {
        "path": "client.audio_native.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "image",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "small",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text_color",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "background_color",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sessionization",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AudioNativeCreateProjectResponseModel",
        "docstring": "Creates Audio Native enabled project, optionally starts conversion and returns project ID and embeddable HTML snippet.\n\nParameters\n----------\nname : str\n    Project name.\n\nimage : typing.Optional[str]\n    (Deprecated) Image URL used in the player. If not provided, default image set in the Player settings is used.\n\nauthor : typing.Optional[str]\n    Author used in the player and inserted at the start of the uploaded article. If not provided, the default author set in the Player settings is used.\n\ntitle : typing.Optional[str]\n    Title used in the player and inserted at the top of the uploaded article. If not provided, the default title set in the Player settings is used.\n\nsmall : typing.Optional[bool]\n    (Deprecated) Whether to use small player or not. If not provided, default value set in the Player settings is used.\n\ntext_color : typing.Optional[str]\n    Text color used in the player. If not provided, default text color set in the Player settings is used.\n\nbackground_color : typing.Optional[str]\n    Background color used in the player. If not provided, default background color set in the Player settings is used.\n\nsessionization : typing.Optional[int]\n    (Deprecated) Specifies for how many minutes to persist the session across page reloads. If not provided, default sessionization set in the Player settings is used.\n\nvoice_id : typing.Optional[str]\n    Voice ID used to voice the content. If not provided, default voice ID set in the Player settings is used.\n\nmodel_id : typing.Optional[str]\n    TTS Model ID used in the player. If not provided, default model ID set in the Player settings is used.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the project to audio or not.\n\napply_text_normalization : typing.Optional[AudioNativeCreateRequestApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\npronunciation_dictionary_locators : typing.Optional[typing.List[str]]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAudioNativeCreateProjectResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.audio_native.create(\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/client.py",
        "source_line": 33
      },
      {
        "path": "client.audio_native.get_settings",
        "name": "get_settings",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAudioNativeProjectSettingsResponseModel",
        "docstring": "Get player settings for the specific project.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAudioNativeProjectSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.audio_native.get_settings(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/client.py",
        "source_line": 142
      },
      {
        "path": "client.audio_native.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_publish",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AudioNativeEditContentResponseModel",
        "docstring": "Updates content for the specific AudioNative Project.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the project to audio or not.\n\nauto_publish : typing.Optional[bool]\n    Whether to auto publish the new project snapshot after it's converted.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAudioNativeEditContentResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.audio_native.update(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/client.py",
        "source_line": 175
      },
      {
        "path": "client.audio_native.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "image",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "small",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text_color",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "background_color",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sessionization",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Creates Audio Native enabled project, optionally starts conversion and returns project ID and embeddable HTML snippet.\n\nParameters\n----------\nname : str\n    Project name.\n\nimage : typing.Optional[str]\n    (Deprecated) Image URL used in the player. If not provided, default image set in the Player settings is used.\n\nauthor : typing.Optional[str]\n    Author used in the player and inserted at the start of the uploaded article. If not provided, the default author set in the Player settings is used.\n\ntitle : typing.Optional[str]\n    Title used in the player and inserted at the top of the uploaded article. If not provided, the default title set in the Player settings is used.\n\nsmall : typing.Optional[bool]\n    (Deprecated) Whether to use small player or not. If not provided, default value set in the Player settings is used.\n\ntext_color : typing.Optional[str]\n    Text color used in the player. If not provided, default text color set in the Player settings is used.\n\nbackground_color : typing.Optional[str]\n    Background color used in the player. If not provided, default background color set in the Player settings is used.\n\nsessionization : typing.Optional[int]\n    (Deprecated) Specifies for how many minutes to persist the session across page reloads. If not provided, default sessionization set in the Player settings is used.\n\nvoice_id : typing.Optional[str]\n    Voice ID used to voice the content. If not provided, default voice ID set in the Player settings is used.\n\nmodel_id : typing.Optional[str]\n    TTS Model ID used in the player. If not provided, default model ID set in the Player settings is used.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the project to audio or not.\n\napply_text_normalization : typing.Optional[AudioNativeCreateRequestApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\npronunciation_dictionary_locators : typing.Optional[typing.List[str]]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AudioNativeCreateProjectResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/raw_client.py",
        "source_line": 28
      },
      {
        "path": "client.audio_native.with_raw_response.get_settings",
        "name": "get_settings",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get player settings for the specific project.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetAudioNativeProjectSettingsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/raw_client.py",
        "source_line": 158
      },
      {
        "path": "client.audio_native.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_publish",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Updates content for the specific AudioNative Project.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the project to audio or not.\n\nauto_publish : typing.Optional[bool]\n    Whether to auto publish the new project snapshot after it's converted.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AudioNativeEditContentResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/raw_client.py",
        "source_line": 208
      },
      {
        "path": "client.conversational_ai.add_to_knowledge_base",
        "name": "add_to_knowledge_base",
        "parameters": [
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddKnowledgeBaseResponseModel",
        "docstring": "Upload a file or webpage URL to create a knowledge base document. <br> <Note> After creating the document, update the agent's knowledge base by calling [Update agent](/docs/api-reference/agents/update). </Note>\n\nParameters\n----------\nagent_id : typing.Optional[str]\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nurl : typing.Optional[str]\n    URL to a page of documentation that the agent will have access to in order to interact with users.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddKnowledgeBaseResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.add_to_knowledge_base(\n    agent_id=\"agent_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/client.py",
        "source_line": 67
      },
      {
        "path": "client.conversational_ai.agents.create",
        "name": "create",
        "parameters": [
          {
            "name": "conversation_config",
            "type": "ConversationalConfig",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "platform_settings",
            "type": "Optional[AgentPlatformSettingsRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workflow",
            "type": "Optional[AgentWorkflowRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tags",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreateAgentResponseModel",
        "docstring": "Create an agent from a config object\n\nParameters\n----------\nconversation_config : ConversationalConfig\n    Conversation configuration for an agent\n\nplatform_settings : typing.Optional[AgentPlatformSettingsRequestModel]\n    Platform settings for the agent are all settings that aren't related to the conversation orchestration and content.\n\nworkflow : typing.Optional[AgentWorkflowRequestModel]\n    Workflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\ntags : typing.Optional[typing.Sequence[str]]\n    Tags to help classify and filter the agent\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreateAgentResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ConversationalConfig, ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.create(\n    conversation_config=ConversationalConfig(),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 54
      },
      {
        "path": "client.conversational_ai.agents.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "None",
        "docstring": "Delete an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.delete(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 144
      },
      {
        "path": "client.conversational_ai.agents.duplicate",
        "name": "duplicate",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreateAgentResponseModel",
        "docstring": "Create a new agent by duplicating an existing one\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreateAgentResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.duplicate(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 307
      },
      {
        "path": "client.conversational_ai.agents.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentResponseModel",
        "docstring": "Retrieve config for an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.get(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 113
      },
      {
        "path": "client.conversational_ai.agents.knowledge_base.size",
        "name": "size",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentKnowledgebaseSizeResponseModel",
        "docstring": "Returns the number of pages in the agent's knowledge base.\n\nParameters\n----------\nagent_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentKnowledgebaseSizeResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.knowledge_base.size(\n    agent_id=\"agent_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/knowledge_base/client.py",
        "source_line": 26
      },
      {
        "path": "client.conversational_ai.agents.knowledge_base.with_raw_response.size",
        "name": "size",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns the number of pages in the agent's knowledge base.\n\nParameters\n----------\nagent_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetAgentKnowledgebaseSizeResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/knowledge_base/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.conversational_ai.agents.link.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentLinkResponseModel",
        "docstring": "Get the current link used to share the agent with others\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentLinkResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.link.get(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/link/client.py",
        "source_line": 26
      },
      {
        "path": "client.conversational_ai.agents.link.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get the current link used to share the agent with others\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetAgentLinkResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/link/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.conversational_ai.agents.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "archived",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[SortDirection]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_by",
            "type": "Optional[AgentSortBy]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentsPageResponseModel",
        "docstring": "Returns a list of your agents and their metadata.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many Agents to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    Search by agents name.\n\narchived : typing.Optional[bool]\n    Filter agents by archived status\n\nsort_direction : typing.Optional[SortDirection]\n    The direction to sort the results\n\nsort_by : typing.Optional[AgentSortBy]\n    The field to sort the results by\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentsPageResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.list(\n    page_size=1,\n    search=\"search\",\n    archived=True,\n    sort_direction=\"asc\",\n    sort_by=\"name\",\n    cursor=\"cursor\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 238
      },
      {
        "path": "client.conversational_ai.agents.llm_usage.calculate",
        "name": "calculate",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "prompt_length",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "number_of_pages",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_enabled",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "LlmUsageCalculatorResponseModel",
        "docstring": "Calculates expected number of LLM tokens needed for the specified agent.\n\nParameters\n----------\nagent_id : str\n\nprompt_length : typing.Optional[int]\n    Length of the prompt in characters.\n\nnumber_of_pages : typing.Optional[int]\n    Pages of content in pdf documents OR urls in agent's Knowledge Base.\n\nrag_enabled : typing.Optional[bool]\n    Whether RAG is enabled.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nLlmUsageCalculatorResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.llm_usage.calculate(\n    agent_id=\"agent_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/llm_usage/client.py",
        "source_line": 29
      },
      {
        "path": "client.conversational_ai.agents.llm_usage.with_raw_response.calculate",
        "name": "calculate",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "prompt_length",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "number_of_pages",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_enabled",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Calculates expected number of LLM tokens needed for the specified agent.\n\nParameters\n----------\nagent_id : str\n\nprompt_length : typing.Optional[int]\n    Length of the prompt in characters.\n\nnumber_of_pages : typing.Optional[int]\n    Pages of content in pdf documents OR urls in agent's Knowledge Base.\n\nrag_enabled : typing.Optional[bool]\n    Whether RAG is enabled.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[LlmUsageCalculatorResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/llm_usage/raw_client.py",
        "source_line": 24
      },
      {
        "path": "client.conversational_ai.agents.run_tests",
        "name": "run_tests",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tests",
            "type": "Sequence[SingleTestRunRequestModel]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_config_override",
            "type": "Optional[AdhocAgentConfigOverrideForTestRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "branch_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestSuiteInvocationResponseModel",
        "docstring": "Run selected tests on the agent with provided configuration. If the agent configuration is provided, it will be used to override default agent configuration.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\ntests : typing.Sequence[SingleTestRunRequestModel]\n    List of tests to run on the agent\n\nagent_config_override : typing.Optional[AdhocAgentConfigOverrideForTestRequestModel]\n    Configuration overrides to use for testing. If not provided, the agent's default configuration will be used.\n\nbranch_id : typing.Optional[str]\n    ID of the branch to run the tests on. If not provided, the tests will be run on the agent default configuration.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestSuiteInvocationResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs, SingleTestRunRequestModel\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.run_tests(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    tests=[\n        SingleTestRunRequestModel(\n            test_id=\"test_id\",\n        )\n    ],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 476
      },
      {
        "path": "client.conversational_ai.agents.simulate_conversation",
        "name": "simulate_conversation",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "simulation_specification",
            "type": "ConversationSimulationSpecification",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_evaluation_criteria",
            "type": "Optional[Sequence[PromptEvaluationCriteria]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "new_turns_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AgentSimulatedChatTestResponseModel",
        "docstring": "Run a conversation between the agent and a simulated user.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nsimulation_specification : ConversationSimulationSpecification\n    A specification detailing how the conversation should be simulated\n\nextra_evaluation_criteria : typing.Optional[typing.Sequence[PromptEvaluationCriteria]]\n    A list of evaluation criteria to test\n\nnew_turns_limit : typing.Optional[int]\n    Maximum number of new turns to generate in the conversation simulation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAgentSimulatedChatTestResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import (\n    AgentConfig,\n    ConversationSimulationSpecification,\n    ElevenLabs,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.simulate_conversation(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    simulation_specification=ConversationSimulationSpecification(\n        simulated_user_config=AgentConfig(\n            first_message=\"Hello, how can I help you today?\",\n            language=\"en\",\n            disable_first_message_interruptions=False,\n        ),\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 347
      },
      {
        "path": "client.conversational_ai.agents.simulate_conversation_stream",
        "name": "simulate_conversation_stream",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "simulation_specification",
            "type": "ConversationSimulationSpecification",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_evaluation_criteria",
            "type": "Optional[Sequence[PromptEvaluationCriteria]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "new_turns_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "None",
        "docstring": "Run a conversation between the agent and a simulated user and stream back the response. Response is streamed back as partial lists of messages that should be concatenated and once the conversation has complete a single final message with the conversation analysis will be sent.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nsimulation_specification : ConversationSimulationSpecification\n    A specification detailing how the conversation should be simulated\n\nextra_evaluation_criteria : typing.Optional[typing.Sequence[PromptEvaluationCriteria]]\n    A list of evaluation criteria to test\n\nnew_turns_limit : typing.Optional[int]\n    Maximum number of new turns to generate in the conversation simulation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nfrom elevenlabs import (\n    AgentConfig,\n    ConversationSimulationSpecification,\n    ElevenLabs,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.simulate_conversation_stream(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    simulation_specification=ConversationSimulationSpecification(\n        simulated_user_config=AgentConfig(\n            first_message=\"Hello, how can I help you today?\",\n            language=\"en\",\n            disable_first_message_interruptions=False,\n        ),\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 412
      },
      {
        "path": "client.conversational_ai.agents.update",
        "name": "update",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "conversation_config",
            "type": "Optional[ConversationalConfig]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "platform_settings",
            "type": "Optional[AgentPlatformSettingsRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workflow",
            "type": "Optional[AgentWorkflowRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tags",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentResponseModel",
        "docstring": "Patches an Agent settings\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nconversation_config : typing.Optional[ConversationalConfig]\n    Conversation configuration for an agent\n\nplatform_settings : typing.Optional[AgentPlatformSettingsRequestModel]\n    Platform settings for the agent are all settings that aren't related to the conversation orchestration and content.\n\nworkflow : typing.Optional[AgentWorkflowRequestModel]\n    Workflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\ntags : typing.Optional[typing.Sequence[str]]\n    Tags to help classify and filter the agent\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.update(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 174
      },
      {
        "path": "client.conversational_ai.agents.widget.avatar.create",
        "name": "create",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "avatar_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PostAgentAvatarResponseModel",
        "docstring": "Sets the avatar for an agent displayed in the widget\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\navatar_file : core.File\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPostAgentAvatarResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.widget.avatar.create(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/widget/avatar/client.py",
        "source_line": 30
      },
      {
        "path": "client.conversational_ai.agents.widget.avatar.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "avatar_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Sets the avatar for an agent displayed in the widget\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\navatar_file : core.File\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PostAgentAvatarResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/widget/avatar/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.conversational_ai.agents.widget.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "conversation_signature",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentEmbedResponseModel",
        "docstring": "Retrieve the widget configuration for an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nconversation_signature : typing.Optional[str]\n    An expiring token that enables a websocket conversation to start. These can be generated for an agent using the /v1/convai/conversation/get-signed-url endpoint\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentEmbedResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.agents.widget.get(\n    agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    conversation_signature=\"conversation_signature\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/widget/client.py",
        "source_line": 33
      },
      {
        "path": "client.conversational_ai.agents.widget.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "conversation_signature",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve the widget configuration for an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nconversation_signature : typing.Optional[str]\n    An expiring token that enables a websocket conversation to start. These can be generated for an agent using the /v1/convai/conversation/get-signed-url endpoint\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetAgentEmbedResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/widget/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "conversation_config",
            "type": "ConversationalConfig",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "platform_settings",
            "type": "Optional[AgentPlatformSettingsRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workflow",
            "type": "Optional[AgentWorkflowRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tags",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create an agent from a config object\n\nParameters\n----------\nconversation_config : ConversationalConfig\n    Conversation configuration for an agent\n\nplatform_settings : typing.Optional[AgentPlatformSettingsRequestModel]\n    Platform settings for the agent are all settings that aren't related to the conversation orchestration and content.\n\nworkflow : typing.Optional[AgentWorkflowRequestModel]\n    Workflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\ntags : typing.Optional[typing.Sequence[str]]\n    Tags to help classify and filter the agent\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[CreateAgentResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 38
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[None]",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 174
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.duplicate",
        "name": "duplicate",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a new agent by duplicating an existing one\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[CreateAgentResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 385
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve config for an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetAgentResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 124
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "archived",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_by",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns a list of your agents and their metadata.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many Agents to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    Search by agents name.\n\narchived : typing.Optional[bool]\n    Filter agents by archived status\n\nsort_direction : typing.Optional[SortDirection]\n    The direction to sort the results\n\nsort_by : typing.Optional[AgentSortBy]\n    The field to sort the results by\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetAgentsPageResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 304
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.run_tests",
        "name": "run_tests",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tests",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_config_override",
            "type": "Optional[AdhocAgentConfigOverrideForTestRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "branch_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Run selected tests on the agent with provided configuration. If the agent configuration is provided, it will be used to override default agent configuration.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\ntests : typing.Sequence[SingleTestRunRequestModel]\n    List of tests to run on the agent\n\nagent_config_override : typing.Optional[AdhocAgentConfigOverrideForTestRequestModel]\n    Configuration overrides to use for testing. If not provided, the agent's default configuration will be used.\n\nbranch_id : typing.Optional[str]\n    ID of the branch to run the tests on. If not provided, the tests will be run on the agent default configuration.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetTestSuiteInvocationResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 601
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.simulate_conversation",
        "name": "simulate_conversation",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "simulation_specification",
            "type": "ConversationSimulationSpecification",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_evaluation_criteria",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "new_turns_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Run a conversation between the agent and a simulated user.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nsimulation_specification : ConversationSimulationSpecification\n    A specification detailing how the conversation should be simulated\n\nextra_evaluation_criteria : typing.Optional[typing.Sequence[PromptEvaluationCriteria]]\n    A list of evaluation criteria to test\n\nnew_turns_limit : typing.Optional[int]\n    Maximum number of new turns to generate in the conversation simulation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AgentSimulatedChatTestResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 449
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.simulate_conversation_stream",
        "name": "simulate_conversation_stream",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "simulation_specification",
            "type": "ConversationSimulationSpecification",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_evaluation_criteria",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "new_turns_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Run a conversation between the agent and a simulated user and stream back the response. Response is streamed back as partial lists of messages that should be concatenated and once the conversation has complete a single final message with the conversation analysis will be sent.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nsimulation_specification : ConversationSimulationSpecification\n    A specification detailing how the conversation should be simulated\n\nextra_evaluation_criteria : typing.Optional[typing.Sequence[PromptEvaluationCriteria]]\n    A list of evaluation criteria to test\n\nnew_turns_limit : typing.Optional[int]\n    Maximum number of new turns to generate in the conversation simulation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[None]",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 529
      },
      {
        "path": "client.conversational_ai.agents.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "conversation_config",
            "type": "Optional[ConversationalConfig]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "platform_settings",
            "type": "Optional[AgentPlatformSettingsRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workflow",
            "type": "Optional[AgentWorkflowRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tags",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Patches an Agent settings\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nconversation_config : typing.Optional[ConversationalConfig]\n    Conversation configuration for an agent\n\nplatform_settings : typing.Optional[AgentPlatformSettingsRequestModel]\n    Platform settings for the agent are all settings that aren't related to the conversation orchestration and content.\n\nworkflow : typing.Optional[AgentWorkflowRequestModel]\n    Workflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\ntags : typing.Optional[typing.Sequence[str]]\n    Tags to help classify and filter the agent\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetAgentResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 214
      },
      {
        "path": "client.conversational_ai.analytics.live_count.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetLiveCountResponse",
        "docstring": "Get the live count of the ongoing conversations.\n\nParameters\n----------\nagent_id : typing.Optional[str]\n    The id of an agent to restrict the analytics to.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetLiveCountResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.analytics.live_count.get(\n    agent_id=\"agent_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/analytics/live_count/client.py",
        "source_line": 26
      },
      {
        "path": "client.conversational_ai.analytics.live_count.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get the live count of the ongoing conversations.\n\nParameters\n----------\nagent_id : typing.Optional[str]\n    The id of an agent to restrict the analytics to.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetLiveCountResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/analytics/live_count/raw_client.py",
        "source_line": 20
      },
      {
        "path": "client.conversational_ai.batch_calls.cancel",
        "name": "cancel",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "BatchCallResponse",
        "docstring": "Cancel a running batch call and set all recipients to cancelled status.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nBatchCallResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.batch_calls.cancel(\n    batch_id=\"batch_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 159
      },
      {
        "path": "client.conversational_ai.batch_calls.create",
        "name": "create",
        "parameters": [
          {
            "name": "call_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "recipients",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "scheduled_time_unix",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "BatchCallResponse",
        "docstring": "Submit a batch call request to schedule calls for multiple recipients.\n\nParameters\n----------\ncall_name : str\n\nagent_id : str\n\nrecipients : typing.Sequence[OutboundCallRecipient]\n\nscheduled_time_unix : typing.Optional[int]\n\nagent_phone_number_id : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nBatchCallResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs, OutboundCallRecipient\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.batch_calls.create(\n    call_name=\"call_name\",\n    agent_id=\"agent_id\",\n    recipients=[OutboundCallRecipient()],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 32
      },
      {
        "path": "client.conversational_ai.batch_calls.get",
        "name": "get",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "BatchCallDetailedResponse",
        "docstring": "Get detailed information about a batch call including all recipients.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nBatchCallDetailedResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.batch_calls.get(\n    batch_id=\"batch_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 127
      },
      {
        "path": "client.conversational_ai.batch_calls.list",
        "name": "list",
        "parameters": [
          {
            "name": "limit",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "last_doc",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceBatchCallsResponse",
        "docstring": "Get all batch calls for the current workspace.\n\nParameters\n----------\nlimit : typing.Optional[int]\n\nlast_doc : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceBatchCallsResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.batch_calls.list(\n    limit=1,\n    last_doc=\"last_doc\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 88
      },
      {
        "path": "client.conversational_ai.batch_calls.retry",
        "name": "retry",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "BatchCallResponse",
        "docstring": "Retry a batch call, calling failed and no-response recipients again.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nBatchCallResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.batch_calls.retry(\n    batch_id=\"batch_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 189
      },
      {
        "path": "client.conversational_ai.batch_calls.with_raw_response.cancel",
        "name": "cancel",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Cancel a running batch call and set all recipients to cancelled status.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[BatchCallResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 213
      },
      {
        "path": "client.conversational_ai.batch_calls.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "call_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "recipients",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "scheduled_time_unix",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Submit a batch call request to schedule calls for multiple recipients.\n\nParameters\n----------\ncall_name : str\n\nagent_id : str\n\nrecipients : typing.Sequence[OutboundCallRecipient]\n\nscheduled_time_unix : typing.Optional[int]\n\nagent_phone_number_id : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[BatchCallResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 28
      },
      {
        "path": "client.conversational_ai.batch_calls.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get detailed information about a batch call including all recipients.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[BatchCallDetailedResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 164
      },
      {
        "path": "client.conversational_ai.batch_calls.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "limit",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "last_doc",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get all batch calls for the current workspace.\n\nParameters\n----------\nlimit : typing.Optional[int]\n\nlast_doc : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[WorkspaceBatchCallsResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 105
      },
      {
        "path": "client.conversational_ai.batch_calls.with_raw_response.retry",
        "name": "retry",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retry a batch call, calling failed and no-response recipients again.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[BatchCallResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 262
      },
      {
        "path": "client.conversational_ai.conversations.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Get the audio recording of a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.conversations.audio.get(\n    conversation_id=\"conversation_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/audio/client.py",
        "source_line": 25
      },
      {
        "path": "client.conversational_ai.conversations.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Get the audio recording of a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 21
      },
      {
        "path": "client.conversational_ai.conversations.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.conversations.delete(\n    conversation_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 291
      },
      {
        "path": "client.conversational_ai.conversations.feedback.create",
        "name": "create",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "feedback",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Send the feedback for the given conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nfeedback : typing.Optional[UserFeedbackScore]\n    Either 'like' or 'dislike' to indicate the feedback for the conversation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.conversations.feedback.create(\n    conversation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    feedback=\"like\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/feedback/client.py",
        "source_line": 29
      },
      {
        "path": "client.conversational_ai.conversations.feedback.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "feedback",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Send the feedback for the given conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nfeedback : typing.Optional[UserFeedbackScore]\n    Either 'like' or 'dislike' to indicate the feedback for the conversation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/feedback/raw_client.py",
        "source_line": 24
      },
      {
        "path": "client.conversational_ai.conversations.get",
        "name": "get",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConversationResponseModel",
        "docstring": "Get the details of a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConversationResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.conversations.get(\n    conversation_id=\"123\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 258
      },
      {
        "path": "client.conversational_ai.conversations.get_signed_url",
        "name": "get_signed_url",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_conversation_id",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ConversationSignedUrlResponseModel",
        "docstring": "Get a signed url to start a conversation with an agent with an agent that requires authorization\n\nParameters\n----------\nagent_id : str\n    The id of the agent you're taking the action on.\n\ninclude_conversation_id : typing.Optional[bool]\n    Whether to include a conversation_id with the response. If included, the conversation_signature cannot be used again.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nConversationSignedUrlResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.conversations.get_signed_url(\n    agent_id=\"21m00Tcm4TlvDq8ikWAM\",\n    include_conversation_id=True,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 40
      },
      {
        "path": "client.conversational_ai.conversations.get_webrtc_token",
        "name": "get_webrtc_token",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "participant_name",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "TokenResponseModel",
        "docstring": "Get a WebRTC session token for real-time communication.\n\nParameters\n----------\nagent_id : str\n    The id of the agent you're taking the action on.\n\nparticipant_name : typing.Optional[str]\n    Optional custom participant name. If not provided, user ID will be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nTokenResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.conversations.get_webrtc_token(\n    agent_id=\"21m00Tcm4TlvDq8ikWAM\",\n    participant_name=\"participant_name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 83
      },
      {
        "path": "client.conversational_ai.conversations.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_successful",
            "type": "Optional[EvaluationSuccessResult]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_start_before_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_start_after_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_duration_min_secs",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_duration_max_secs",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rating_max",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rating_min",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "has_feedback_comment",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "evaluation_params",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "data_collection_params",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_names",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "summary_mode",
            "type": "Optional[ConversationsListRequestSummaryMode]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConversationsPageResponseModel",
        "docstring": "Get all conversations of agents that user owns. With option to restrict to a specific agent.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nagent_id : typing.Optional[str]\n    The id of the agent you're taking the action on.\n\ncall_successful : typing.Optional[EvaluationSuccessResult]\n    The result of the success evaluation\n\ncall_start_before_unix : typing.Optional[int]\n    Unix timestamp (in seconds) to filter conversations up to this start date.\n\ncall_start_after_unix : typing.Optional[int]\n    Unix timestamp (in seconds) to filter conversations after to this start date.\n\ncall_duration_min_secs : typing.Optional[int]\n    Minimum call duration in seconds.\n\ncall_duration_max_secs : typing.Optional[int]\n    Maximum call duration in seconds.\n\nrating_max : typing.Optional[int]\n    Maximum overall rating (1-5).\n\nrating_min : typing.Optional[int]\n    Minimum overall rating (1-5).\n\nhas_feedback_comment : typing.Optional[bool]\n    Filter conversations with user feedback comments.\n\nuser_id : typing.Optional[str]\n    Filter conversations by the user ID who initiated them.\n\nevaluation_params : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Evaluation filters. Repeat param. Format: criteria_id:result. Example: eval=value_framing:success\n\ndata_collection_params : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Data collection filters. Repeat param. Format: id:op:value where op is one of eq|neq|gt|gte|lt|lte|in|exists|missing. For in, pipe-delimit values.\n\ntool_names : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Filter conversations by tool names used during the call.\n\npage_size : typing.Optional[int]\n    How many conversations to return at maximum. Can not exceed 100, defaults to 30.\n\nsummary_mode : typing.Optional[ConversationsListRequestSummaryMode]\n    Whether to include transcript summaries in the response.\n\nsearch : typing.Optional[str]\n    Full-text or fuzzy search over transcript messages\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConversationsPageResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.conversations.list(\n    cursor=\"cursor\",\n    agent_id=\"agent_id\",\n    call_successful=\"success\",\n    call_start_before_unix=1,\n    call_start_after_unix=1,\n    call_duration_min_secs=1,\n    call_duration_max_secs=1,\n    rating_max=1,\n    rating_min=1,\n    has_feedback_comment=True,\n    user_id=\"user_id\",\n    page_size=1,\n    summary_mode=\"exclude\",\n    search=\"search\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 126
      },
      {
        "path": "client.conversational_ai.conversations.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 334
      },
      {
        "path": "client.conversational_ai.conversations.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get the details of a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetConversationResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 284
      },
      {
        "path": "client.conversational_ai.conversations.with_raw_response.get_signed_url",
        "name": "get_signed_url",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_conversation_id",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get a signed url to start a conversation with an agent with an agent that requires authorization\n\nParameters\n----------\nagent_id : str\n    The id of the agent you're taking the action on.\n\ninclude_conversation_id : typing.Optional[bool]\n    Whether to include a conversation_id with the response. If included, the conversation_signature cannot be used again.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ConversationSignedUrlResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 26
      },
      {
        "path": "client.conversational_ai.conversations.with_raw_response.get_webrtc_token",
        "name": "get_webrtc_token",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "participant_name",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get a WebRTC session token for real-time communication.\n\nParameters\n----------\nagent_id : str\n    The id of the agent you're taking the action on.\n\nparticipant_name : typing.Optional[str]\n    Optional custom participant name. If not provided, user ID will be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[TokenResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 87
      },
      {
        "path": "client.conversational_ai.conversations.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_successful",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_start_before_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_start_after_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_duration_min_secs",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_duration_max_secs",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rating_max",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rating_min",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "has_feedback_comment",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "evaluation_params",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "data_collection_params",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_names",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "summary_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get all conversations of agents that user owns. With option to restrict to a specific agent.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nagent_id : typing.Optional[str]\n    The id of the agent you're taking the action on.\n\ncall_successful : typing.Optional[EvaluationSuccessResult]\n    The result of the success evaluation\n\ncall_start_before_unix : typing.Optional[int]\n    Unix timestamp (in seconds) to filter conversations up to this start date.\n\ncall_start_after_unix : typing.Optional[int]\n    Unix timestamp (in seconds) to filter conversations after to this start date.\n\ncall_duration_min_secs : typing.Optional[int]\n    Minimum call duration in seconds.\n\ncall_duration_max_secs : typing.Optional[int]\n    Maximum call duration in seconds.\n\nrating_max : typing.Optional[int]\n    Maximum overall rating (1-5).\n\nrating_min : typing.Optional[int]\n    Minimum overall rating (1-5).\n\nhas_feedback_comment : typing.Optional[bool]\n    Filter conversations with user feedback comments.\n\nuser_id : typing.Optional[str]\n    Filter conversations by the user ID who initiated them.\n\nevaluation_params : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Evaluation filters. Repeat param. Format: criteria_id:result. Example: eval=value_framing:success\n\ndata_collection_params : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Data collection filters. Repeat param. Format: id:op:value where op is one of eq|neq|gt|gte|lt|lte|in|exists|missing. For in, pipe-delimit values.\n\ntool_names : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Filter conversations by tool names used during the call.\n\npage_size : typing.Optional[int]\n    How many conversations to return at maximum. Can not exceed 100, defaults to 30.\n\nsummary_mode : typing.Optional[ConversationsListRequestSummaryMode]\n    Whether to include transcript summaries in the response.\n\nsearch : typing.Optional[str]\n    Full-text or fuzzy search over transcript messages\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetConversationsPageResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 148
      },
      {
        "path": "client.conversational_ai.dashboard.settings.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConvAiDashboardSettingsResponseModel",
        "docstring": "Retrieve Convai dashboard settings for the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConvAiDashboardSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.dashboard.settings.get()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/dashboard/settings/client.py",
        "source_line": 30
      },
      {
        "path": "client.conversational_ai.dashboard.settings.update",
        "name": "update",
        "parameters": [
          {
            "name": "charts",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConvAiDashboardSettingsResponseModel",
        "docstring": "Update Convai dashboard settings for the workspace\n\nParameters\n----------\ncharts : typing.Optional[typing.Sequence[PatchConvAiDashboardSettingsRequestChartsItem]]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConvAiDashboardSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.dashboard.settings.update()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/dashboard/settings/client.py",
        "source_line": 58
      },
      {
        "path": "client.conversational_ai.dashboard.settings.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve Convai dashboard settings for the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetConvAiDashboardSettingsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/dashboard/settings/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.conversational_ai.dashboard.settings.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "charts",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update Convai dashboard settings for the workspace\n\nParameters\n----------\ncharts : typing.Optional[typing.Sequence[PatchConvAiDashboardSettingsRequestChartsItem]]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetConvAiDashboardSettingsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/dashboard/settings/raw_client.py",
        "source_line": 72
      },
      {
        "path": "client.conversational_ai.delete_document_rag_index",
        "name": "delete_document_rag_index",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rag_index_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RagDocumentIndexResponseModel",
        "docstring": "Delete RAG index for the knowledgebase document.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrag_index_id : str\n    The id of RAG index of document from the knowledge base.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRagDocumentIndexResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.delete_document_rag_index(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    rag_index_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/client.py",
        "source_line": 177
      },
      {
        "path": "client.conversational_ai.get_document_rag_indexes",
        "name": "get_document_rag_indexes",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RagDocumentIndexesResponseModel",
        "docstring": "Provides information about all RAG indexes of the specified knowledgebase document.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRagDocumentIndexesResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.get_document_rag_indexes(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/client.py",
        "source_line": 144
      },
      {
        "path": "client.conversational_ai.knowledge_base.document.compute_rag_index",
        "name": "compute_rag_index",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "model",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RagDocumentIndexResponseModel",
        "docstring": "In case the document is not RAG indexed, it triggers rag indexing task, otherwise it just returns the current status.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nmodel : EmbeddingModelEnum\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRagDocumentIndexResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.document.compute_rag_index(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    model=\"e5_mistral_7b_instruct\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/document/client.py",
        "source_line": 30
      },
      {
        "path": "client.conversational_ai.knowledge_base.document.with_raw_response.compute_rag_index",
        "name": "compute_rag_index",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "model",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "In case the document is not RAG indexed, it triggers rag indexing task, otherwise it just returns the current status.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nmodel : EmbeddingModelEnum\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[RagDocumentIndexResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/document/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.chunk.get",
        "name": "get",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chunk_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "KnowledgeBaseDocumentChunkResponseModel",
        "docstring": "Get details about a specific documentation part used by RAG.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nchunk_id : str\n    The id of a document RAG chunk from the knowledge base.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nKnowledgeBaseDocumentChunkResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.chunk.get(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    chunk_id=\"chunk_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/chunk/client.py",
        "source_line": 26
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.chunk.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chunk_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get details about a specific documentation part used by RAG.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nchunk_id : str\n    The id of a document RAG chunk from the knowledge base.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[KnowledgeBaseDocumentChunkResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/chunk/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.create_from_file",
        "name": "create_from_file",
        "parameters": [
          {
            "name": "file",
            "type": "core.File",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddKnowledgeBaseResponseModel",
        "docstring": "Create a knowledge base document generated form the uploaded file.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddKnowledgeBaseResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.create_from_file()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 87
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.create_from_text",
        "name": "create_from_text",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddKnowledgeBaseResponseModel",
        "docstring": "Create a knowledge base document containing the provided text.\n\nParameters\n----------\ntext : str\n    Text content to be added to the knowledge base.\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddKnowledgeBaseResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.create_from_text(\n    text=\"text\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 131
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.create_from_url",
        "name": "create_from_url",
        "parameters": [
          {
            "name": "url",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddKnowledgeBaseResponseModel",
        "docstring": "Create a knowledge base document generated by scraping the given webpage.\n\nParameters\n----------\nurl : str\n    URL to a page of documentation that the agent will have access to in order to interact with users.\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddKnowledgeBaseResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.create_from_url(\n    url=\"url\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 41
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "force",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a document from the knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nforce : typing.Optional[bool]\n    If set to true, the document will be deleted regardless of whether it is used by any agents and it will be deleted from the dependent agents.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.delete(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    force=True,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 217
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.get",
        "name": "get",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DocumentsGetResponse",
        "docstring": "Get details about a specific documentation making up the agent's knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nagent_id : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDocumentsGetResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.get(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    agent_id=\"agent_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 177
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.get_agents",
        "name": "get_agents",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetKnowledgeBaseDependentAgentsResponseModel",
        "docstring": "Get a list of agents depending on this knowledge base document\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetKnowledgeBaseDependentAgentsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.get_agents(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    cursor=\"cursor\",\n    page_size=1,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 295
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.get_content",
        "name": "get_content",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "None",
        "docstring": "Get the entire content of a document from the knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.get_content(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 343
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.summaries.get",
        "name": "get",
        "parameters": [
          {
            "name": "document_ids",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Dict[str, Annotated]",
        "docstring": "Gets multiple knowledge base document summaries by their IDs.\n\nParameters\n----------\ndocument_ids : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    The ids of knowledge base documents.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Dict[str, SummariesGetResponseValue]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.summaries.get()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/summaries/client.py",
        "source_line": 26
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.summaries.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "document_ids",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets multiple knowledge base document summaries by their IDs.\n\nParameters\n----------\ndocument_ids : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    The ids of knowledge base documents.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Dict[str, SummariesGetResponseValue]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/summaries/raw_client.py",
        "source_line": 20
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.update",
        "name": "update",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DocumentsUpdateResponse",
        "docstring": "Update the name of a document\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nname : str\n    A custom, human-readable name for the document.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDocumentsUpdateResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.documents.update(\n    documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 258
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.with_raw_response.create_from_file",
        "name": "create_from_file",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a knowledge base document generated form the uploaded file.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddKnowledgeBaseResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 98
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.with_raw_response.create_from_text",
        "name": "create_from_text",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a knowledge base document containing the provided text.\n\nParameters\n----------\ntext : str\n    Text content to be added to the knowledge base.\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddKnowledgeBaseResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 168
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.with_raw_response.create_from_url",
        "name": "create_from_url",
        "parameters": [
          {
            "name": "url",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a knowledge base document generated by scraping the given webpage.\n\nParameters\n----------\nurl : str\n    URL to a page of documentation that the agent will have access to in order to interact with users.\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddKnowledgeBaseResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 28
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "force",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete a document from the knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nforce : typing.Optional[bool]\n    If set to true, the document will be deleted regardless of whether it is used by any agents and it will be deleted from the dependent agents.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 297
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get details about a specific documentation making up the agent's knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nagent_id : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DocumentsGetResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 238
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.with_raw_response.get_agents",
        "name": "get_agents",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get a list of agents depending on this knowledge base document\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetKnowledgeBaseDependentAgentsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 419
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.with_raw_response.get_content",
        "name": "get_content",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get the entire content of a document from the knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[None]",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 484
      },
      {
        "path": "client.conversational_ai.knowledge_base.documents.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update the name of a document\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nname : str\n    A custom, human-readable name for the document.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DocumentsUpdateResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 359
      },
      {
        "path": "client.conversational_ai.knowledge_base.get_or_create_rag_indexes",
        "name": "get_or_create_rag_indexes",
        "parameters": [
          {
            "name": "items",
            "type": "Sequence[GetOrCreateRagIndexRequestModel]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Dict[str, KnowledgeBaseGetOrCreateRagIndexesResponseValue]",
        "docstring": "Retrieves and/or creates RAG indexes for multiple knowledge base documents in a single request.\n\nParameters\n----------\nitems : typing.Sequence[GetOrCreateRagIndexRequestModel]\n    List of requested RAG indexes.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Dict[str, KnowledgeBaseGetOrCreateRagIndexesResponseValue]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs, GetOrCreateRagIndexRequestModel\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.get_or_create_rag_indexes(\n    items=[\n        GetOrCreateRagIndexRequestModel(\n            document_id=\"document_id\",\n            create_if_missing=True,\n            model=\"e5_mistral_7b_instruct\",\n        )\n    ],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/client.py",
        "source_line": 144
      },
      {
        "path": "client.conversational_ai.knowledge_base.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "show_only_owned_documents",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "types",
            "type": "Optional[Union[KnowledgeBaseDocumentType, Sequence[KnowledgeBaseDocumentType]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "ancestor_folder_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "folders_first",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[SortDirection]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_by",
            "type": "Optional[KnowledgeBaseSortBy]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_typesense",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetKnowledgeBaseListResponseModel",
        "docstring": "Get a list of available knowledge base documents\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    If specified, the endpoint returns only such knowledge base documents whose names start with this string.\n\nshow_only_owned_documents : typing.Optional[bool]\n    If set to true, the endpoint will return only documents owned by you (and not shared from somebody else).\n\ntypes : typing.Optional[typing.Union[KnowledgeBaseDocumentType, typing.Sequence[KnowledgeBaseDocumentType]]]\n    If present, the endpoint will return only documents of the given types.\n\nparent_folder_id : typing.Optional[str]\n    If set, the endpoint will return only documents that are direct children of the given folder.\n\nancestor_folder_id : typing.Optional[str]\n    If set, the endpoint will return only documents that are descendants of the given folder.\n\nfolders_first : typing.Optional[bool]\n    Whether folders should be returned first in the list of documents.\n\nsort_direction : typing.Optional[SortDirection]\n    The direction to sort the results\n\nsort_by : typing.Optional[KnowledgeBaseSortBy]\n    The field to sort the results by\n\nuse_typesense : typing.Optional[bool]\n    If set to true, the endpoint will use typesense DB to search for the documents).\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetKnowledgeBaseListResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.knowledge_base.list(\n    page_size=1,\n    search=\"search\",\n    show_only_owned_documents=True,\n    parent_folder_id=\"parent_folder_id\",\n    ancestor_folder_id=\"ancestor_folder_id\",\n    folders_first=True,\n    sort_direction=\"asc\",\n    sort_by=\"name\",\n    use_typesense=True,\n    cursor=\"cursor\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/client.py",
        "source_line": 44
      },
      {
        "path": "client.conversational_ai.knowledge_base.with_raw_response.get_or_create_rag_indexes",
        "name": "get_or_create_rag_indexes",
        "parameters": [
          {
            "name": "items",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieves and/or creates RAG indexes for multiple knowledge base documents in a single request.\n\nParameters\n----------\nitems : typing.Sequence[GetOrCreateRagIndexRequestModel]\n    List of requested RAG indexes.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Dict[str, KnowledgeBaseGetOrCreateRagIndexesResponseValue]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/raw_client.py",
        "source_line": 139
      },
      {
        "path": "client.conversational_ai.knowledge_base.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "show_only_owned_documents",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "types",
            "type": "Union[Literal, Any, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "ancestor_folder_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "folders_first",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_by",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_typesense",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get a list of available knowledge base documents\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    If specified, the endpoint returns only such knowledge base documents whose names start with this string.\n\nshow_only_owned_documents : typing.Optional[bool]\n    If set to true, the endpoint will return only documents owned by you (and not shared from somebody else).\n\ntypes : typing.Optional[typing.Union[KnowledgeBaseDocumentType, typing.Sequence[KnowledgeBaseDocumentType]]]\n    If present, the endpoint will return only documents of the given types.\n\nparent_folder_id : typing.Optional[str]\n    If set, the endpoint will return only documents that are direct children of the given folder.\n\nancestor_folder_id : typing.Optional[str]\n    If set, the endpoint will return only documents that are descendants of the given folder.\n\nfolders_first : typing.Optional[bool]\n    Whether folders should be returned first in the list of documents.\n\nsort_direction : typing.Optional[SortDirection]\n    The direction to sort the results\n\nsort_by : typing.Optional[KnowledgeBaseSortBy]\n    The field to sort the results by\n\nuse_typesense : typing.Optional[bool]\n    If set to true, the endpoint will use typesense DB to search for the documents).\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetKnowledgeBaseListResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/raw_client.py",
        "source_line": 31
      },
      {
        "path": "client.conversational_ai.llm_usage.calculate",
        "name": "calculate",
        "parameters": [
          {
            "name": "prompt_length",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "number_of_pages",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_enabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "LlmUsageCalculatorResponseModel",
        "docstring": "Returns a list of LLM models and the expected cost for using them based on the provided values.\n\nParameters\n----------\nprompt_length : int\n    Length of the prompt in characters.\n\nnumber_of_pages : int\n    Pages of content in PDF documents or URLs in the agent's knowledge base.\n\nrag_enabled : bool\n    Whether RAG is enabled.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nLlmUsageCalculatorResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.llm_usage.calculate(\n    prompt_length=1,\n    number_of_pages=1,\n    rag_enabled=True,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/llm_usage/client.py",
        "source_line": 29
      },
      {
        "path": "client.conversational_ai.llm_usage.with_raw_response.calculate",
        "name": "calculate",
        "parameters": [
          {
            "name": "prompt_length",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "number_of_pages",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_enabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns a list of LLM models and the expected cost for using them based on the provided values.\n\nParameters\n----------\nprompt_length : int\n    Length of the prompt in characters.\n\nnumber_of_pages : int\n    Pages of content in PDF documents or URLs in the agent's knowledge base.\n\nrag_enabled : bool\n    Whether RAG is enabled.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[LlmUsageCalculatorResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/llm_usage/raw_client.py",
        "source_line": 23
      },
      {
        "path": "client.conversational_ai.mcp_servers.approval_policy.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Update the approval policy configuration for an MCP server. DEPRECATED: Use PATCH /mcp-servers/{id} endpoint instead.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\napproval_policy : McpApprovalPolicy\n    The approval mode to set for the MCP server\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.approval_policy.update(\n    mcp_server_id=\"mcp_server_id\",\n    approval_policy=\"auto_approve_all\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/approval_policy/client.py",
        "source_line": 30
      },
      {
        "path": "client.conversational_ai.mcp_servers.approval_policy.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update the approval policy configuration for an MCP server. DEPRECATED: Use PATCH /mcp-servers/{id} endpoint instead.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\napproval_policy : McpApprovalPolicy\n    The approval mode to set for the MCP server\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/approval_policy/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.conversational_ai.mcp_servers.create",
        "name": "create",
        "parameters": [
          {
            "name": "config",
            "type": "McpServerConfigInput",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Create a new MCP server configuration in the workspace.\n\nParameters\n----------\nconfig : McpServerConfigInput\n    Configuration details for the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs, McpServerConfigInput\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.create(\n    config=McpServerConfigInput(\n        url=\"url\",\n        name=\"name\",\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 76
      },
      {
        "path": "client.conversational_ai.mcp_servers.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a specific MCP server configuration from the workspace.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.delete(\n    mcp_server_id=\"mcp_server_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 145
      },
      {
        "path": "client.conversational_ai.mcp_servers.get",
        "name": "get",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Retrieve a specific MCP server configuration from the workspace.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.get(\n    mcp_server_id=\"mcp_server_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 112
      },
      {
        "path": "client.conversational_ai.mcp_servers.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServersResponseModel",
        "docstring": "Retrieve all MCP server configurations available in the workspace.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServersResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.list()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 50
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_approvals.create",
        "name": "create",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "input_schema",
            "type": "Optional[Dict[str, Any]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Add approval for a specific MCP tool when using per-tool approval mode.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    The name of the MCP tool\n\ntool_description : str\n    The description of the MCP tool\n\ninput_schema : typing.Optional[typing.Dict[str, typing.Any]]\n    The input schema of the MCP tool (the schema defined on the MCP server before ElevenLabs does any extra processing)\n\napproval_policy : typing.Optional[McpToolApprovalPolicy]\n    The tool-level approval policy\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.tool_approvals.create(\n    mcp_server_id=\"mcp_server_id\",\n    tool_name=\"tool_name\",\n    tool_description=\"tool_description\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_approvals/client.py",
        "source_line": 30
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_approvals.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Remove approval for a specific MCP tool when using per-tool approval mode.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to remove approval for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.tool_approvals.delete(\n    mcp_server_id=\"mcp_server_id\",\n    tool_name=\"tool_name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_approvals/client.py",
        "source_line": 91
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_approvals.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "input_schema",
            "type": "Optional[Dict[str, Any]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Add approval for a specific MCP tool when using per-tool approval mode.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    The name of the MCP tool\n\ntool_description : str\n    The description of the MCP tool\n\ninput_schema : typing.Optional[typing.Dict[str, typing.Any]]\n    The input schema of the MCP tool (the schema defined on the MCP server before ElevenLabs does any extra processing)\n\napproval_policy : typing.Optional[McpToolApprovalPolicy]\n    The tool-level approval policy\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_approvals/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_approvals.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Remove approval for a specific MCP tool when using per-tool approval mode.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to remove approval for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_approvals/raw_client.py",
        "source_line": 104
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_configs.create",
        "name": "create",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "assignments",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Create configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    The name of the MCP tool\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    If set, overrides the server's tool_call_sound setting for this tool\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    If set, overrides the server's tool_call_sound_behavior setting for this tool\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nassignments : typing.Optional[typing.Sequence[DynamicVariableAssignment]]\n    Dynamic variable assignments for this MCP tool\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.tool_configs.create(\n    mcp_server_id=\"mcp_server_id\",\n    tool_name=\"tool_name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/client.py",
        "source_line": 34
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_configs.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Remove configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to remove config overrides for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.tool_configs.delete(\n    mcp_server_id=\"mcp_server_id\",\n    tool_name=\"tool_name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/client.py",
        "source_line": 146
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_configs.get",
        "name": "get",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpToolConfigOverride",
        "docstring": "Retrieve configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to retrieve config overrides for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpToolConfigOverride\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.tool_configs.get(\n    mcp_server_id=\"mcp_server_id\",\n    tool_name=\"tool_name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/client.py",
        "source_line": 109
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_configs.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "assignments",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Update configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to update config overrides for.\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    If set, overrides the server's tool_call_sound setting for this tool\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    If set, overrides the server's tool_call_sound_behavior setting for this tool\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nassignments : typing.Optional[typing.Sequence[DynamicVariableAssignment]]\n    Dynamic variable assignments for this MCP tool\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.tool_configs.update(\n    mcp_server_id=\"mcp_server_id\",\n    tool_name=\"tool_name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/client.py",
        "source_line": 183
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_configs.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "assignments",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    The name of the MCP tool\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    If set, overrides the server's tool_call_sound setting for this tool\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    If set, overrides the server's tool_call_sound_behavior setting for this tool\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nassignments : typing.Optional[typing.Sequence[DynamicVariableAssignment]]\n    Dynamic variable assignments for this MCP tool\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/raw_client.py",
        "source_line": 32
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_configs.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Remove configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to remove config overrides for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/raw_client.py",
        "source_line": 203
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_configs.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to retrieve config overrides for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpToolConfigOverride]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/raw_client.py",
        "source_line": 139
      },
      {
        "path": "client.conversational_ai.mcp_servers.tool_configs.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "assignments",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to update config overrides for.\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    If set, overrides the server's tool_call_sound setting for this tool\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    If set, overrides the server's tool_call_sound_behavior setting for this tool\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nassignments : typing.Optional[typing.Sequence[DynamicVariableAssignment]]\n    Dynamic variable assignments for this MCP tool\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/raw_client.py",
        "source_line": 256
      },
      {
        "path": "client.conversational_ai.mcp_servers.tools.list",
        "name": "list",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ListMcpToolsResponseModel",
        "docstring": "Retrieve all tools available for a specific MCP server configuration.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nListMcpToolsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.tools.list(\n    mcp_server_id=\"mcp_server_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tools/client.py",
        "source_line": 26
      },
      {
        "path": "client.conversational_ai.mcp_servers.tools.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve all tools available for a specific MCP server configuration.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ListMcpToolsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tools/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.conversational_ai.mcp_servers.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "approval_policy",
            "type": "Optional[McpApprovalPolicy]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Optional[ToolCallSoundType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Optional[ToolCallSoundBehavior]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Optional[ToolExecutionMode]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_headers",
            "type": "Optional[Dict[str, Optional[McpServerConfigUpdateRequestModelRequestHeadersValue]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Update the configuration settings for an MCP server.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\napproval_policy : typing.Optional[McpApprovalPolicy]\n    The approval mode to set for the MCP server\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    Predefined tool call sound type to play during tool execution for all tools from this MCP server\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    Determines when the tool call sound should play for all tools from this MCP server\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nrequest_headers : typing.Optional[typing.Dict[str, typing.Optional[McpServerConfigUpdateRequestModelRequestHeadersValue]]]\n    The headers to include in requests to the MCP server\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.mcp_servers.update(\n    mcp_server_id=\"mcp_server_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 176
      },
      {
        "path": "client.conversational_ai.mcp_servers.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "config",
            "type": "McpServerConfigInput",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a new MCP server configuration in the workspace.\n\nParameters\n----------\nconfig : McpServerConfigInput\n    Configuration details for the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 79
      },
      {
        "path": "client.conversational_ai.mcp_servers.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete a specific MCP server configuration from the workspace.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 188
      },
      {
        "path": "client.conversational_ai.mcp_servers.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve a specific MCP server configuration from the workspace.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 138
      },
      {
        "path": "client.conversational_ai.mcp_servers.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve all MCP server configurations available in the workspace.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServersResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 34
      },
      {
        "path": "client.conversational_ai.mcp_servers.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_headers",
            "type": "Optional[Dict[str, Union[str, ConvAiSecretLocator, ConvAiDynamicVariable, NoneType]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update the configuration settings for an MCP server.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\napproval_policy : typing.Optional[McpApprovalPolicy]\n    The approval mode to set for the MCP server\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    Predefined tool call sound type to play during tool execution for all tools from this MCP server\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    Determines when the tool call sound should play for all tools from this MCP server\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nrequest_headers : typing.Optional[typing.Dict[str, typing.Optional[McpServerConfigUpdateRequestModelRequestHeadersValue]]]\n    The headers to include in requests to the MCP server\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 240
      },
      {
        "path": "client.conversational_ai.phone_numbers.create",
        "name": "create",
        "parameters": [
          {
            "name": "request",
            "type": "Annotated",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreatePhoneNumberResponseModel",
        "docstring": "Import Phone Number from provider configuration (Twilio or SIP trunk)\n\nParameters\n----------\nrequest : PhoneNumbersCreateRequestBody\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreatePhoneNumberResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\nfrom elevenlabs.conversational_ai.phone_numbers import (\n    PhoneNumbersCreateRequestBody_Twilio,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.phone_numbers.create(\n    request=PhoneNumbersCreateRequestBody_Twilio(\n        phone_number=\"phone_number\",\n        label=\"label\",\n        sid=\"sid\",\n        token=\"token\",\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 64
      },
      {
        "path": "client.conversational_ai.phone_numbers.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete Phone Number by ID\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.phone_numbers.delete(\n    phone_number_id=\"TeaqRRdTcIfIu2i7BYfT\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 137
      },
      {
        "path": "client.conversational_ai.phone_numbers.get",
        "name": "get",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Annotated",
        "docstring": "Retrieve Phone Number details by ID\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPhoneNumbersGetResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.phone_numbers.get(\n    phone_number_id=\"TeaqRRdTcIfIu2i7BYfT\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 104
      },
      {
        "path": "client.conversational_ai.phone_numbers.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "List[Annotated]",
        "docstring": "Retrieve all Phone Numbers\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.List[PhoneNumbersListResponseItem]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.phone_numbers.list()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 36
      },
      {
        "path": "client.conversational_ai.phone_numbers.update",
        "name": "update",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "inbound_trunk_config",
            "type": "Optional[InboundSipTrunkConfigRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "outbound_trunk_config",
            "type": "Optional[OutboundSipTrunkConfigRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "livekit_stack",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Annotated",
        "docstring": "Update assigned agent of a phone number\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nagent_id : typing.Optional[str]\n\ninbound_trunk_config : typing.Optional[InboundSipTrunkConfigRequestModel]\n\noutbound_trunk_config : typing.Optional[OutboundSipTrunkConfigRequestModel]\n\nlivekit_stack : typing.Optional[LivekitStackType]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPhoneNumbersUpdateResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.phone_numbers.update(\n    phone_number_id=\"TeaqRRdTcIfIu2i7BYfT\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 168
      },
      {
        "path": "client.conversational_ai.phone_numbers.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "request",
            "type": "Annotated",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Import Phone Number from provider configuration (Twilio or SIP trunk)\n\nParameters\n----------\nrequest : PhoneNumbersCreateRequestBody\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[CreatePhoneNumberResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 79
      },
      {
        "path": "client.conversational_ai.phone_numbers.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete Phone Number by ID\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 185
      },
      {
        "path": "client.conversational_ai.phone_numbers.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve Phone Number details by ID\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PhoneNumbersGetResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 135
      },
      {
        "path": "client.conversational_ai.phone_numbers.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve all Phone Numbers\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.List[PhoneNumbersListResponseItem]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 32
      },
      {
        "path": "client.conversational_ai.phone_numbers.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "inbound_trunk_config",
            "type": "Optional[InboundSipTrunkConfigRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "outbound_trunk_config",
            "type": "Optional[OutboundSipTrunkConfigRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "livekit_stack",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update assigned agent of a phone number\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nagent_id : typing.Optional[str]\n\ninbound_trunk_config : typing.Optional[InboundSipTrunkConfigRequestModel]\n\noutbound_trunk_config : typing.Optional[OutboundSipTrunkConfigRequestModel]\n\nlivekit_stack : typing.Optional[LivekitStackType]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PhoneNumbersUpdateResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 237
      },
      {
        "path": "client.conversational_ai.rag_index_overview",
        "name": "rag_index_overview",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RagIndexOverviewResponseModel",
        "docstring": "Provides total size and other information of RAG indexes used by knowledgebase documents\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRagIndexOverviewResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.rag_index_overview()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/client.py",
        "source_line": 116
      },
      {
        "path": "client.conversational_ai.secrets.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "value",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PostWorkspaceSecretResponseModel",
        "docstring": "Create a new secret for the workspace\n\nParameters\n----------\nname : str\n\nvalue : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPostWorkspaceSecretResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.secrets.create(\n    name=\"name\",\n    value=\"value\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/client.py",
        "source_line": 56
      },
      {
        "path": "client.conversational_ai.secrets.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "secret_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a workspace secret if it's not in use\n\nParameters\n----------\nsecret_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.secrets.delete(\n    secret_id=\"secret_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/client.py",
        "source_line": 91
      },
      {
        "path": "client.conversational_ai.secrets.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetWorkspaceSecretsResponseModel",
        "docstring": "Get all workspace secrets for the user\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetWorkspaceSecretsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.secrets.list()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/client.py",
        "source_line": 30
      },
      {
        "path": "client.conversational_ai.secrets.update",
        "name": "update",
        "parameters": [
          {
            "name": "secret_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "value",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PostWorkspaceSecretResponseModel",
        "docstring": "Update an existing secret for the workspace\n\nParameters\n----------\nsecret_id : str\n\nname : str\n\nvalue : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPostWorkspaceSecretResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.secrets.update(\n    secret_id=\"secret_id\",\n    name=\"name\",\n    value=\"value\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/client.py",
        "source_line": 120
      },
      {
        "path": "client.conversational_ai.secrets.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "value",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a new secret for the workspace\n\nParameters\n----------\nname : str\n\nvalue : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PostWorkspaceSecretResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/raw_client.py",
        "source_line": 72
      },
      {
        "path": "client.conversational_ai.secrets.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "secret_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete a workspace secret if it's not in use\n\nParameters\n----------\nsecret_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[None]",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/raw_client.py",
        "source_line": 132
      },
      {
        "path": "client.conversational_ai.secrets.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get all workspace secrets for the user\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetWorkspaceSecretsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.conversational_ai.secrets.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "secret_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "value",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update an existing secret for the workspace\n\nParameters\n----------\nsecret_id : str\n\nname : str\n\nvalue : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PostWorkspaceSecretResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/raw_client.py",
        "source_line": 171
      },
      {
        "path": "client.conversational_ai.settings.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConvAiSettingsResponseModel",
        "docstring": "Retrieve Convai settings for the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConvAiSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.settings.get()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/settings/client.py",
        "source_line": 32
      },
      {
        "path": "client.conversational_ai.settings.update",
        "name": "update",
        "parameters": [
          {
            "name": "conversation_initiation_client_data_webhook",
            "type": "Optional[ConversationInitiationClientDataWebhook]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhooks",
            "type": "Optional[ConvAiWebhooks]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "can_use_mcp_servers",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_retention_period_days",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_livekit_stack",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConvAiSettingsResponseModel",
        "docstring": "Update Convai settings for the workspace\n\nParameters\n----------\nconversation_initiation_client_data_webhook : typing.Optional[ConversationInitiationClientDataWebhook]\n\nwebhooks : typing.Optional[ConvAiWebhooks]\n\ncan_use_mcp_servers : typing.Optional[bool]\n    Whether the workspace can use MCP servers\n\nrag_retention_period_days : typing.Optional[int]\n\ndefault_livekit_stack : typing.Optional[LivekitStackType]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConvAiSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.settings.update()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/settings/client.py",
        "source_line": 58
      },
      {
        "path": "client.conversational_ai.settings.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve Convai settings for the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetConvAiSettingsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/settings/raw_client.py",
        "source_line": 27
      },
      {
        "path": "client.conversational_ai.settings.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "conversation_initiation_client_data_webhook",
            "type": "Optional[ConversationInitiationClientDataWebhook]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhooks",
            "type": "Optional[ConvAiWebhooks]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "can_use_mcp_servers",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_retention_period_days",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_livekit_stack",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update Convai settings for the workspace\n\nParameters\n----------\nconversation_initiation_client_data_webhook : typing.Optional[ConversationInitiationClientDataWebhook]\n\nwebhooks : typing.Optional[ConvAiWebhooks]\n\ncan_use_mcp_servers : typing.Optional[bool]\n    Whether the workspace can use MCP servers\n\nrag_retention_period_days : typing.Optional[int]\n\ndefault_livekit_stack : typing.Optional[LivekitStackType]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetConvAiSettingsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/settings/raw_client.py",
        "source_line": 74
      },
      {
        "path": "client.conversational_ai.sip_trunk.outbound_call",
        "name": "outbound_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SipTrunkOutboundCallResponse",
        "docstring": "Handle an outbound call via SIP trunk\n\nParameters\n----------\nagent_id : str\n\nagent_phone_number_id : str\n\nto_number : str\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSipTrunkOutboundCallResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.sip_trunk.outbound_call(\n    agent_id=\"agent_id\",\n    agent_phone_number_id=\"agent_phone_number_id\",\n    to_number=\"to_number\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/sip_trunk/client.py",
        "source_line": 30
      },
      {
        "path": "client.conversational_ai.sip_trunk.with_raw_response.outbound_call",
        "name": "outbound_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Handle an outbound call via SIP trunk\n\nParameters\n----------\nagent_id : str\n\nagent_phone_number_id : str\n\nto_number : str\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SipTrunkOutboundCallResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/sip_trunk/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.conversational_ai.tests.create",
        "name": "create",
        "parameters": [
          {
            "name": "chat_history",
            "type": "Sequence[ConversationHistoryTranscriptCommonModelInput]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_condition",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_examples",
            "type": "Sequence[AgentSuccessfulResponseExample]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "failure_examples",
            "type": "Sequence[AgentFailureResponseExample]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_parameters",
            "type": "Optional[UnitTestToolCallEvaluationModelInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dynamic_variables",
            "type": "Optional[Dict[str, Optional[CreateUnitTestRequestDynamicVariablesValue]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "type",
            "type": "Optional[UnitTestCommonModelType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_conversation_metadata",
            "type": "Optional[TestFromConversationMetadataInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreateUnitTestResponseModel",
        "docstring": "Creates a new agent response test.\n\nParameters\n----------\nchat_history : typing.Sequence[ConversationHistoryTranscriptCommonModelInput]\n\nsuccess_condition : str\n    A prompt that evaluates whether the agent's response is successful. Should return True or False.\n\nsuccess_examples : typing.Sequence[AgentSuccessfulResponseExample]\n    Non-empty list of example responses that should be considered successful\n\nfailure_examples : typing.Sequence[AgentFailureResponseExample]\n    Non-empty list of example responses that should be considered failures\n\nname : str\n\ntool_call_parameters : typing.Optional[UnitTestToolCallEvaluationModelInput]\n    How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated.\n\ndynamic_variables : typing.Optional[typing.Dict[str, typing.Optional[CreateUnitTestRequestDynamicVariablesValue]]]\n    Dynamic variables to replace in the agent config during testing\n\ntype : typing.Optional[UnitTestCommonModelType]\n\nfrom_conversation_metadata : typing.Optional[TestFromConversationMetadataInput]\n    Metadata of a conversation this test was created from (if applicable).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreateUnitTestResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import (\n    AgentFailureResponseExample,\n    AgentSuccessfulResponseExample,\n    ConversationHistoryTranscriptCommonModelInput,\n    ElevenLabs,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.create(\n    chat_history=[\n        ConversationHistoryTranscriptCommonModelInput(\n            role=\"user\",\n            time_in_call_secs=1,\n        )\n    ],\n    success_condition=\"success_condition\",\n    success_examples=[\n        AgentSuccessfulResponseExample(\n            response=\"response\",\n        )\n    ],\n    failure_examples=[\n        AgentFailureResponseExample(\n            response=\"response\",\n        )\n    ],\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 46
      },
      {
        "path": "client.conversational_ai.tests.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Deletes an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.delete(\n    test_id=\"TeaqRRdTcIfIu2i7BYfT\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 283
      },
      {
        "path": "client.conversational_ai.tests.get",
        "name": "get",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetUnitTestResponseModel",
        "docstring": "Gets an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetUnitTestResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.get(\n    test_id=\"TeaqRRdTcIfIu2i7BYfT\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 146
      },
      {
        "path": "client.conversational_ai.tests.invocations.get",
        "name": "get",
        "parameters": [
          {
            "name": "test_invocation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestSuiteInvocationResponseModel",
        "docstring": "Gets a test invocation by ID.\n\nParameters\n----------\ntest_invocation_id : str\n    The id of a test invocation. This is returned when tests are run.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestSuiteInvocationResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.invocations.get(\n    test_invocation_id=\"test_invocation_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/client.py",
        "source_line": 79
      },
      {
        "path": "client.conversational_ai.tests.invocations.list",
        "name": "list",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestInvocationsPageResponseModel",
        "docstring": "Lists all test invocations with pagination support and optional search filtering.\n\nParameters\n----------\nagent_id : str\n    Filter by agent ID\n\npage_size : typing.Optional[int]\n    How many Tests to return at maximum. Can not exceed 100, defaults to 30.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestInvocationsPageResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.invocations.list(\n    agent_id=\"agent_id\",\n    page_size=1,\n    cursor=\"cursor\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/client.py",
        "source_line": 31
      },
      {
        "path": "client.conversational_ai.tests.invocations.resubmit",
        "name": "resubmit",
        "parameters": [
          {
            "name": "test_invocation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "test_run_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_config_override",
            "type": "Optional[AdhocAgentConfigOverrideForTestRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "branch_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Resubmits specific test runs from a test invocation.\n\nParameters\n----------\ntest_invocation_id : str\n    The id of a test invocation. This is returned when tests are run.\n\ntest_run_ids : typing.Sequence[str]\n    List of test run IDs to resubmit\n\nagent_id : str\n    Agent ID to resubmit tests for\n\nagent_config_override : typing.Optional[AdhocAgentConfigOverrideForTestRequestModel]\n    Configuration overrides to use for testing. If not provided, the agent's default configuration will be used.\n\nbranch_id : typing.Optional[str]\n    ID of the branch to run the tests on. If not provided, the tests will be run on the agent default configuration.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.invocations.resubmit(\n    test_invocation_id=\"test_invocation_id\",\n    test_run_ids=[\"test_run_ids\"],\n    agent_id=\"agent_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/client.py",
        "source_line": 112
      },
      {
        "path": "client.conversational_ai.tests.invocations.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "test_invocation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets a test invocation by ID.\n\nParameters\n----------\ntest_invocation_id : str\n    The id of a test invocation. This is returned when tests are run.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetTestSuiteInvocationResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/raw_client.py",
        "source_line": 93
      },
      {
        "path": "client.conversational_ai.tests.invocations.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Lists all test invocations with pagination support and optional search filtering.\n\nParameters\n----------\nagent_id : str\n    Filter by agent ID\n\npage_size : typing.Optional[int]\n    How many Tests to return at maximum. Can not exceed 100, defaults to 30.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetTestInvocationsPageResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/raw_client.py",
        "source_line": 27
      },
      {
        "path": "client.conversational_ai.tests.invocations.with_raw_response.resubmit",
        "name": "resubmit",
        "parameters": [
          {
            "name": "test_invocation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "test_run_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_config_override",
            "type": "Optional[AdhocAgentConfigOverrideForTestRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "branch_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Resubmits specific test runs from a test invocation.\n\nParameters\n----------\ntest_invocation_id : str\n    The id of a test invocation. This is returned when tests are run.\n\ntest_run_ids : typing.Sequence[str]\n    List of test run IDs to resubmit\n\nagent_id : str\n    Agent ID to resubmit tests for\n\nagent_config_override : typing.Optional[AdhocAgentConfigOverrideForTestRequestModel]\n    Configuration overrides to use for testing. If not provided, the agent's default configuration will be used.\n\nbranch_id : typing.Optional[str]\n    ID of the branch to run the tests on. If not provided, the tests will be run on the agent default configuration.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/raw_client.py",
        "source_line": 143
      },
      {
        "path": "client.conversational_ai.tests.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestsPageResponseModel",
        "docstring": "Lists all agent response tests with pagination support and optional search filtering.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many Tests to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    Search query to filter tests by name.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestsPageResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.list(\n    cursor=\"cursor\",\n    page_size=1,\n    search=\"search\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 347
      },
      {
        "path": "client.conversational_ai.tests.summaries",
        "name": "summaries",
        "parameters": [
          {
            "name": "test_ids",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestsSummariesByIdsResponseModel",
        "docstring": "Gets multiple agent response tests by their IDs. Returns a dictionary mapping test IDs to test summaries.\n\nParameters\n----------\ntest_ids : typing.Sequence[str]\n    List of test IDs to fetch. No duplicates allowed.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestsSummariesByIdsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.summaries(\n    test_ids=[\"test_id_1\", \"test_id_2\"],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 314
      },
      {
        "path": "client.conversational_ai.tests.update",
        "name": "update",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chat_history",
            "type": "Sequence[ConversationHistoryTranscriptCommonModelInput]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_condition",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_examples",
            "type": "Sequence[AgentSuccessfulResponseExample]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "failure_examples",
            "type": "Sequence[AgentFailureResponseExample]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_parameters",
            "type": "Optional[UnitTestToolCallEvaluationModelInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dynamic_variables",
            "type": "Optional[Dict[str, Optional[UpdateUnitTestRequestDynamicVariablesValue]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "type",
            "type": "Optional[UnitTestCommonModelType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_conversation_metadata",
            "type": "Optional[TestFromConversationMetadataInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetUnitTestResponseModel",
        "docstring": "Updates an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nchat_history : typing.Sequence[ConversationHistoryTranscriptCommonModelInput]\n\nsuccess_condition : str\n    A prompt that evaluates whether the agent's response is successful. Should return True or False.\n\nsuccess_examples : typing.Sequence[AgentSuccessfulResponseExample]\n    Non-empty list of example responses that should be considered successful\n\nfailure_examples : typing.Sequence[AgentFailureResponseExample]\n    Non-empty list of example responses that should be considered failures\n\nname : str\n\ntool_call_parameters : typing.Optional[UnitTestToolCallEvaluationModelInput]\n    How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated.\n\ndynamic_variables : typing.Optional[typing.Dict[str, typing.Optional[UpdateUnitTestRequestDynamicVariablesValue]]]\n    Dynamic variables to replace in the agent config during testing\n\ntype : typing.Optional[UnitTestCommonModelType]\n\nfrom_conversation_metadata : typing.Optional[TestFromConversationMetadataInput]\n    Metadata of a conversation this test was created from (if applicable).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetUnitTestResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import (\n    AgentFailureResponseExample,\n    AgentSuccessfulResponseExample,\n    ConversationHistoryTranscriptCommonModelInput,\n    ElevenLabs,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tests.update(\n    test_id=\"TeaqRRdTcIfIu2i7BYfT\",\n    chat_history=[\n        ConversationHistoryTranscriptCommonModelInput(\n            role=\"user\",\n            time_in_call_secs=1,\n        )\n    ],\n    success_condition=\"success_condition\",\n    success_examples=[\n        AgentSuccessfulResponseExample(\n            response=\"response\",\n        )\n    ],\n    failure_examples=[\n        AgentFailureResponseExample(\n            response=\"response\",\n        )\n    ],\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 177
      },
      {
        "path": "client.conversational_ai.tests.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "chat_history",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_condition",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_examples",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "failure_examples",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_parameters",
            "type": "Optional[UnitTestToolCallEvaluationModelInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dynamic_variables",
            "type": "Optional[Dict[str, Union[str, int, float, bool, NoneType]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "type",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_conversation_metadata",
            "type": "Optional[TestFromConversationMetadataInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Creates a new agent response test.\n\nParameters\n----------\nchat_history : typing.Sequence[ConversationHistoryTranscriptCommonModelInput]\n\nsuccess_condition : str\n    A prompt that evaluates whether the agent's response is successful. Should return True or False.\n\nsuccess_examples : typing.Sequence[AgentSuccessfulResponseExample]\n    Non-empty list of example responses that should be considered successful\n\nfailure_examples : typing.Sequence[AgentFailureResponseExample]\n    Non-empty list of example responses that should be considered failures\n\nname : str\n\ntool_call_parameters : typing.Optional[UnitTestToolCallEvaluationModelInput]\n    How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated.\n\ndynamic_variables : typing.Optional[typing.Dict[str, typing.Optional[CreateUnitTestRequestDynamicVariablesValue]]]\n    Dynamic variables to replace in the agent config during testing\n\ntype : typing.Optional[UnitTestCommonModelType]\n\nfrom_conversation_metadata : typing.Optional[TestFromConversationMetadataInput]\n    Metadata of a conversation this test was created from (if applicable).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[CreateUnitTestResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 36
      },
      {
        "path": "client.conversational_ai.tests.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Deletes an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 324
      },
      {
        "path": "client.conversational_ai.tests.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetUnitTestResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 153
      },
      {
        "path": "client.conversational_ai.tests.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Lists all agent response tests with pagination support and optional search filtering.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many Tests to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    Search query to filter tests by name.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetTestsPageResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 433
      },
      {
        "path": "client.conversational_ai.tests.with_raw_response.summaries",
        "name": "summaries",
        "parameters": [
          {
            "name": "test_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets multiple agent response tests by their IDs. Returns a dictionary mapping test IDs to test summaries.\n\nParameters\n----------\ntest_ids : typing.Sequence[str]\n    List of test IDs to fetch. No duplicates allowed.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetTestsSummariesByIdsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 376
      },
      {
        "path": "client.conversational_ai.tests.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chat_history",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_condition",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_examples",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "failure_examples",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_parameters",
            "type": "Optional[UnitTestToolCallEvaluationModelInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dynamic_variables",
            "type": "Optional[Dict[str, Union[str, int, float, bool, NoneType]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "type",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_conversation_metadata",
            "type": "Optional[TestFromConversationMetadataInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Updates an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nchat_history : typing.Sequence[ConversationHistoryTranscriptCommonModelInput]\n\nsuccess_condition : str\n    A prompt that evaluates whether the agent's response is successful. Should return True or False.\n\nsuccess_examples : typing.Sequence[AgentSuccessfulResponseExample]\n    Non-empty list of example responses that should be considered successful\n\nfailure_examples : typing.Sequence[AgentFailureResponseExample]\n    Non-empty list of example responses that should be considered failures\n\nname : str\n\ntool_call_parameters : typing.Optional[UnitTestToolCallEvaluationModelInput]\n    How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated.\n\ndynamic_variables : typing.Optional[typing.Dict[str, typing.Optional[UpdateUnitTestRequestDynamicVariablesValue]]]\n    Dynamic variables to replace in the agent config during testing\n\ntype : typing.Optional[UnitTestCommonModelType]\n\nfrom_conversation_metadata : typing.Optional[TestFromConversationMetadataInput]\n    Metadata of a conversation this test was created from (if applicable).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetUnitTestResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 203
      },
      {
        "path": "client.conversational_ai.tools.create",
        "name": "create",
        "parameters": [
          {
            "name": "request",
            "type": "ToolRequestModel",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ToolResponseModel",
        "docstring": "Add a new tool to the available tools in the workspace.\n\nParameters\n----------\nrequest : ToolRequestModel\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nToolResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import (\n    ElevenLabs,\n    ToolRequestModel,\n    ToolRequestModelToolConfig_Client,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tools.create(\n    request=ToolRequestModel(\n        tool_config=ToolRequestModelToolConfig_Client(\n            name=\"name\",\n            description=\"description\",\n            expects_response=False,\n        ),\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 58
      },
      {
        "path": "client.conversational_ai.tools.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete tool from the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tools.delete(\n    tool_id=\"tool_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 131
      },
      {
        "path": "client.conversational_ai.tools.get",
        "name": "get",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ToolResponseModel",
        "docstring": "Get tool that is available in the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nToolResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tools.get(\n    tool_id=\"tool_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 100
      },
      {
        "path": "client.conversational_ai.tools.get_dependent_agents",
        "name": "get_dependent_agents",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetToolDependentAgentsResponseModel",
        "docstring": "Get a list of agents depending on this tool\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetToolDependentAgentsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tools.get_dependent_agents(\n    tool_id=\"tool_id\",\n    cursor=\"cursor\",\n    page_size=1,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 208
      },
      {
        "path": "client.conversational_ai.tools.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ToolsResponseModel",
        "docstring": "Get all available tools in the workspace.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nToolsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tools.list()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 32
      },
      {
        "path": "client.conversational_ai.tools.update",
        "name": "update",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request",
            "type": "ToolRequestModel",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ToolResponseModel",
        "docstring": "Update tool that is available in the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest : ToolRequestModel\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nToolResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import (\n    ElevenLabs,\n    ToolRequestModel,\n    ToolRequestModelToolConfig_Client,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.tools.update(\n    tool_id=\"tool_id\",\n    request=ToolRequestModel(\n        tool_config=ToolRequestModelToolConfig_Client(\n            name=\"name\",\n            description=\"description\",\n            expects_response=False,\n        ),\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 162
      },
      {
        "path": "client.conversational_ai.tools.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "request",
            "type": "ToolRequestModel",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Add a new tool to the available tools in the workspace.\n\nParameters\n----------\nrequest : ToolRequestModel\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ToolResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 73
      },
      {
        "path": "client.conversational_ai.tools.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete tool from the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 179
      },
      {
        "path": "client.conversational_ai.tools.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get tool that is available in the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ToolResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 129
      },
      {
        "path": "client.conversational_ai.tools.with_raw_response.get_dependent_agents",
        "name": "get_dependent_agents",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get a list of agents depending on this tool\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetToolDependentAgentsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 290
      },
      {
        "path": "client.conversational_ai.tools.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get all available tools in the workspace.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ToolsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 28
      },
      {
        "path": "client.conversational_ai.tools.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request",
            "type": "ToolRequestModel",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update tool that is available in the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest : ToolRequestModel\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ToolResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 231
      },
      {
        "path": "client.conversational_ai.twilio.outbound_call",
        "name": "outbound_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "TwilioOutboundCallResponse",
        "docstring": "Handle an outbound call via Twilio\n\nParameters\n----------\nagent_id : str\n\nagent_phone_number_id : str\n\nto_number : str\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nTwilioOutboundCallResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.twilio.outbound_call(\n    agent_id=\"agent_id\",\n    agent_phone_number_id=\"agent_phone_number_id\",\n    to_number=\"to_number\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/twilio/client.py",
        "source_line": 33
      },
      {
        "path": "client.conversational_ai.twilio.register_call",
        "name": "register_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Register a Twilio call and return TwiML to connect the call\n\nParameters\n----------\nagent_id : str\n\nfrom_number : str\n\nto_number : str\n\ndirection : typing.Optional[BodyRegisterATwilioCallAndReturnTwiMlV1ConvaiTwilioRegisterCallPostDirection]\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.conversational_ai.twilio.register_call(\n    agent_id=\"agent_id\",\n    from_number=\"from_number\",\n    to_number=\"to_number\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/twilio/client.py",
        "source_line": 85
      },
      {
        "path": "client.conversational_ai.twilio.with_raw_response.outbound_call",
        "name": "outbound_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Handle an outbound call via Twilio\n\nParameters\n----------\nagent_id : str\n\nagent_phone_number_id : str\n\nto_number : str\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[TwilioOutboundCallResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/twilio/raw_client.py",
        "source_line": 28
      },
      {
        "path": "client.conversational_ai.twilio.with_raw_response.register_call",
        "name": "register_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Register a Twilio call and return TwiML to connect the call\n\nParameters\n----------\nagent_id : str\n\nfrom_number : str\n\nto_number : str\n\ndirection : typing.Optional[BodyRegisterATwilioCallAndReturnTwiMlV1ConvaiTwilioRegisterCallPostDirection]\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[None]",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/twilio/raw_client.py",
        "source_line": 103
      },
      {
        "path": "client.conversational_ai.with_raw_response.add_to_knowledge_base",
        "name": "add_to_knowledge_base",
        "parameters": [
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Upload a file or webpage URL to create a knowledge base document. <br> <Note> After creating the document, update the agent's knowledge base by calling [Update agent](/docs/api-reference/agents/update). </Note>\n\nParameters\n----------\nagent_id : typing.Optional[str]\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nurl : typing.Optional[str]\n    URL to a page of documentation that the agent will have access to in order to interact with users.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddKnowledgeBaseResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/raw_client.py",
        "source_line": 28
      },
      {
        "path": "client.conversational_ai.with_raw_response.delete_document_rag_index",
        "name": "delete_document_rag_index",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rag_index_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete RAG index for the knowledgebase document.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrag_index_id : str\n    The id of RAG index of document from the knowledge base.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[RagDocumentIndexResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/raw_client.py",
        "source_line": 201
      },
      {
        "path": "client.conversational_ai.with_raw_response.get_document_rag_indexes",
        "name": "get_document_rag_indexes",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Provides information about all RAG indexes of the specified knowledgebase document.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[RagDocumentIndexesResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/raw_client.py",
        "source_line": 151
      },
      {
        "path": "client.conversational_ai.with_raw_response.rag_index_overview",
        "name": "rag_index_overview",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Provides total size and other information of RAG indexes used by knowledgebase documents\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[RagIndexOverviewResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/raw_client.py",
        "source_line": 104
      },
      {
        "path": "client.dubbing.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language_code",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Returns dub as a streamed MP3 or MP4 file. If this dub has been edited using Dubbing Studio you need to use the resource render endpoint as this endpoint only returns the original automatic dub result.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage_code : str\n    ID of the language.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The dubbed audio or video file\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.audio.get(\n    dubbing_id=\"dubbing_id\",\n    language_code=\"language_code\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/audio/client.py",
        "source_line": 25
      },
      {
        "path": "client.dubbing.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language_code",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Returns dub as a streamed MP3 or MP4 file. If this dub has been edited using Dubbing Studio you need to use the resource render endpoint as this endpoint only returns the original automatic dub result.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage_code : str\n    ID of the language.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The dubbed audio or video file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 24
      },
      {
        "path": "client.dubbing.create",
        "name": "create",
        "parameters": [
          {
            "name": "file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "csv_file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "foreground_audio_file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "background_audio_file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_lang",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_lang",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_accent",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "num_speakers",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "watermark",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "start_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "highest_resolution",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "drop_background_audio",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_profanity_filter",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dubbing_studio",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_voice_cloning",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mode",
            "type": "Optional[DubbingCreateRequestMode]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "csv_fps",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DoDubbingResponse",
        "docstring": "Dubs a provided audio or video file into given language.\n\nParameters\n----------\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\ncsv_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nforeground_audio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nbackground_audio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nname : typing.Optional[str]\n    Name of the dubbing project.\n\nsource_url : typing.Optional[str]\n    URL of the source video/audio file.\n\nsource_lang : typing.Optional[str]\n    Source language. Expects a valid iso639-1 or iso639-3 language code.\n\ntarget_lang : typing.Optional[str]\n    The Target language to dub the content into. Expects a valid iso639-1 or iso639-3 language code.\n\ntarget_accent : typing.Optional[str]\n    [Experimental] An accent to apply when selecting voices from the library and to use to inform translation of the dialect to prefer.\n\nnum_speakers : typing.Optional[int]\n    Number of speakers to use for the dubbing. Set to 0 to automatically detect the number of speakers\n\nwatermark : typing.Optional[bool]\n    Whether to apply watermark to the output video.\n\nstart_time : typing.Optional[int]\n    Start time of the source video/audio file.\n\nend_time : typing.Optional[int]\n    End time of the source video/audio file.\n\nhighest_resolution : typing.Optional[bool]\n    Whether to use the highest resolution available.\n\ndrop_background_audio : typing.Optional[bool]\n    An advanced setting. Whether to drop background audio from the final dub. This can improve dub quality where it's known that audio shouldn't have a background track such as for speeches or monologues.\n\nuse_profanity_filter : typing.Optional[bool]\n    [BETA] Whether transcripts should have profanities censored with the words '[censored]'\n\ndubbing_studio : typing.Optional[bool]\n    Whether to prepare dub for edits in dubbing studio or edits as a dubbing resource.\n\ndisable_voice_cloning : typing.Optional[bool]\n    Instead of using a voice clone in dubbing, use a similar voice from the ElevenLabs Voice Library. Voices used from the library will contribute towards a workspace's custom voices limit, and if there aren't enough available slots the dub will fail. Using this feature requires the caller to have the 'add_voice_from_voice_library' permission on their workspace to access new voices.\n\nmode : typing.Optional[DubbingCreateRequestMode]\n    The mode in which to run this Dubbing job. Defaults to automatic, use manual if specifically providing a CSV transcript to use.\n\ncsv_fps : typing.Optional[float]\n    Frames per second to use when parsing a CSV file for dubbing. If not provided, FPS will be inferred from timecodes.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDoDubbingResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.create()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/client.py",
        "source_line": 115
      },
      {
        "path": "client.dubbing.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteDubbingResponseModel",
        "docstring": "Deletes a dubbing project.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteDubbingResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.delete(\n    dubbing_id=\"dubbing_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/client.py",
        "source_line": 280
      },
      {
        "path": "client.dubbing.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DubbingMetadataResponse",
        "docstring": "Returns metadata about a dubbing project, including whether it's still in progress or not\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDubbingMetadataResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.get(\n    dubbing_id=\"dubbing_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/client.py",
        "source_line": 247
      },
      {
        "path": "client.dubbing.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dubbing_status",
            "type": "Optional[DubbingListRequestDubbingStatus]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "filter_by_creator",
            "type": "Optional[DubbingListRequestFilterByCreator]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "order_by",
            "type": "Optional[Literal['created_at']]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "order_direction",
            "type": "Optional[DubbingListRequestOrderDirection]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DubbingMetadataPageResponseModel",
        "docstring": "List the dubs you have access to.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many dubs to return at maximum. Can not exceed 200, defaults to 100.\n\ndubbing_status : typing.Optional[DubbingListRequestDubbingStatus]\n    What state the dub is currently in.\n\nfilter_by_creator : typing.Optional[DubbingListRequestFilterByCreator]\n    Filters who created the resources being listed, whether it was the user running the request or someone else that shared the resource with them.\n\norder_by : typing.Optional[typing.Literal[\"created_at\"]]\n    The field to use for ordering results from this query.\n\norder_direction : typing.Optional[DubbingListRequestOrderDirection]\n    The order direction to use for results from this query.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDubbingMetadataPageResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.list(\n    cursor=\"cursor\",\n    page_size=1,\n    dubbing_status=\"dubbing\",\n    filter_by_creator=\"personal\",\n    order_direction=\"DESCENDING\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/client.py",
        "source_line": 47
      },
      {
        "path": "client.dubbing.resource.dub",
        "name": "dub",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentDubResponse",
        "docstring": "Regenerate the dubs for either the entire resource or the specified segments/languages. Will automatically transcribe and translate any missing transcriptions and translations.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Dub only this list of segments.\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Dub only these languages for each segment.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentDubResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.dub(\n    dubbing_id=\"dubbing_id\",\n    segments=[\"segments\"],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 211
      },
      {
        "path": "client.dubbing.resource.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DubbingResource",
        "docstring": "Given a dubbing ID generated from the '/v1/dubbing' endpoint with studio enabled, returns the dubbing resource.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDubbingResource\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.get(\n    dubbing_id=\"dubbing_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 46
      },
      {
        "path": "client.dubbing.resource.language.add",
        "name": "add",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "LanguageAddedResponse",
        "docstring": "Adds the given ElevenLab Turbo V2/V2.5 language code to the resource. Does not automatically generate transcripts/translations/audio.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage : typing.Optional[str]\n    The Target language.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nLanguageAddedResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.language.add(\n    dubbing_id=\"dubbing_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/language/client.py",
        "source_line": 29
      },
      {
        "path": "client.dubbing.resource.language.with_raw_response.add",
        "name": "add",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Adds the given ElevenLab Turbo V2/V2.5 language code to the resource. Does not automatically generate transcripts/translations/audio.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage : typing.Optional[str]\n    The Target language.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[LanguageAddedResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/language/raw_client.py",
        "source_line": 24
      },
      {
        "path": "client.dubbing.resource.migrate_segments",
        "name": "migrate_segments",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_ids",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentMigrationResponse",
        "docstring": "Change the attribution of one or more segments to a different speaker.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_ids : typing.Sequence[str]\n\nspeaker_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentMigrationResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.migrate_segments(\n    dubbing_id=\"dubbing_id\",\n    segment_ids=[\"segment_ids\"],\n    speaker_id=\"speaker_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 77
      },
      {
        "path": "client.dubbing.resource.render",
        "name": "render",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "ResourceRenderRequestLanguage",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "render_type",
            "type": "RenderType",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "normalize_volume",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DubbingRenderResponseModel",
        "docstring": "Regenerate the output media for a language using the latest Studio state. Please ensure all segments have been dubbed before rendering, otherwise they will be omitted. Renders are generated asynchronously, and to check the status of all renders please use the 'Get Dubbing Resource' endpoint.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage : ResourceRenderRequestLanguage\n    The target language code to render, eg. 'es'. To render the source track use 'original'.\n\nrender_type : RenderType\n    The type of the render. One of ['mp4', 'aac', 'mp3', 'wav', 'aaf', 'tracks_zip', 'clips_zip']\n\nnormalize_volume : typing.Optional[bool]\n    Whether to normalize the volume of the rendered audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDubbingRenderResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.render(\n    dubbing_id=\"dubbing_id\",\n    language=\"original\",\n    render_type=\"mp4\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 258
      },
      {
        "path": "client.dubbing.resource.segment.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentDeleteResponse",
        "docstring": "Deletes a single segment from the dubbing.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_id : str\n    ID of the segment\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentDeleteResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.segment.delete(\n    dubbing_id=\"dubbing_id\",\n    segment_id=\"segment_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/segment/client.py",
        "source_line": 93
      },
      {
        "path": "client.dubbing.resource.segment.update",
        "name": "update",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "start_time",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentUpdateResponse",
        "docstring": "Modifies a single segment with new text and/or start/end times. Will update the values for only a specific language of a segment. Does not automatically regenerate the dub.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_id : str\n    ID of the segment\n\nlanguage : str\n    ID of the language.\n\nstart_time : typing.Optional[float]\n\nend_time : typing.Optional[float]\n\ntext : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentUpdateResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.segment.update(\n    dubbing_id=\"dubbing_id\",\n    segment_id=\"segment_id\",\n    language=\"language\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/segment/client.py",
        "source_line": 30
      },
      {
        "path": "client.dubbing.resource.segment.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Deletes a single segment from the dubbing.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_id : str\n    ID of the segment\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SegmentDeleteResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/segment/raw_client.py",
        "source_line": 104
      },
      {
        "path": "client.dubbing.resource.segment.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "start_time",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Modifies a single segment with new text and/or start/end times. Will update the values for only a specific language of a segment. Does not automatically regenerate the dub.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_id : str\n    ID of the segment\n\nlanguage : str\n    ID of the language.\n\nstart_time : typing.Optional[float]\n\nend_time : typing.Optional[float]\n\ntext : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SegmentUpdateResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/segment/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.dubbing.resource.speaker.create",
        "name": "create",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_stability",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_similarity",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_style",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeakerCreatedResponse",
        "docstring": "Parameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_name : typing.Optional[str]\n    Name to attribute to this speaker.\n\nvoice_id : typing.Optional[str]\n    Either the identifier of a voice from the ElevenLabs voice library, or one of ['track-clone', 'clip-clone'].\n\nvoice_stability : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\n\nvoice_similarity : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nvoice_style : typing.Optional[float]\n    For models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeakerCreatedResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.speaker.create(\n    dubbing_id=\"dubbing_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/client.py",
        "source_line": 112
      },
      {
        "path": "client.dubbing.resource.speaker.find_similar_voices",
        "name": "find_similar_voices",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SimilarVoicesForSpeakerResponse",
        "docstring": "Fetch the top 10 similar voices to a speaker, including the voice IDs, names, descriptions, and, where possible, a sample audio recording.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSimilarVoicesForSpeakerResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.speaker.find_similar_voices(\n    dubbing_id=\"dubbing_id\",\n    speaker_id=\"speaker_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/client.py",
        "source_line": 174
      },
      {
        "path": "client.dubbing.resource.speaker.segment.create",
        "name": "create",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "start_time",
            "type": "float",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "float",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "translations",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentCreateResponse",
        "docstring": "Creates a new segment in dubbing resource with a start and end time for the speaker in every available language. Does not automatically generate transcripts/translations/audio.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nstart_time : float\n\nend_time : float\n\ntext : typing.Optional[str]\n\ntranslations : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentCreateResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.speaker.segment.create(\n    dubbing_id=\"dubbing_id\",\n    speaker_id=\"speaker_id\",\n    start_time=1.1,\n    end_time=1.1,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/segment/client.py",
        "source_line": 29
      },
      {
        "path": "client.dubbing.resource.speaker.segment.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "start_time",
            "type": "float",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "float",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "translations",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Creates a new segment in dubbing resource with a start and end time for the speaker in every available language. Does not automatically generate transcripts/translations/audio.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nstart_time : float\n\nend_time : float\n\ntext : typing.Optional[str]\n\ntranslations : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SegmentCreateResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/segment/raw_client.py",
        "source_line": 24
      },
      {
        "path": "client.dubbing.resource.speaker.update",
        "name": "update",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_stability",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_similarity",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_style",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeakerUpdatedResponse",
        "docstring": "Amend the metadata associated with a speaker, such as their voice. Both voice cloning and using voices from the ElevenLabs library are supported.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nspeaker_name : typing.Optional[str]\n    Name to attribute to this speaker.\n\nvoice_id : typing.Optional[str]\n    Either the identifier of a voice from the ElevenLabs voice library, or one of ['track-clone', 'clip-clone'].\n\nvoice_stability : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\n\nvoice_similarity : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nvoice_style : typing.Optional[float]\n    For models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Languages to apply these changes to. If empty, will apply to all languages.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeakerUpdatedResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.speaker.update(\n    dubbing_id=\"dubbing_id\",\n    speaker_id=\"speaker_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/client.py",
        "source_line": 37
      },
      {
        "path": "client.dubbing.resource.speaker.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_stability",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_similarity",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_style",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Parameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_name : typing.Optional[str]\n    Name to attribute to this speaker.\n\nvoice_id : typing.Optional[str]\n    Either the identifier of a voice from the ElevenLabs voice library, or one of ['track-clone', 'clip-clone'].\n\nvoice_stability : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\n\nvoice_similarity : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nvoice_style : typing.Optional[float]\n    For models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SpeakerCreatedResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/raw_client.py",
        "source_line": 119
      },
      {
        "path": "client.dubbing.resource.speaker.with_raw_response.find_similar_voices",
        "name": "find_similar_voices",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Fetch the top 10 similar voices to a speaker, including the voice IDs, names, descriptions, and, where possible, a sample audio recording.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SimilarVoicesForSpeakerResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/raw_client.py",
        "source_line": 201
      },
      {
        "path": "client.dubbing.resource.speaker.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_stability",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_similarity",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_style",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Amend the metadata associated with a speaker, such as their voice. Both voice cloning and using voices from the ElevenLabs library are supported.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nspeaker_name : typing.Optional[str]\n    Name to attribute to this speaker.\n\nvoice_id : typing.Optional[str]\n    Either the identifier of a voice from the ElevenLabs voice library, or one of ['track-clone', 'clip-clone'].\n\nvoice_stability : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\n\nvoice_similarity : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nvoice_style : typing.Optional[float]\n    For models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Languages to apply these changes to. If empty, will apply to all languages.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SpeakerUpdatedResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/raw_client.py",
        "source_line": 26
      },
      {
        "path": "client.dubbing.resource.transcribe",
        "name": "transcribe",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentTranscriptionResponse",
        "docstring": "Regenerate the transcriptions for the specified segments. Does not automatically regenerate translations or dubs.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Transcribe this specific list of segments.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentTranscriptionResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.transcribe(\n    dubbing_id=\"dubbing_id\",\n    segments=[\"segments\"],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 123
      },
      {
        "path": "client.dubbing.resource.translate",
        "name": "translate",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentTranslationResponse",
        "docstring": "Regenerate the translations for either the entire resource or the specified segments/languages. Will automatically transcribe missing transcriptions. Will not automatically regenerate the dubs.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Translate only this list of segments.\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Translate only these languages for each segment.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentTranslationResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.resource.translate(\n    dubbing_id=\"dubbing_id\",\n    segments=[\"segments\"],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 164
      },
      {
        "path": "client.dubbing.resource.with_raw_response.dub",
        "name": "dub",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Regenerate the dubs for either the entire resource or the specified segments/languages. Will automatically transcribe and translate any missing transcriptions and translations.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Dub only this list of segments.\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Dub only these languages for each segment.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SegmentDubResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 281
      },
      {
        "path": "client.dubbing.resource.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Given a dubbing ID generated from the '/v1/dubbing' endpoint with studio enabled, returns the dubbing resource.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DubbingResource]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 31
      },
      {
        "path": "client.dubbing.resource.with_raw_response.migrate_segments",
        "name": "migrate_segments",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Change the attribution of one or more segments to a different speaker.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_ids : typing.Sequence[str]\n\nspeaker_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SegmentMigrationResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 81
      },
      {
        "path": "client.dubbing.resource.with_raw_response.render",
        "name": "render",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "Union[str, Literal]",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "render_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "normalize_volume",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Regenerate the output media for a language using the latest Studio state. Please ensure all segments have been dubbed before rendering, otherwise they will be omitted. Renders are generated asynchronously, and to check the status of all renders please use the 'Get Dubbing Resource' endpoint.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage : ResourceRenderRequestLanguage\n    The target language code to render, eg. 'es'. To render the source track use 'original'.\n\nrender_type : RenderType\n    The type of the render. One of ['mp4', 'aac', 'mp3', 'wav', 'aaf', 'tracks_zip', 'clips_zip']\n\nnormalize_volume : typing.Optional[bool]\n    Whether to normalize the volume of the rendered audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DubbingRenderResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 350
      },
      {
        "path": "client.dubbing.resource.with_raw_response.transcribe",
        "name": "transcribe",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Regenerate the transcriptions for the specified segments. Does not automatically regenerate translations or dubs.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Transcribe this specific list of segments.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SegmentTranscriptionResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 148
      },
      {
        "path": "client.dubbing.resource.with_raw_response.translate",
        "name": "translate",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Regenerate the translations for either the entire resource or the specified segments/languages. Will automatically transcribe missing transcriptions. Will not automatically regenerate the dubs.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Translate only this list of segments.\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Translate only these languages for each segment.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SegmentTranslationResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 212
      },
      {
        "path": "client.dubbing.transcript.get_transcript_for_dub",
        "name": "get_transcript_for_dub",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language_code",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "format_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Union[DubbingTranscriptResponseModel, str]",
        "docstring": "Returns transcript for the dub as an SRT or WEBVTT file.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage_code : str\n    ID of the language.\n\nformat_type : typing.Optional[TranscriptGetTranscriptForDubRequestFormatType]\n    Format to return transcript in. For subtitles use either 'srt' or 'webvtt', and for a full transcript use 'json'. The 'json' format is not yet supported for Dubbing Studio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nTranscriptGetTranscriptForDubResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.dubbing.transcript.get_transcript_for_dub(\n    dubbing_id=\"dubbing_id\",\n    language_code=\"language_code\",\n    format_type=\"srt\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/transcript/client.py",
        "source_line": 27
      },
      {
        "path": "client.dubbing.transcript.with_raw_response.get_transcript_for_dub",
        "name": "get_transcript_for_dub",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language_code",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "format_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns transcript for the dub as an SRT or WEBVTT file.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage_code : str\n    ID of the language.\n\nformat_type : typing.Optional[TranscriptGetTranscriptForDubRequestFormatType]\n    Format to return transcript in. For subtitles use either 'srt' or 'webvtt', and for a full transcript use 'json'. The 'json' format is not yet supported for Dubbing Studio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[TranscriptGetTranscriptForDubResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/transcript/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.dubbing.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "csv_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "foreground_audio_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "background_audio_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_lang",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_lang",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_accent",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "num_speakers",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "watermark",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "start_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "highest_resolution",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "drop_background_audio",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_profanity_filter",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dubbing_studio",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_voice_cloning",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "csv_fps",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Dubs a provided audio or video file into given language.\n\nParameters\n----------\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\ncsv_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nforeground_audio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nbackground_audio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nname : typing.Optional[str]\n    Name of the dubbing project.\n\nsource_url : typing.Optional[str]\n    URL of the source video/audio file.\n\nsource_lang : typing.Optional[str]\n    Source language. Expects a valid iso639-1 or iso639-3 language code.\n\ntarget_lang : typing.Optional[str]\n    The Target language to dub the content into. Expects a valid iso639-1 or iso639-3 language code.\n\ntarget_accent : typing.Optional[str]\n    [Experimental] An accent to apply when selecting voices from the library and to use to inform translation of the dialect to prefer.\n\nnum_speakers : typing.Optional[int]\n    Number of speakers to use for the dubbing. Set to 0 to automatically detect the number of speakers\n\nwatermark : typing.Optional[bool]\n    Whether to apply watermark to the output video.\n\nstart_time : typing.Optional[int]\n    Start time of the source video/audio file.\n\nend_time : typing.Optional[int]\n    End time of the source video/audio file.\n\nhighest_resolution : typing.Optional[bool]\n    Whether to use the highest resolution available.\n\ndrop_background_audio : typing.Optional[bool]\n    An advanced setting. Whether to drop background audio from the final dub. This can improve dub quality where it's known that audio shouldn't have a background track such as for speeches or monologues.\n\nuse_profanity_filter : typing.Optional[bool]\n    [BETA] Whether transcripts should have profanities censored with the words '[censored]'\n\ndubbing_studio : typing.Optional[bool]\n    Whether to prepare dub for edits in dubbing studio or edits as a dubbing resource.\n\ndisable_voice_cloning : typing.Optional[bool]\n    Instead of using a voice clone in dubbing, use a similar voice from the ElevenLabs Voice Library. Voices used from the library will contribute towards a workspace's custom voices limit, and if there aren't enough available slots the dub will fail. Using this feature requires the caller to have the 'add_voice_from_voice_library' permission on their workspace to access new voices.\n\nmode : typing.Optional[DubbingCreateRequestMode]\n    The mode in which to run this Dubbing job. Defaults to automatic, use manual if specifically providing a CSV transcript to use.\n\ncsv_fps : typing.Optional[float]\n    Frames per second to use when parsing a CSV file for dubbing. If not provided, FPS will be inferred from timecodes.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DoDubbingResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/raw_client.py",
        "source_line": 113
      },
      {
        "path": "client.dubbing.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Deletes a dubbing project.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteDubbingResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/raw_client.py",
        "source_line": 318
      },
      {
        "path": "client.dubbing.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns metadata about a dubbing project, including whether it's still in progress or not\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DubbingMetadataResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/raw_client.py",
        "source_line": 268
      },
      {
        "path": "client.dubbing.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dubbing_status",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "filter_by_creator",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "order_by",
            "type": "Optional[Literal]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "order_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "List the dubs you have access to.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many dubs to return at maximum. Can not exceed 200, defaults to 100.\n\ndubbing_status : typing.Optional[DubbingListRequestDubbingStatus]\n    What state the dub is currently in.\n\nfilter_by_creator : typing.Optional[DubbingListRequestFilterByCreator]\n    Filters who created the resources being listed, whether it was the user running the request or someone else that shared the resource with them.\n\norder_by : typing.Optional[typing.Literal[\"created_at\"]]\n    The field to use for ordering results from this query.\n\norder_direction : typing.Optional[DubbingListRequestOrderDirection]\n    The order direction to use for results from this query.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DubbingMetadataPageResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/raw_client.py",
        "source_line": 32
      },
      {
        "path": "client.forced_alignment.create",
        "name": "create",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enabled_spooled_file",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ForcedAlignmentResponseModel",
        "docstring": "Force align an audio file to text. Use this endpoint to get the timing information for each character and word in an audio file based on a provided text transcript.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\ntext : str\n    The text to align with the audio. The input text can be in any format, however diarization is not supported at this time.\n\nenabled_spooled_file : typing.Optional[bool]\n    If true, the file will be streamed to the server and processed in chunks. This is useful for large files that cannot be loaded into memory. The default is false.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nForcedAlignmentResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.forced_alignment.create(\n    text=\"text\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/forced_alignment/client.py",
        "source_line": 30
      },
      {
        "path": "client.forced_alignment.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enabled_spooled_file",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Force align an audio file to text. Use this endpoint to get the timing information for each character and word in an audio file based on a provided text transcript.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\ntext : str\n    The text to align with the audio. The input text can be in any format, however diarization is not supported at this time.\n\nenabled_spooled_file : typing.Optional[bool]\n    If true, the file will be streamed to the server and processed in chunks. This is useful for large files that cannot be loaded into memory. The default is false.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ForcedAlignmentResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/forced_alignment/raw_client.py",
        "source_line": 24
      },
      {
        "path": "client.history.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteHistoryItemResponse",
        "docstring": "Delete a history item by its ID\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteHistoryItemResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.history.delete(\n    history_item_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 153
      },
      {
        "path": "client.history.download",
        "name": "download",
        "parameters": [
          {
            "name": "history_item_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Download one or more history items. If one history item ID is provided, we will return a single audio file. If more than one history item IDs are provided, we will provide the history items packed into a .zip file.\n\nParameters\n----------\nhistory_item_ids : typing.Sequence[str]\n    A list of history items to download, you can get IDs of history items and other metadata using the GET https://api.elevenlabs.io/v1/history endpoint.\n\noutput_format : typing.Optional[str]\n    Output format to transcode the audio file, can be wav or default.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The requested audio file, or a zip file containing multiple audio files when multiple history items are requested.\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.history.download(\n    history_item_ids=[\"history_item_ids\", \"history_item_ids\"],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 219
      },
      {
        "path": "client.history.get",
        "name": "get",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeechHistoryItemResponse",
        "docstring": "Retrieves a history item.\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeechHistoryItemResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.history.get(\n    history_item_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 120
      },
      {
        "path": "client.history.get_audio",
        "name": "get_audio",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Returns the audio of an history item.\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The audio file of the history item.\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.history.get_audio(\n    history_item_id=\"history_item_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 186
      },
      {
        "path": "client.history.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "start_after_history_item_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "date_before_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "date_after_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetSpeechHistoryResponse",
        "docstring": "Returns a list of your generated audio.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many history items to return at maximum. Can not exceed 1000, defaults to 100.\n\nstart_after_history_item_id : typing.Optional[str]\n    After which ID to start fetching, use this parameter to paginate across a large collection of history items. In case this parameter is not provided history items will be fetched starting from the most recently created one ordered descending by their creation date.\n\nvoice_id : typing.Optional[str]\n    ID of the voice to be filtered for. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nmodel_id : typing.Optional[str]\n    Search term used for filtering history items. If provided, source becomes required.\n\ndate_before_unix : typing.Optional[int]\n    Unix timestamp to filter history items before this date (exclusive).\n\ndate_after_unix : typing.Optional[int]\n    Unix timestamp to filter history items after this date (inclusive).\n\nsort_direction : typing.Optional[HistoryListRequestSortDirection]\n    Sort direction for the results.\n\nsearch : typing.Optional[str]\n    search term used for filtering\n\nsource : typing.Optional[HistoryListRequestSource]\n    Source of the generated history item\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetSpeechHistoryResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.history.list(\n    page_size=1,\n    start_after_history_item_id=\"start_after_history_item_id\",\n    voice_id=\"voice_id\",\n    model_id=\"model_id\",\n    date_before_unix=1,\n    date_after_unix=1,\n    sort_direction=\"asc\",\n    search=\"search\",\n    source=\"TTS\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 33
      },
      {
        "path": "client.history.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete a history item by its ID\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteHistoryItemResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/raw_client.py",
        "source_line": 177
      },
      {
        "path": "client.history.with_raw_response.download",
        "name": "download",
        "parameters": [
          {
            "name": "history_item_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Download one or more history items. If one history item ID is provided, we will return a single audio file. If more than one history item IDs are provided, we will provide the history items packed into a .zip file.\n\nParameters\n----------\nhistory_item_ids : typing.Sequence[str]\n    A list of history items to download, you can get IDs of history items and other metadata using the GET https://api.elevenlabs.io/v1/history endpoint.\n\noutput_format : typing.Optional[str]\n    Output format to transcode the audio file, can be wav or default.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The requested audio file, or a zip file containing multiple audio files when multiple history items are requested.",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 281
      },
      {
        "path": "client.history.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieves a history item.\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SpeechHistoryItemResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/raw_client.py",
        "source_line": 127
      },
      {
        "path": "client.history.with_raw_response.get_audio",
        "name": "get_audio",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Returns the audio of an history item.\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The audio file of the history item.",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 227
      },
      {
        "path": "client.history.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "start_after_history_item_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "date_before_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "date_after_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns a list of your generated audio.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many history items to return at maximum. Can not exceed 1000, defaults to 100.\n\nstart_after_history_item_id : typing.Optional[str]\n    After which ID to start fetching, use this parameter to paginate across a large collection of history items. In case this parameter is not provided history items will be fetched starting from the most recently created one ordered descending by their creation date.\n\nvoice_id : typing.Optional[str]\n    ID of the voice to be filtered for. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nmodel_id : typing.Optional[str]\n    Search term used for filtering history items. If provided, source becomes required.\n\ndate_before_unix : typing.Optional[int]\n    Unix timestamp to filter history items before this date (exclusive).\n\ndate_after_unix : typing.Optional[int]\n    Unix timestamp to filter history items after this date (inclusive).\n\nsort_direction : typing.Optional[HistoryListRequestSortDirection]\n    Sort direction for the results.\n\nsearch : typing.Optional[str]\n    search term used for filtering\n\nsource : typing.Optional[HistoryListRequestSource]\n    Source of the generated history item\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetSpeechHistoryResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/raw_client.py",
        "source_line": 31
      },
      {
        "path": "client.models.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "List[Model]",
        "docstring": "Gets a list of available models.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.List[Model]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.models.list()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/models/client.py",
        "source_line": 26
      },
      {
        "path": "client.models.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets a list of available models.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.List[Model]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/models/raw_client.py",
        "source_line": 20
      },
      {
        "path": "client.music.compose",
        "name": "compose",
        "parameters": [
          {
            "name": "output_format",
            "type": "Optional[MusicComposeRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal['music_v1']]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "respect_sections_durations",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator[bytes]",
        "docstring": "Compose a song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicComposeRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nrespect_sections_durations : typing.Optional[bool]\n    Controls how strictly section durations in the `composition_plan` are enforced. Only used with `composition_plan`. When set to true, the model will precisely respect each section's `duration_ms` from the plan. When set to false, the model may adjust individual section durations which will generally lead to better generation quality and improved latency, while always preserving the total song duration from the plan.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The generated audio file in the format specified\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.music.compose()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/client.py",
        "source_line": 41
      },
      {
        "path": "client.music.compose_detailed",
        "name": "compose_detailed",
        "parameters": [
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "MultipartResponse",
        "docstring": "Compose a song from a prompt or a composition plan with detailed response parsing.\nThis method calls the original compose_detailed and then parses the stream response.\n\nReturns a MultipartResponse containing parsed JSON metadata, audio bytes, and filename.",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music_custom.py",
        "source_line": 41
      },
      {
        "path": "client.music.composition_plan.create",
        "name": "create",
        "parameters": [
          {
            "name": "prompt",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "MusicPrompt",
        "docstring": "Create a composition plan for music generation. Usage of this endpoint does not cost any credits but is subject to rate limiting depending on your tier.\n\nParameters\n----------\nprompt : str\n    A simple text prompt to compose a plan from.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the composition plan to generate in milliseconds. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nsource_composition_plan : typing.Optional[MusicPrompt]\n    An optional composition plan to use as a source for the new composition plan.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMusicPrompt\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.music.composition_plan.create(\n    prompt=\"prompt\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/composition_plan/client.py",
        "source_line": 29
      },
      {
        "path": "client.music.composition_plan.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "prompt",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a composition plan for music generation. Usage of this endpoint does not cost any credits but is subject to rate limiting depending on your tier.\n\nParameters\n----------\nprompt : str\n    A simple text prompt to compose a plan from.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the composition plan to generate in milliseconds. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nsource_composition_plan : typing.Optional[MusicPrompt]\n    An optional composition plan to use as a source for the new composition plan.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[MusicPrompt]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/composition_plan/raw_client.py",
        "source_line": 24
      },
      {
        "path": "client.music.separate_stems",
        "name": "separate_stems",
        "parameters": [
          {
            "name": "file",
            "type": "core.File",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[MusicSeparateStemsRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stem_variation_id",
            "type": "Optional[MusicSeparateStemsRequestStemVariationId]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator[bytes]",
        "docstring": "Separate an audio file into individual stems. This endpoint might have high latency, depending on the length of the audio file.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\noutput_format : typing.Optional[MusicSeparateStemsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nstem_variation_id : typing.Optional[MusicSeparateStemsRequestStemVariationId]\n    The id of the stem variation to use.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    ZIP archive containing separated audio stems. Each stem is provided as a separate audio file in the requested output format.",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/client.py",
        "source_line": 262
      },
      {
        "path": "client.music.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "output_format",
            "type": "Optional[MusicStreamRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal['music_v1']]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator[bytes]",
        "docstring": "Stream a composed song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Streaming audio data in the format specified\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.music.stream()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/client.py",
        "source_line": 195
      },
      {
        "path": "client.music.with_raw_response.compose",
        "name": "compose",
        "parameters": [
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "respect_sections_durations",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Compose a song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicComposeRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nrespect_sections_durations : typing.Optional[bool]\n    Controls how strictly section durations in the `composition_plan` are enforced. Only used with `composition_plan`. When set to true, the model will precisely respect each section's `duration_ms` from the plan. When set to false, the model may adjust individual section durations which will generally lead to better generation quality and improved latency, while always preserving the total song duration from the plan.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The generated audio file in the format specified",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 31
      },
      {
        "path": "client.music.with_raw_response.compose_detailed",
        "name": "compose_detailed",
        "parameters": [
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "with_timestamps",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Compose a song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicComposeDetailedRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nwith_timestamps : typing.Optional[bool]\n    Whether to return the timestamps of the words in the generated song.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Multipart/mixed response with JSON metadata and binary audio file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 139
      },
      {
        "path": "client.music.with_raw_response.separate_stems",
        "name": "separate_stems",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stem_variation_id",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Separate an audio file into individual stems. This endpoint might have high latency, depending on the length of the audio file.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\noutput_format : typing.Optional[MusicSeparateStemsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nstem_variation_id : typing.Optional[MusicSeparateStemsRequestStemVariationId]\n    The id of the stem variation to use.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    ZIP archive containing separated audio stems. Each stem is provided as a separate audio file in the requested output format.",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 345
      },
      {
        "path": "client.music.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream a composed song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Streaming audio data in the format specified",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 247
      },
      {
        "path": "client.pronunciation_dictionaries.create_from_file",
        "name": "create_from_file",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_access",
            "type": "Optional[PronunciationDictionariesCreateFromFileRequestWorkspaceAccess]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddPronunciationDictionaryResponseModel",
        "docstring": "Creates a new pronunciation dictionary from a lexicon .PLS file\n\nParameters\n----------\nname : str\n    The name of the pronunciation dictionary, used for identification only.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\ndescription : typing.Optional[str]\n    A description of the pronunciation dictionary, used for identification only.\n\nworkspace_access : typing.Optional[PronunciationDictionariesCreateFromFileRequestWorkspaceAccess]\n    Should be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddPronunciationDictionaryResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.pronunciation_dictionaries.create_from_file(\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 50
      },
      {
        "path": "client.pronunciation_dictionaries.create_from_rules",
        "name": "create_from_rules",
        "parameters": [
          {
            "name": "rules",
            "type": "Sequence[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_access",
            "type": "Optional[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostWorkspaceAccess]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddPronunciationDictionaryResponseModel",
        "docstring": "Creates a new pronunciation dictionary from provided rules.\n\nParameters\n----------\nrules : typing.Sequence[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem]\n    List of pronunciation rules. Rule can be either:\n        an alias rule: {'string_to_replace': 'a', 'type': 'alias', 'alias': 'b', }\n        or a phoneme rule: {'string_to_replace': 'a', 'type': 'phoneme', 'phoneme': 'b', 'alphabet': 'ipa' }\n\nname : str\n    The name of the pronunciation dictionary, used for identification only.\n\ndescription : typing.Optional[str]\n    A description of the pronunciation dictionary, used for identification only.\n\nworkspace_access : typing.Optional[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostWorkspaceAccess]\n    Should be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddPronunciationDictionaryResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\nfrom elevenlabs.pronunciation_dictionaries import (\n    BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem_Alias,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.pronunciation_dictionaries.create_from_rules(\n    rules=[\n        BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem_Alias(\n            string_to_replace=\"Thailand\",\n            alias=\"tie-land\",\n        )\n    ],\n    name=\"My Dictionary\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 104
      },
      {
        "path": "client.pronunciation_dictionaries.download",
        "name": "download",
        "parameters": [
          {
            "name": "dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "version_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator[bytes]",
        "docstring": "Get a PLS file with a pronunciation dictionary version rules\n\nParameters\n----------\ndictionary_id : str\n    The id of the pronunciation dictionary\n\nversion_id : str\n    The id of the pronunciation dictionary version\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The PLS file containing pronunciation dictionary rules\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.pronunciation_dictionaries.download(\n    dictionary_id=\"dictionary_id\",\n    version_id=\"version_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 250
      },
      {
        "path": "client.pronunciation_dictionaries.get",
        "name": "get",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetPronunciationDictionaryMetadataResponse",
        "docstring": "Get metadata for a pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetPronunciationDictionaryMetadataResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.pronunciation_dictionaries.get(\n    pronunciation_dictionary_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 171
      },
      {
        "path": "client.pronunciation_dictionaries.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[PronunciationDictionariesListRequestSort]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetPronunciationDictionariesMetadataResponseModel",
        "docstring": "Get a list of the pronunciation dictionaries you have access to and their metadata\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many pronunciation dictionaries to return at maximum. Can not exceed 100, defaults to 30.\n\nsort : typing.Optional[PronunciationDictionariesListRequestSort]\n    Which field to sort by, one of 'created_at_unix' or 'name'.\n\nsort_direction : typing.Optional[str]\n    Which direction to sort the voices in. 'ascending' or 'descending'.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetPronunciationDictionariesMetadataResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.pronunciation_dictionaries.list(\n    cursor=\"cursor\",\n    page_size=1,\n    sort=\"creation_time_unix\",\n    sort_direction=\"sort_direction\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 287
      },
      {
        "path": "client.pronunciation_dictionaries.rules.add",
        "name": "add",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rules",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PronunciationDictionaryRulesResponseModel",
        "docstring": "Add rules to the pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrules : typing.Sequence[PronunciationDictionaryRule]\n    List of pronunciation rules. Rule can be either:\n        an alias rule: {'string_to_replace': 'a', 'type': 'alias', 'alias': 'b', }\n        or a phoneme rule: {'string_to_replace': 'a', 'type': 'phoneme', 'phoneme': 'b', 'alphabet': 'ipa' }\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPronunciationDictionaryRulesResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\nfrom elevenlabs.pronunciation_dictionaries.rules import (\n    PronunciationDictionaryRule_Alias,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.pronunciation_dictionaries.rules.add(\n    pronunciation_dictionary_id=\"21m00Tcm4TlvDq8ikWAM\",\n    rules=[\n        PronunciationDictionaryRule_Alias(\n            string_to_replace=\"Thailand\",\n            alias=\"tie-land\",\n        )\n    ],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/rules/client.py",
        "source_line": 30
      },
      {
        "path": "client.pronunciation_dictionaries.rules.remove",
        "name": "remove",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rule_strings",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PronunciationDictionaryRulesResponseModel",
        "docstring": "Remove rules from the pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrule_strings : typing.Sequence[str]\n    List of strings to remove from the pronunciation dictionary.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPronunciationDictionaryRulesResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.pronunciation_dictionaries.rules.remove(\n    pronunciation_dictionary_id=\"21m00Tcm4TlvDq8ikWAM\",\n    rule_strings=[\"rule_strings\"],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/rules/client.py",
        "source_line": 81
      },
      {
        "path": "client.pronunciation_dictionaries.rules.with_raw_response.add",
        "name": "add",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rules",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Add rules to the pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrules : typing.Sequence[PronunciationDictionaryRule]\n    List of pronunciation rules. Rule can be either:\n        an alias rule: {'string_to_replace': 'a', 'type': 'alias', 'alias': 'b', }\n        or a phoneme rule: {'string_to_replace': 'a', 'type': 'phoneme', 'phoneme': 'b', 'alphabet': 'ipa' }\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PronunciationDictionaryRulesResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/rules/raw_client.py",
        "source_line": 26
      },
      {
        "path": "client.pronunciation_dictionaries.rules.with_raw_response.remove",
        "name": "remove",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rule_strings",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Remove rules from the pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrule_strings : typing.Sequence[str]\n    List of strings to remove from the pronunciation dictionary.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PronunciationDictionaryRulesResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/rules/raw_client.py",
        "source_line": 94
      },
      {
        "path": "client.pronunciation_dictionaries.update",
        "name": "update",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "archived",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetPronunciationDictionaryMetadataResponse",
        "docstring": "Partially update the pronunciation dictionary without changing the version\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\narchived : typing.Optional[bool]\n    The name of the pronunciation dictionary, used for identification only.\n\nname : typing.Optional[str]\n    The name of the pronunciation dictionary, used for identification only.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetPronunciationDictionaryMetadataResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.pronunciation_dictionaries.update(\n    pronunciation_dictionary_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 204
      },
      {
        "path": "client.pronunciation_dictionaries.with_raw_response.create_from_file",
        "name": "create_from_file",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_access",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Creates a new pronunciation dictionary from a lexicon .PLS file\n\nParameters\n----------\nname : str\n    The name of the pronunciation dictionary, used for identification only.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\ndescription : typing.Optional[str]\n    A description of the pronunciation dictionary, used for identification only.\n\nworkspace_access : typing.Optional[PronunciationDictionariesCreateFromFileRequestWorkspaceAccess]\n    Should be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddPronunciationDictionaryResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 41
      },
      {
        "path": "client.pronunciation_dictionaries.with_raw_response.create_from_rules",
        "name": "create_from_rules",
        "parameters": [
          {
            "name": "rules",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_access",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Creates a new pronunciation dictionary from provided rules.\n\nParameters\n----------\nrules : typing.Sequence[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem]\n    List of pronunciation rules. Rule can be either:\n        an alias rule: {'string_to_replace': 'a', 'type': 'alias', 'alias': 'b', }\n        or a phoneme rule: {'string_to_replace': 'a', 'type': 'phoneme', 'phoneme': 'b', 'alphabet': 'ipa' }\n\nname : str\n    The name of the pronunciation dictionary, used for identification only.\n\ndescription : typing.Optional[str]\n    A description of the pronunciation dictionary, used for identification only.\n\nworkspace_access : typing.Optional[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostWorkspaceAccess]\n    Should be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddPronunciationDictionaryResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 116
      },
      {
        "path": "client.pronunciation_dictionaries.with_raw_response.download",
        "name": "download",
        "parameters": [
          {
            "name": "dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "version_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Get a PLS file with a pronunciation dictionary version rules\n\nParameters\n----------\ndictionary_id : str\n    The id of the pronunciation dictionary\n\nversion_id : str\n    The id of the pronunciation dictionary version\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The PLS file containing pronunciation dictionary rules",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 320
      },
      {
        "path": "client.pronunciation_dictionaries.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get metadata for a pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetPronunciationDictionaryMetadataResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 201
      },
      {
        "path": "client.pronunciation_dictionaries.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get a list of the pronunciation dictionaries you have access to and their metadata\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many pronunciation dictionaries to return at maximum. Can not exceed 100, defaults to 30.\n\nsort : typing.Optional[PronunciationDictionariesListRequestSort]\n    Which field to sort by, one of 'created_at_unix' or 'name'.\n\nsort_direction : typing.Optional[str]\n    Which direction to sort the voices in. 'ascending' or 'descending'.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetPronunciationDictionariesMetadataResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 377
      },
      {
        "path": "client.pronunciation_dictionaries.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "archived",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Partially update the pronunciation dictionary without changing the version\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\narchived : typing.Optional[bool]\n    The name of the pronunciation dictionary, used for identification only.\n\nname : typing.Optional[str]\n    The name of the pronunciation dictionary, used for identification only.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetPronunciationDictionaryMetadataResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 251
      },
      {
        "path": "client.samples.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteSampleResponse",
        "docstring": "Removes a sample by its ID.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nsample_id : str\n    ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteSampleResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.samples.delete(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/samples/client.py",
        "source_line": 26
      },
      {
        "path": "client.samples.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Removes a sample by its ID.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nsample_id : str\n    ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteSampleResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/samples/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.save_a_voice_preview",
        "name": "save_a_voice_preview",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "None",
        "docstring": "Add a generated voice to the voice library.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.save_a_voice_preview()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/base_client.py",
        "source_line": 142
      },
      {
        "path": "client.service_accounts.api_keys.create",
        "name": "create",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "permissions",
            "type": "Union[List[Union[Literal, Any]], Literal]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "character_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceCreateApiKeyResponseModel",
        "docstring": "Create a new API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\nname : str\n\npermissions : BodyCreateServiceAccountApiKeyV1ServiceAccountsServiceAccountUserIdApiKeysPostPermissions\n    The permissions of the XI API.\n\ncharacter_limit : typing.Optional[int]\n    The character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceCreateApiKeyResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.service_accounts.api_keys.create(\n    service_account_user_id=\"service_account_user_id\",\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/client.py",
        "source_line": 68
      },
      {
        "path": "client.service_accounts.api_keys.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "api_key_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete an existing API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\napi_key_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.service_accounts.api_keys.delete(\n    service_account_user_id=\"service_account_user_id\",\n    api_key_id=\"api_key_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/client.py",
        "source_line": 121
      },
      {
        "path": "client.service_accounts.api_keys.list",
        "name": "list",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceApiKeyListResponseModel",
        "docstring": "Get all API keys for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceApiKeyListResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.service_accounts.api_keys.list(\n    service_account_user_id=\"service_account_user_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/client.py",
        "source_line": 36
      },
      {
        "path": "client.service_accounts.api_keys.update",
        "name": "update",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "api_key_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "is_enabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "permissions",
            "type": "Union[List[Union[Literal, Any]], Literal]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "character_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Update an existing API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\napi_key_id : str\n\nis_enabled : bool\n    Whether to enable or disable the API key.\n\nname : str\n    The name of the XI API key to use (used for identification purposes only).\n\npermissions : BodyEditServiceAccountApiKeyV1ServiceAccountsServiceAccountUserIdApiKeysApiKeyIdPatchPermissions\n    The permissions of the XI API.\n\ncharacter_limit : typing.Optional[int]\n    The character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.service_accounts.api_keys.update(\n    service_account_user_id=\"service_account_user_id\",\n    api_key_id=\"api_key_id\",\n    is_enabled=True,\n    name=\"Sneaky Fox\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/client.py",
        "source_line": 156
      },
      {
        "path": "client.service_accounts.api_keys.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "permissions",
            "type": "Union[List[Union[Literal, Any]], Literal]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "character_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a new API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\nname : str\n\npermissions : BodyCreateServiceAccountApiKeyV1ServiceAccountsServiceAccountUserIdApiKeysPostPermissions\n    The permissions of the XI API.\n\ncharacter_limit : typing.Optional[int]\n    The character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[WorkspaceCreateApiKeyResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/raw_client.py",
        "source_line": 81
      },
      {
        "path": "client.service_accounts.api_keys.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "api_key_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete an existing API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\napi_key_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/raw_client.py",
        "source_line": 157
      },
      {
        "path": "client.service_accounts.api_keys.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get all API keys for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[WorkspaceApiKeyListResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/raw_client.py",
        "source_line": 32
      },
      {
        "path": "client.service_accounts.api_keys.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "api_key_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "is_enabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "permissions",
            "type": "Union[List[Union[Literal, Any]], Literal]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "character_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update an existing API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\napi_key_id : str\n\nis_enabled : bool\n    Whether to enable or disable the API key.\n\nname : str\n    The name of the XI API key to use (used for identification purposes only).\n\npermissions : BodyEditServiceAccountApiKeyV1ServiceAccountsServiceAccountUserIdApiKeysApiKeyIdPatchPermissions\n    The permissions of the XI API.\n\ncharacter_limit : typing.Optional[int]\n    The character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/raw_client.py",
        "source_line": 210
      },
      {
        "path": "client.service_accounts.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceServiceAccountListResponseModel",
        "docstring": "List all service accounts in the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceServiceAccountListResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.service_accounts.list()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/client.py",
        "source_line": 33
      },
      {
        "path": "client.service_accounts.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "List all service accounts in the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[WorkspaceServiceAccountListResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/raw_client.py",
        "source_line": 20
      },
      {
        "path": "client.speech_to_speech.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Transform audio from one voice to another. Maintain full control over emotion, timing and delivery.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\naudio : core.File\n    See core.File for more documentation\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[SpeechToSpeechConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\n\nvoice_settings : typing.Optional[str]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nremove_background_noise : typing.Optional[bool]\n    If set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\n\nfile_format : typing.Optional[SpeechToSpeechConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The generated audio file\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.speech_to_speech.convert(\n    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n    output_format=\"mp3_44100_128\",\n    model_id=\"eleven_multilingual_sts_v2\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_speech/client.py",
        "source_line": 33
      },
      {
        "path": "client.speech_to_speech.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream audio from one voice to another. Maintain full control over emotion, timing and delivery.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\naudio : core.File\n    See core.File for more documentation\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[SpeechToSpeechStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\n\nvoice_settings : typing.Optional[str]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nremove_background_noise : typing.Optional[bool]\n    If set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\n\nfile_format : typing.Optional[SpeechToSpeechStreamRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.speech_to_speech.stream(\n    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n    output_format=\"mp3_44100_128\",\n    model_id=\"eleven_multilingual_sts_v2\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_speech/client.py",
        "source_line": 126
      },
      {
        "path": "client.speech_to_speech.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Transform audio from one voice to another. Maintain full control over emotion, timing and delivery.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\naudio : core.File\n    See core.File for more documentation\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[SpeechToSpeechConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\n\nvoice_settings : typing.Optional[str]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nremove_background_noise : typing.Optional[bool]\n    If set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\n\nfile_format : typing.Optional[SpeechToSpeechConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The generated audio file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 29
      },
      {
        "path": "client.speech_to_speech.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream audio from one voice to another. Maintain full control over emotion, timing and delivery.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\naudio : core.File\n    See core.File for more documentation\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[SpeechToSpeechStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\n\nvoice_settings : typing.Optional[str]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nremove_background_noise : typing.Optional[bool]\n    If set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\n\nfile_format : typing.Optional[SpeechToSpeechStreamRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 146
      },
      {
        "path": "client.speech_to_text.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "model_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tag_audio_events",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "num_speakers",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "timestamps_granularity",
            "type": "Optional[SpeechToTextConvertRequestTimestampsGranularity]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "diarize",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "diarization_threshold",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "additional_formats",
            "type": "Optional[AdditionalFormats]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Optional[SpeechToTextConvertRequestFileFormat]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cloud_storage_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "temperature",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_multi_channel",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook_metadata",
            "type": "Optional[SpeechToTextConvertRequestWebhookMetadata]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeechToTextConvertResponse",
        "docstring": "Transcribe an audio or video file. If webhook is set to true, the request will be processed asynchronously and results sent to configured webhooks. When use_multi_channel is true and the provided audio has multiple channels, a 'transcripts' object with separate transcripts for each channel is returned. Otherwise, returns a single transcript. The optional webhook_metadata parameter allows you to attach custom data that will be included in webhook responses for request correlation and tracking.\n\nParameters\n----------\nmodel_id : str\n    The ID of the model to use for transcription, currently only 'scribe_v1' and 'scribe_v1_experimental' are available.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean log and transcript storage features are unavailable for this request. Zero retention mode may only be used by enterprise customers.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nlanguage_code : typing.Optional[str]\n    An ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file. Can sometimes improve transcription performance if known beforehand. Defaults to null, in this case the language is predicted automatically.\n\ntag_audio_events : typing.Optional[bool]\n    Whether to tag audio events like (laughter), (footsteps), etc. in the transcription.\n\nnum_speakers : typing.Optional[int]\n    The maximum amount of speakers talking in the uploaded file. Can help with predicting who speaks when. The maximum amount of speakers that can be predicted is 32. Defaults to null, in this case the amount of speakers is set to the maximum value the model supports.\n\ntimestamps_granularity : typing.Optional[SpeechToTextConvertRequestTimestampsGranularity]\n    The granularity of the timestamps in the transcription. 'word' provides word-level timestamps and 'character' provides character-level timestamps per word.\n\ndiarize : typing.Optional[bool]\n    Whether to annotate which speaker is currently talking in the uploaded file.\n\ndiarization_threshold : typing.Optional[float]\n    Diarization threshold to apply during speaker diarization. A higher value means there will be a lower chance of one speaker being diarized as two different speakers but also a higher chance of two different speakers being diarized as one speaker (less total speakers predicted). A low value means there will be a higher chance of one speaker being diarized as two different speakers but also a lower chance of two different speakers being diarized as one speaker (more total speakers predicted). Can only be set when diarize=True and num_speakers=None. Defaults to None, in which case we will choose a threshold based on the model_id (0.22 usually).\n\nadditional_formats : typing.Optional[AdditionalFormats]\n    A list of additional formats to export the transcript to.\n\nfile_format : typing.Optional[SpeechToTextConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\ncloud_storage_url : typing.Optional[str]\n    The HTTPS URL of the file to transcribe. Exactly one of the file or cloud_storage_url parameters must be provided. The file must be accessible via HTTPS and the file size must be less than 2GB. Any valid HTTPS URL is accepted, including URLs from cloud storage providers (AWS S3, Google Cloud Storage, Cloudflare R2, etc.), CDNs, or any other HTTPS source. URLs can be pre-signed or include authentication tokens in query parameters.\n\nwebhook : typing.Optional[bool]\n    Whether to send the transcription result to configured speech-to-text webhooks.  If set the request will return early without the transcription, which will be delivered later via webhook.\n\nwebhook_id : typing.Optional[str]\n    Optional specific webhook ID to send the transcription result to. Only valid when webhook is set to true. If not provided, transcription will be sent to all configured speech-to-text webhooks.\n\ntemperature : typing.Optional[float]\n    Controls the randomness of the transcription output. Accepts values between 0.0 and 2.0, where higher values result in more diverse and less deterministic results. If omitted, we will use a temperature based on the model you selected which is usually 0.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be an integer between 0 and 2147483647.\n\nuse_multi_channel : typing.Optional[bool]\n    Whether the audio file contains multiple channels where each channel contains a single speaker. When enabled, each channel will be transcribed independently and the results will be combined. Each word in the response will include a 'channel_index' field indicating which channel it was spoken on. A maximum of 5 channels is supported.\n\nwebhook_metadata : typing.Optional[SpeechToTextConvertRequestWebhookMetadata]\n    Optional metadata to be included in the webhook response. This should be a JSON string representing an object with a maximum depth of 2 levels and maximum size of 16KB. Useful for tracking internal IDs, job references, or other contextual information.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeechToTextConvertResponse\n    Synchronous transcription result\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.speech_to_text.convert(\n    enable_logging=True,\n    model_id=\"model_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/client.py",
        "source_line": 40
      },
      {
        "path": "client.speech_to_text.transcripts.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "transcription_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a previously generated transcript by its ID.\n\nParameters\n----------\ntranscription_id : str\n    The unique ID of the transcript to delete\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Delete completed successfully.\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.speech_to_text.transcripts.delete(\n    transcription_id=\"transcription_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/transcripts/client.py",
        "source_line": 59
      },
      {
        "path": "client.speech_to_text.transcripts.get",
        "name": "get",
        "parameters": [
          {
            "name": "transcription_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Union[SpeechToTextChunkResponseModel, MultichannelSpeechToTextResponseModel]",
        "docstring": "Retrieve a previously generated transcript by its ID.\n\nParameters\n----------\ntranscription_id : str\n    The unique ID of the transcript to retrieve\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nTranscriptsGetResponse\n    The transcript data\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.speech_to_text.transcripts.get(\n    transcription_id=\"transcription_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/transcripts/client.py",
        "source_line": 26
      },
      {
        "path": "client.speech_to_text.transcripts.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "transcription_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete a previously generated transcript by its ID.\n\nParameters\n----------\ntranscription_id : str\n    The unique ID of the transcript to delete\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Delete completed successfully.",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/transcripts/raw_client.py",
        "source_line": 95
      },
      {
        "path": "client.speech_to_text.transcripts.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "transcription_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve a previously generated transcript by its ID.\n\nParameters\n----------\ntranscription_id : str\n    The unique ID of the transcript to retrieve\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[TranscriptsGetResponse]\n    The transcript data",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/transcripts/raw_client.py",
        "source_line": 23
      },
      {
        "path": "client.speech_to_text.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "model_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tag_audio_events",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "num_speakers",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "timestamps_granularity",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "diarize",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "diarization_threshold",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "additional_formats",
            "type": "Optional[List[Annotated]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cloud_storage_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "temperature",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_multi_channel",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook_metadata",
            "type": "Union[str, Dict[str, Any], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Transcribe an audio or video file. If webhook is set to true, the request will be processed asynchronously and results sent to configured webhooks. When use_multi_channel is true and the provided audio has multiple channels, a 'transcripts' object with separate transcripts for each channel is returned. Otherwise, returns a single transcript. The optional webhook_metadata parameter allows you to attach custom data that will be included in webhook responses for request correlation and tracking.\n\nParameters\n----------\nmodel_id : str\n    The ID of the model to use for transcription, currently only 'scribe_v1' and 'scribe_v1_experimental' are available.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean log and transcript storage features are unavailable for this request. Zero retention mode may only be used by enterprise customers.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nlanguage_code : typing.Optional[str]\n    An ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file. Can sometimes improve transcription performance if known beforehand. Defaults to null, in this case the language is predicted automatically.\n\ntag_audio_events : typing.Optional[bool]\n    Whether to tag audio events like (laughter), (footsteps), etc. in the transcription.\n\nnum_speakers : typing.Optional[int]\n    The maximum amount of speakers talking in the uploaded file. Can help with predicting who speaks when. The maximum amount of speakers that can be predicted is 32. Defaults to null, in this case the amount of speakers is set to the maximum value the model supports.\n\ntimestamps_granularity : typing.Optional[SpeechToTextConvertRequestTimestampsGranularity]\n    The granularity of the timestamps in the transcription. 'word' provides word-level timestamps and 'character' provides character-level timestamps per word.\n\ndiarize : typing.Optional[bool]\n    Whether to annotate which speaker is currently talking in the uploaded file.\n\ndiarization_threshold : typing.Optional[float]\n    Diarization threshold to apply during speaker diarization. A higher value means there will be a lower chance of one speaker being diarized as two different speakers but also a higher chance of two different speakers being diarized as one speaker (less total speakers predicted). A low value means there will be a higher chance of one speaker being diarized as two different speakers but also a lower chance of two different speakers being diarized as one speaker (more total speakers predicted). Can only be set when diarize=True and num_speakers=None. Defaults to None, in which case we will choose a threshold based on the model_id (0.22 usually).\n\nadditional_formats : typing.Optional[AdditionalFormats]\n    A list of additional formats to export the transcript to.\n\nfile_format : typing.Optional[SpeechToTextConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\ncloud_storage_url : typing.Optional[str]\n    The HTTPS URL of the file to transcribe. Exactly one of the file or cloud_storage_url parameters must be provided. The file must be accessible via HTTPS and the file size must be less than 2GB. Any valid HTTPS URL is accepted, including URLs from cloud storage providers (AWS S3, Google Cloud Storage, Cloudflare R2, etc.), CDNs, or any other HTTPS source. URLs can be pre-signed or include authentication tokens in query parameters.\n\nwebhook : typing.Optional[bool]\n    Whether to send the transcription result to configured speech-to-text webhooks.  If set the request will return early without the transcription, which will be delivered later via webhook.\n\nwebhook_id : typing.Optional[str]\n    Optional specific webhook ID to send the transcription result to. Only valid when webhook is set to true. If not provided, transcription will be sent to all configured speech-to-text webhooks.\n\ntemperature : typing.Optional[float]\n    Controls the randomness of the transcription output. Accepts values between 0.0 and 2.0, where higher values result in more diverse and less deterministic results. If omitted, we will use a temperature based on the model you selected which is usually 0.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be an integer between 0 and 2147483647.\n\nuse_multi_channel : typing.Optional[bool]\n    Whether the audio file contains multiple channels where each channel contains a single speaker. When enabled, each channel will be transcribed independently and the results will be combined. Each word in the response will include a 'channel_index' field indicating which channel it was spoken on. A maximum of 5 channels is supported.\n\nwebhook_metadata : typing.Optional[SpeechToTextConvertRequestWebhookMetadata]\n    Optional metadata to be included in the webhook response. This should be a JSON string representing an object with a maximum depth of 2 levels and maximum size of 16KB. Useful for tracking internal IDs, job references, or other contextual information.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SpeechToTextConvertResponse]\n    Synchronous transcription result",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/raw_client.py",
        "source_line": 30
      },
      {
        "path": "client.studio.create_podcast",
        "name": "create_podcast",
        "parameters": [
          {
            "name": "model_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mode",
            "type": "BodyCreatePodcastV1StudioPodcastsPostMode",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source",
            "type": "BodyCreatePodcastV1StudioPodcastsPostSource",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "safety_identifier",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality_preset",
            "type": "Optional[BodyCreatePodcastV1StudioPodcastsPostQualityPreset]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "duration_scale",
            "type": "Optional[BodyCreatePodcastV1StudioPodcastsPostDurationScale]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "intro",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "outro",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "instructions_prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "highlights",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "callback_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Optional[BodyCreatePodcastV1StudioPodcastsPostApplyTextNormalization]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PodcastProjectResponseModel",
        "docstring": "Create and auto-convert a podcast project. Currently, the LLM cost is covered by us but you will still be charged for the audio generation. In the future, you will be charged for both the LLM and audio generation costs.\n\nParameters\n----------\nmodel_id : str\n    The ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\n\nmode : BodyCreatePodcastV1StudioPodcastsPostMode\n    The type of podcast to generate. Can be 'conversation', an interaction between two voices, or 'bulletin', a monologue.\n\nsource : BodyCreatePodcastV1StudioPodcastsPostSource\n    The source content for the Podcast.\n\nsafety_identifier : typing.Optional[str]\n    Used for moderation. Your workspace must be allowlisted to use this feature.\n\nquality_preset : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostQualityPreset]\n    Output quality of the generated audio. Must be one of:\n    standard - standard output format, 128kbps with 44.1kHz sample rate.\n    high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. Using this setting increases the credit cost by 20%.\n    ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. Using this setting increases the credit cost by 50%.\n    ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format. Using this setting increases the credit cost by 100%.\n\nduration_scale : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostDurationScale]\n    Duration of the generated podcast. Must be one of:\n    short - produces podcasts shorter than 3 minutes.\n    default - produces podcasts roughly between 3-7 minutes.\n    long - produces podcasts longer than 7 minutes.\n\nlanguage : typing.Optional[str]\n    An optional language of the Studio project. Two-letter language code (ISO 639-1).\n\nintro : typing.Optional[str]\n    The intro text that will always be added to the beginning of the podcast.\n\noutro : typing.Optional[str]\n    The outro text that will always be added to the end of the podcast.\n\ninstructions_prompt : typing.Optional[str]\n    Additional instructions prompt for the podcast generation used to adjust the podcast's style and tone.\n\nhighlights : typing.Optional[typing.Sequence[str]]\n    A brief summary or highlights of the Studio project's content, providing key points or themes. This should be between 10 and 70 characters.\n\ncallback_url : typing.Optional[str]\n\n        A url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion\n        Messages:\n        1. When project was converted successfully:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"success\",\n            project_snapshot_id: \"22m00Tcm4TlvDq8ikMAT\",\n            error_details: None,\n          }\n        }\n        2. When project conversion failed:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"error\",\n            project_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n        3. When chapter was converted successfully:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"success\",\n            chapter_snapshot_id: \"23m00Tcm4TlvDq8ikMAV\",\n            error_details: None,\n          }\n        }\n        4. When chapter conversion failed:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"error\",\n            chapter_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n\napply_text_normalization : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPodcastProjectResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import (\n    ElevenLabs,\n    PodcastConversationModeData,\n    PodcastTextSource,\n)\nfrom elevenlabs.studio import (\n    BodyCreatePodcastV1StudioPodcastsPostMode_Conversation,\n)\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.create_podcast(\n    safety_identifier=\"safety-identifier\",\n    model_id=\"eleven_multilingual_v2\",\n    mode=BodyCreatePodcastV1StudioPodcastsPostMode_Conversation(\n        conversation=PodcastConversationModeData(\n            host_voice_id=\"aw1NgEzBg83R7vgmiJt6\",\n            guest_voice_id=\"aw1NgEzBg83R7vgmiJt7\",\n        ),\n    ),\n    source=PodcastTextSource(\n        text=\"This is a test podcast.\",\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/client.py",
        "source_line": 46
      },
      {
        "path": "client.studio.projects.chapters.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ConvertChapterResponseModel",
        "docstring": "Starts conversion of a specific chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nConvertChapterResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.convert(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 242
      },
      {
        "path": "client.studio.projects.chapters.create",
        "name": "create",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddChapterResponseModel",
        "docstring": "Creates a new chapter either as blank or from a URL.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nname : str\n    The name of the chapter, used for identification only.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddChapterResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.create(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    name=\"Chapter 1\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 72
      },
      {
        "path": "client.studio.projects.chapters.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteChapterResponseModel",
        "docstring": "Deletes a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteChapterResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.delete(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 205
      },
      {
        "path": "client.studio.projects.chapters.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ChapterWithContentResponseModel",
        "docstring": "Returns information about a specific chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nChapterWithContentResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.get(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 117
      },
      {
        "path": "client.studio.projects.chapters.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetChaptersResponse",
        "docstring": "Returns a list of a Studio project's chapters.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetChaptersResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.list(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 41
      },
      {
        "path": "client.studio.projects.chapters.snapshots.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ChapterSnapshotExtendedResponseModel",
        "docstring": "Returns the chapter snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nchapter_id : str\n    The ID of the chapter.\n\nchapter_snapshot_id : str\n    The ID of the chapter snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nChapterSnapshotExtendedResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.snapshots.get(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n    chapter_snapshot_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/client.py",
        "source_line": 67
      },
      {
        "path": "client.studio.projects.chapters.snapshots.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ChapterSnapshotsResponse",
        "docstring": "Gets information about all the snapshots of a chapter. Each snapshot can be downloaded as audio. Whenever a chapter is converted a snapshot will automatically be created.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nChapterSnapshotsResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.snapshots.list(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/client.py",
        "source_line": 30
      },
      {
        "path": "client.studio.projects.chapters.snapshots.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "convert_to_mpeg",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream the audio from a chapter snapshot. Use `GET /v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots` to return the snapshots of a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nchapter_snapshot_id : str\n    The ID of the chapter snapshot to be used. You can use the [List project chapter snapshots](/docs/api-reference/studio/get-snapshots) endpoint to list all the available snapshots.\n\nconvert_to_mpeg : typing.Optional[bool]\n    Whether to convert the audio to mpeg format.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.snapshots.stream(\n    project_id=\"project_id\",\n    chapter_id=\"chapter_id\",\n    chapter_snapshot_id=\"chapter_snapshot_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/client.py",
        "source_line": 113
      },
      {
        "path": "client.studio.projects.chapters.snapshots.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns the chapter snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nchapter_id : str\n    The ID of the chapter.\n\nchapter_snapshot_id : str\n    The ID of the chapter snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ChapterSnapshotExtendedResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/raw_client.py",
        "source_line": 79
      },
      {
        "path": "client.studio.projects.chapters.snapshots.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets information about all the snapshots of a chapter. Each snapshot can be downloaded as audio. Whenever a chapter is converted a snapshot will automatically be created.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ChapterSnapshotsResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/raw_client.py",
        "source_line": 26
      },
      {
        "path": "client.studio.projects.chapters.snapshots.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "convert_to_mpeg",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream the audio from a chapter snapshot. Use `GET /v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots` to return the snapshots of a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nchapter_snapshot_id : str\n    The ID of the chapter snapshot to be used. You can use the [List project chapter snapshots](/docs/api-reference/studio/get-snapshots) endpoint to list all the available snapshots.\n\nconvert_to_mpeg : typing.Optional[bool]\n    Whether to convert the audio to mpeg format.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 140
      },
      {
        "path": "client.studio.projects.chapters.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "content",
            "type": "Optional[ChapterContentInputModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditChapterResponseModel",
        "docstring": "Updates a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nname : typing.Optional[str]\n    The name of the chapter, used for identification only.\n\ncontent : typing.Optional[ChapterContentInputModel]\n    The chapter content to use.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditChapterResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.chapters.update(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 154
      },
      {
        "path": "client.studio.projects.chapters.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Starts conversion of a specific chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ConvertChapterResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 331
      },
      {
        "path": "client.studio.projects.chapters.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Creates a new chapter either as blank or from a URL.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nname : str\n    The name of the chapter, used for identification only.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddChapterResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 81
      },
      {
        "path": "client.studio.projects.chapters.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Deletes a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteChapterResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 278
      },
      {
        "path": "client.studio.projects.chapters.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns information about a specific chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ChapterWithContentResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 150
      },
      {
        "path": "client.studio.projects.chapters.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns a list of a Studio project's chapters.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetChaptersResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 31
      },
      {
        "path": "client.studio.projects.chapters.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "content",
            "type": "Optional[ChapterContentInputModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Updates a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nname : typing.Optional[str]\n    The name of the chapter, used for identification only.\n\ncontent : typing.Optional[ChapterContentInputModel]\n    The chapter content to use.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[EditChapterResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 203
      },
      {
        "path": "client.studio.projects.content.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_document",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_content_json",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditProjectResponseModel",
        "docstring": "Updates Studio project content.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nfrom_document : typing.Optional[core.File]\n    See core.File for more documentation\n\nfrom_content_json : typing.Optional[str]\n\n        An optional content to initialize the Studio project with. If this is set, 'from_url' and 'from_document' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\n        Example:\n        [{\"name\": \"Chapter A\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"A\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"B\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h1\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"C\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"D\", \"type\": \"tts_node\"}]}]}, {\"name\": \"Chapter B\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"E\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"F\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h2\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"G\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"H\", \"type\": \"tts_node\"}]}]}]\n\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the Studio project to audio or not.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditProjectResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.content.update(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/content/client.py",
        "source_line": 30
      },
      {
        "path": "client.studio.projects.content.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_document",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_content_json",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Updates Studio project content.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nfrom_document : typing.Optional[core.File]\n    See core.File for more documentation\n\nfrom_content_json : typing.Optional[str]\n\n        An optional content to initialize the Studio project with. If this is set, 'from_url' and 'from_document' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\n        Example:\n        [{\"name\": \"Chapter A\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"A\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"B\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h1\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"C\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"D\", \"type\": \"tts_node\"}]}]}, {\"name\": \"Chapter B\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"E\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"F\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h2\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"G\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"H\", \"type\": \"tts_node\"}]}]}]\n\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the Studio project to audio or not.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[EditProjectResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/content/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.studio.projects.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ConvertProjectResponseModel",
        "docstring": "Starts conversion of a Studio project and all of its chapters.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nConvertProjectResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.convert(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 474
      },
      {
        "path": "client.studio.projects.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_title_voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_paragraph_voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_document",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_content_json",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality_preset",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "genres",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_audience",
            "type": "Optional[ProjectsCreateRequestTargetAudience]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "content_type",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "original_publication_date",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mature_content",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "isbn_number",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "acx_volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "callback_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "fiction",
            "type": "Optional[ProjectsCreateRequestFiction]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Optional[ProjectsCreateRequestApplyTextNormalization]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_assign_voices",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_type",
            "type": "Optional[ProjectsCreateRequestSourceType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddProjectResponseModel",
        "docstring": "Creates a new Studio project, it can be either initialized as blank, from a document or from a URL.\n\nParameters\n----------\nname : str\n    The name of the Studio project, used for identification only.\n\ndefault_title_voice_id : typing.Optional[str]\n    The voice_id that corresponds to the default voice used for new titles.\n\ndefault_paragraph_voice_id : typing.Optional[str]\n    The voice_id that corresponds to the default voice used for new paragraphs.\n\ndefault_model_id : typing.Optional[str]\n    The ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nfrom_document : typing.Optional[core.File]\n    See core.File for more documentation\n\nfrom_content_json : typing.Optional[str]\n\n        An optional content to initialize the Studio project with. If this is set, 'from_url' and 'from_document' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\n        Example:\n        [{\"name\": \"Chapter A\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"A\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"B\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h1\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"C\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"D\", \"type\": \"tts_node\"}]}]}, {\"name\": \"Chapter B\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"E\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"F\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h2\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"G\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"H\", \"type\": \"tts_node\"}]}]}]\n\n\nquality_preset : typing.Optional[str]\n    Output quality of the generated audio. Must be one of:\n    standard - standard output format, 128kbps with 44.1kHz sample rate.\n    high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. Using this setting increases the credit cost by 20%.\n    ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. Using this setting increases the credit cost by 50%.\n    ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format. Using this setting increases the credit cost by 100%.\n\ntitle : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nauthor : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\ndescription : typing.Optional[str]\n    An optional description of the Studio project.\n\ngenres : typing.Optional[typing.List[str]]\n    An optional list of genres associated with the Studio project.\n\ntarget_audience : typing.Optional[ProjectsCreateRequestTargetAudience]\n    An optional target audience of the Studio project.\n\nlanguage : typing.Optional[str]\n    An optional language of the Studio project. Two-letter language code (ISO 639-1).\n\ncontent_type : typing.Optional[str]\n    An optional content type of the Studio project.\n\noriginal_publication_date : typing.Optional[str]\n    An optional original publication date of the Studio project, in the format YYYY-MM-DD or YYYY.\n\nmature_content : typing.Optional[bool]\n    An optional specification of whether this Studio project contains mature content.\n\nisbn_number : typing.Optional[str]\n    An optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nacx_volume_normalization : typing.Optional[bool]\n    [Deprecated] When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\nvolume_normalization : typing.Optional[bool]\n    When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\npronunciation_dictionary_locators : typing.Optional[typing.List[str]]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\ncallback_url : typing.Optional[str]\n\n        A url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion\n        Messages:\n        1. When project was converted successfully:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"success\",\n            project_snapshot_id: \"22m00Tcm4TlvDq8ikMAT\",\n            error_details: None,\n          }\n        }\n        2. When project conversion failed:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"error\",\n            project_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n        3. When chapter was converted successfully:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"success\",\n            chapter_snapshot_id: \"23m00Tcm4TlvDq8ikMAV\",\n            error_details: None,\n          }\n        }\n        4. When chapter conversion failed:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"error\",\n            chapter_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n\nfiction : typing.Optional[ProjectsCreateRequestFiction]\n    An optional specification of whether the content of this Studio project is fiction.\n\napply_text_normalization : typing.Optional[ProjectsCreateRequestApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the Studio project to audio or not.\n\nauto_assign_voices : typing.Optional[bool]\n    [Alpha Feature] Whether automatically assign voices to phrases in the create Project.\n\nsource_type : typing.Optional[ProjectsCreateRequestSourceType]\n    The type of Studio project to create.\n\nvoice_settings : typing.Optional[typing.List[str]]\n        Optional voice settings overrides for the project, encoded as a list of JSON strings.\n\n        Example:\n        [\"{\\\"voice_id\\\": \\\"21m00Tcm4TlvDq8ikWAM\\\", \\\"stability\\\": 0.7, \\\"similarity_boost\\\": 0.8, \\\"style\\\": 0.5, \\\"speed\\\": 1.0, \\\"use_speaker_boost\\\": true}\"]\n\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddProjectResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.create(\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 77
      },
      {
        "path": "client.studio.projects.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteProjectResponseModel",
        "docstring": "Deletes a Studio project.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteProjectResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.delete(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 441
      },
      {
        "path": "client.studio.projects.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "share_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ProjectExtendedResponse",
        "docstring": "Returns information about a specific Studio project. This endpoint returns more detailed information about a project than `GET /v1/studio`.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nshare_id : typing.Optional[str]\n    The share ID of the project\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nProjectExtendedResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.get(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    share_id=\"share_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 323
      },
      {
        "path": "client.studio.projects.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetProjectsResponse",
        "docstring": "Returns a list of your Studio projects with metadata.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetProjectsResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.list()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 51
      },
      {
        "path": "client.studio.projects.pronunciation_dictionaries.create",
        "name": "create",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "invalidate_affected_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreatePronunciationDictionaryResponseModel",
        "docstring": "Create a set of pronunciation dictionaries acting on a project. This will automatically mark text within this project as requiring reconverting where the new dictionary would apply or the old one no longer does.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\npronunciation_dictionary_locators : typing.Sequence[PronunciationDictionaryVersionLocator]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\ninvalidate_affected_text : typing.Optional[bool]\n    This will automatically mark text in this project for reconversion when the new dictionary applies or the old one no longer does.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreatePronunciationDictionaryResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs, PronunciationDictionaryVersionLocator\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.pronunciation_dictionaries.create(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    pronunciation_dictionary_locators=[\n        PronunciationDictionaryVersionLocator(\n            pronunciation_dictionary_id=\"pronunciation_dictionary_id\",\n        )\n    ],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/pronunciation_dictionaries/client.py",
        "source_line": 30
      },
      {
        "path": "client.studio.projects.pronunciation_dictionaries.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "invalidate_affected_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a set of pronunciation dictionaries acting on a project. This will automatically mark text within this project as requiring reconverting where the new dictionary would apply or the old one no longer does.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\npronunciation_dictionary_locators : typing.Sequence[PronunciationDictionaryVersionLocator]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\ninvalidate_affected_text : typing.Optional[bool]\n    This will automatically mark text in this project for reconversion when the new dictionary applies or the old one no longer does.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[CreatePronunciationDictionaryResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/pronunciation_dictionaries/raw_client.py",
        "source_line": 26
      },
      {
        "path": "client.studio.projects.snapshots.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ProjectSnapshotExtendedResponseModel",
        "docstring": "Returns the project snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nProjectSnapshotExtendedResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.snapshots.get(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    project_snapshot_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/client.py",
        "source_line": 63
      },
      {
        "path": "client.studio.projects.snapshots.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ProjectSnapshotsResponse",
        "docstring": "Retrieves a list of snapshots for a Studio project.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nProjectSnapshotsResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.snapshots.list(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/client.py",
        "source_line": 30
      },
      {
        "path": "client.studio.projects.snapshots.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "convert_to_mpeg",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream the audio from a Studio project snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nconvert_to_mpeg : typing.Optional[bool]\n    Whether to convert the audio to mpeg format.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.snapshots.stream(\n    project_id=\"project_id\",\n    project_snapshot_id=\"project_snapshot_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/client.py",
        "source_line": 100
      },
      {
        "path": "client.studio.projects.snapshots.stream_archive",
        "name": "stream_archive",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Returns a compressed archive of the Studio project's audio.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Streaming archive data\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.snapshots.stream_archive(\n    project_id=\"project_id\",\n    project_snapshot_id=\"project_snapshot_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/client.py",
        "source_line": 147
      },
      {
        "path": "client.studio.projects.snapshots.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns the project snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ProjectSnapshotExtendedResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/raw_client.py",
        "source_line": 76
      },
      {
        "path": "client.studio.projects.snapshots.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieves a list of snapshots for a Studio project.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ProjectSnapshotsResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/raw_client.py",
        "source_line": 26
      },
      {
        "path": "client.studio.projects.snapshots.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "convert_to_mpeg",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream the audio from a Studio project snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nconvert_to_mpeg : typing.Optional[bool]\n    Whether to convert the audio to mpeg format.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 129
      },
      {
        "path": "client.studio.projects.snapshots.with_raw_response.stream_archive",
        "name": "stream_archive",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Returns a compressed archive of the Studio project's audio.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Streaming archive data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 201
      },
      {
        "path": "client.studio.projects.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_title_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_paragraph_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "isbn_number",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditProjectResponseModel",
        "docstring": "Updates the specified Studio project by setting the values of the parameters passed.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nname : str\n    The name of the Studio project, used for identification only.\n\ndefault_title_voice_id : str\n    The voice_id that corresponds to the default voice used for new titles.\n\ndefault_paragraph_voice_id : str\n    The voice_id that corresponds to the default voice used for new paragraphs.\n\ntitle : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nauthor : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nisbn_number : typing.Optional[str]\n    An optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nvolume_normalization : typing.Optional[bool]\n    When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditProjectResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.studio.projects.update(\n    project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    name=\"Project 1\",\n    default_title_voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    default_paragraph_voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 364
      },
      {
        "path": "client.studio.projects.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Starts conversion of a Studio project and all of its chapters.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ConvertProjectResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 550
      },
      {
        "path": "client.studio.projects.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_title_voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_paragraph_voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_document",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_content_json",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality_preset",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "genres",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_audience",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "content_type",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "original_publication_date",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mature_content",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "isbn_number",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "acx_volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "callback_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "fiction",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_assign_voices",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Creates a new Studio project, it can be either initialized as blank, from a document or from a URL.\n\nParameters\n----------\nname : str\n    The name of the Studio project, used for identification only.\n\ndefault_title_voice_id : typing.Optional[str]\n    The voice_id that corresponds to the default voice used for new titles.\n\ndefault_paragraph_voice_id : typing.Optional[str]\n    The voice_id that corresponds to the default voice used for new paragraphs.\n\ndefault_model_id : typing.Optional[str]\n    The ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nfrom_document : typing.Optional[core.File]\n    See core.File for more documentation\n\nfrom_content_json : typing.Optional[str]\n\n        An optional content to initialize the Studio project with. If this is set, 'from_url' and 'from_document' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\n        Example:\n        [{\"name\": \"Chapter A\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"A\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"B\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h1\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"C\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"D\", \"type\": \"tts_node\"}]}]}, {\"name\": \"Chapter B\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"E\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"F\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h2\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"G\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"H\", \"type\": \"tts_node\"}]}]}]\n\n\nquality_preset : typing.Optional[str]\n    Output quality of the generated audio. Must be one of:\n    standard - standard output format, 128kbps with 44.1kHz sample rate.\n    high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. Using this setting increases the credit cost by 20%.\n    ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. Using this setting increases the credit cost by 50%.\n    ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format. Using this setting increases the credit cost by 100%.\n\ntitle : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nauthor : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\ndescription : typing.Optional[str]\n    An optional description of the Studio project.\n\ngenres : typing.Optional[typing.List[str]]\n    An optional list of genres associated with the Studio project.\n\ntarget_audience : typing.Optional[ProjectsCreateRequestTargetAudience]\n    An optional target audience of the Studio project.\n\nlanguage : typing.Optional[str]\n    An optional language of the Studio project. Two-letter language code (ISO 639-1).\n\ncontent_type : typing.Optional[str]\n    An optional content type of the Studio project.\n\noriginal_publication_date : typing.Optional[str]\n    An optional original publication date of the Studio project, in the format YYYY-MM-DD or YYYY.\n\nmature_content : typing.Optional[bool]\n    An optional specification of whether this Studio project contains mature content.\n\nisbn_number : typing.Optional[str]\n    An optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nacx_volume_normalization : typing.Optional[bool]\n    [Deprecated] When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\nvolume_normalization : typing.Optional[bool]\n    When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\npronunciation_dictionary_locators : typing.Optional[typing.List[str]]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\ncallback_url : typing.Optional[str]\n\n        A url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion\n        Messages:\n        1. When project was converted successfully:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"success\",\n            project_snapshot_id: \"22m00Tcm4TlvDq8ikMAT\",\n            error_details: None,\n          }\n        }\n        2. When project conversion failed:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"error\",\n            project_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n        3. When chapter was converted successfully:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"success\",\n            chapter_snapshot_id: \"23m00Tcm4TlvDq8ikMAV\",\n            error_details: None,\n          }\n        }\n        4. When chapter conversion failed:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"error\",\n            chapter_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n\nfiction : typing.Optional[ProjectsCreateRequestFiction]\n    An optional specification of whether the content of this Studio project is fiction.\n\napply_text_normalization : typing.Optional[ProjectsCreateRequestApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the Studio project to audio or not.\n\nauto_assign_voices : typing.Optional[bool]\n    [Alpha Feature] Whether automatically assign voices to phrases in the create Project.\n\nsource_type : typing.Optional[ProjectsCreateRequestSourceType]\n    The type of Studio project to create.\n\nvoice_settings : typing.Optional[typing.List[str]]\n        Optional voice settings overrides for the project, encoded as a list of JSON strings.\n\n        Example:\n        [\"{\\\"voice_id\\\": \\\"21m00Tcm4TlvDq8ikWAM\\\", \\\"stability\\\": 0.7, \\\"similarity_boost\\\": 0.8, \\\"style\\\": 0.5, \\\"speed\\\": 1.0, \\\"use_speaker_boost\\\": true}\"]\n\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddProjectResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 79
      },
      {
        "path": "client.studio.projects.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Deletes a Studio project.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteProjectResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 500
      },
      {
        "path": "client.studio.projects.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "share_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns information about a specific Studio project. This endpoint returns more detailed information about a project than `GET /v1/studio`.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nshare_id : typing.Optional[str]\n    The share ID of the project\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ProjectExtendedResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 346
      },
      {
        "path": "client.studio.projects.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns a list of your Studio projects with metadata.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetProjectsResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 34
      },
      {
        "path": "client.studio.projects.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_title_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_paragraph_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "isbn_number",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Updates the specified Studio project by setting the values of the parameters passed.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nname : str\n    The name of the Studio project, used for identification only.\n\ndefault_title_voice_id : str\n    The voice_id that corresponds to the default voice used for new titles.\n\ndefault_paragraph_voice_id : str\n    The voice_id that corresponds to the default voice used for new paragraphs.\n\ntitle : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nauthor : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nisbn_number : typing.Optional[str]\n    An optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nvolume_normalization : typing.Optional[bool]\n    When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[EditProjectResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 406
      },
      {
        "path": "client.studio.with_raw_response.create_podcast",
        "name": "create_podcast",
        "parameters": [
          {
            "name": "model_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mode",
            "type": "Annotated",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source",
            "type": "Union[PodcastTextSource, PodcastUrlSource, List[Annotated]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "safety_identifier",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality_preset",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "duration_scale",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "intro",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "outro",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "instructions_prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "highlights",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "callback_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create and auto-convert a podcast project. Currently, the LLM cost is covered by us but you will still be charged for the audio generation. In the future, you will be charged for both the LLM and audio generation costs.\n\nParameters\n----------\nmodel_id : str\n    The ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\n\nmode : BodyCreatePodcastV1StudioPodcastsPostMode\n    The type of podcast to generate. Can be 'conversation', an interaction between two voices, or 'bulletin', a monologue.\n\nsource : BodyCreatePodcastV1StudioPodcastsPostSource\n    The source content for the Podcast.\n\nsafety_identifier : typing.Optional[str]\n    Used for moderation. Your workspace must be allowlisted to use this feature.\n\nquality_preset : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostQualityPreset]\n    Output quality of the generated audio. Must be one of:\n    standard - standard output format, 128kbps with 44.1kHz sample rate.\n    high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. Using this setting increases the credit cost by 20%.\n    ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. Using this setting increases the credit cost by 50%.\n    ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format. Using this setting increases the credit cost by 100%.\n\nduration_scale : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostDurationScale]\n    Duration of the generated podcast. Must be one of:\n    short - produces podcasts shorter than 3 minutes.\n    default - produces podcasts roughly between 3-7 minutes.\n    long - produces podcasts longer than 7 minutes.\n\nlanguage : typing.Optional[str]\n    An optional language of the Studio project. Two-letter language code (ISO 639-1).\n\nintro : typing.Optional[str]\n    The intro text that will always be added to the beginning of the podcast.\n\noutro : typing.Optional[str]\n    The outro text that will always be added to the end of the podcast.\n\ninstructions_prompt : typing.Optional[str]\n    Additional instructions prompt for the podcast generation used to adjust the podcast's style and tone.\n\nhighlights : typing.Optional[typing.Sequence[str]]\n    A brief summary or highlights of the Studio project's content, providing key points or themes. This should be between 10 and 70 characters.\n\ncallback_url : typing.Optional[str]\n\n        A url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion\n        Messages:\n        1. When project was converted successfully:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"success\",\n            project_snapshot_id: \"22m00Tcm4TlvDq8ikMAT\",\n            error_details: None,\n          }\n        }\n        2. When project conversion failed:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"error\",\n            project_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n        3. When chapter was converted successfully:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"success\",\n            chapter_snapshot_id: \"23m00Tcm4TlvDq8ikMAV\",\n            error_details: None,\n          }\n        }\n        4. When chapter conversion failed:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"error\",\n            chapter_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n\napply_text_normalization : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PodcastProjectResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/raw_client.py",
        "source_line": 35
      },
      {
        "path": "client.text_to_dialogue.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns audio.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueMultiVoiceV1TextToDialoguePostApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The generated audio file\n\nExamples\n--------\nfrom elevenlabs import DialogueInput, ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_dialogue.convert(\n    inputs=[\n        DialogueInput(\n            text=\"Knock knock\",\n            voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n        ),\n        DialogueInput(\n            text=\"Who is there?\",\n            voice_id=\"Aw4FAjKCGjjNkVhN1Xmq\",\n        ),\n    ],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/client.py",
        "source_line": 57
      },
      {
        "path": "client.text_to_dialogue.convert_with_timestamps",
        "name": "convert_with_timestamps",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AudioWithTimestampsAndVoiceSegmentsResponseModel",
        "docstring": "Generate dialogue from text with precise character-level timing information for audio-text synchronization.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueConvertWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueFullWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAudioWithTimestampsAndVoiceSegmentsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import DialogueInput, ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_dialogue.convert_with_timestamps(\n    output_format=\"mp3_22050_32\",\n    inputs=[\n        DialogueInput(\n            text=\"Hello, how are you?\",\n            voice_id=\"bYTqZQo3Jz7LQtmGTgwi\",\n        ),\n        DialogueInput(\n            text=\"I'm doing well, thank you!\",\n            voice_id=\"6lCwbsX1yVjD49QmpkTR\",\n        ),\n    ],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/client.py",
        "source_line": 319
      },
      {
        "path": "client.text_to_dialogue.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns an audio stream.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueMultiVoiceStreamingV1TextToDialogueStreamPostApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nfrom elevenlabs import DialogueInput, ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_dialogue.stream(\n    inputs=[\n        DialogueInput(\n            text=\"Knock knock\",\n            voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n        ),\n        DialogueInput(\n            text=\"Who is there?\",\n            voice_id=\"Aw4FAjKCGjjNkVhN1Xmq\",\n        ),\n    ],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/client.py",
        "source_line": 144
      },
      {
        "path": "client.text_to_dialogue.stream_with_timestamps",
        "name": "stream_with_timestamps",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns a stream of JSON blobs containing audio as a base64 encoded string and timestamps\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueStreamWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueStreamWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nYields\n------\ntyping.Iterator[StreamingAudioChunkWithTimestampsAndVoiceSegmentsResponseModel]\n    Stream of transcription chunks\n\nExamples\n--------\nfrom elevenlabs import DialogueInput, ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nresponse = client.text_to_dialogue.stream_with_timestamps(\n    output_format=\"mp3_22050_32\",\n    inputs=[\n        DialogueInput(\n            text=\"Hello, how are you?\",\n            voice_id=\"bYTqZQo3Jz7LQtmGTgwi\",\n        ),\n        DialogueInput(\n            text=\"I'm doing well, thank you!\",\n            voice_id=\"6lCwbsX1yVjD49QmpkTR\",\n        ),\n    ],\n)\nfor chunk in response:\n    yield chunk",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/client.py",
        "source_line": 231
      },
      {
        "path": "client.text_to_dialogue.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns audio.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueMultiVoiceV1TextToDialoguePostApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The generated audio file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 54
      },
      {
        "path": "client.text_to_dialogue.with_raw_response.convert_with_timestamps",
        "name": "convert_with_timestamps",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Generate dialogue from text with precise character-level timing information for audio-text synchronization.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueConvertWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueFullWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AudioWithTimestampsAndVoiceSegmentsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/raw_client.py",
        "source_line": 407
      },
      {
        "path": "client.text_to_dialogue.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns an audio stream.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueMultiVoiceStreamingV1TextToDialogueStreamPostApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 167
      },
      {
        "path": "client.text_to_dialogue.with_raw_response.stream_with_timestamps",
        "name": "stream_with_timestamps",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns a stream of JSON blobs containing audio as a base64 encoded string and timestamps\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueStreamWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueStreamWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nYields\n------\ntyping.Iterator[HttpResponse[typing.Iterator[StreamingAudioChunkWithTimestampsAndVoiceSegmentsResponseModel]]]\n    Stream of transcription chunks",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 280
      },
      {
        "path": "client.text_to_sound_effects.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loop",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "duration_seconds",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_influence",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Turn text into sound effects for your videos, voice-overs or video games using the most advanced sound effects models in the world.\n\nParameters\n----------\ntext : str\n    The text that will get converted into a sound effect.\n\noutput_format : typing.Optional[TextToSoundEffectsConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nloop : typing.Optional[bool]\n    Whether to create a sound effect that loops smoothly. Only available for the 'eleven_text_to_sound_v2 model'.\n\nduration_seconds : typing.Optional[float]\n    The duration of the sound which will be generated in seconds. Must be at least 0.5 and at most 30. If set to None we will guess the optimal duration using the prompt. Defaults to None.\n\nprompt_influence : typing.Optional[float]\n    A higher prompt influence makes your generation follow the prompt more closely while also making generations less variable. Must be a value between 0 and 1. Defaults to 0.3.\n\nmodel_id : typing.Optional[str]\n    The model ID to use for the sound generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The generated sound effect as an MP3 file\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_sound_effects.convert(\n    text=\"Spacious braam suitable for high-impact movie trailer moments\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_sound_effects/client.py",
        "source_line": 29
      },
      {
        "path": "client.text_to_sound_effects.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loop",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "duration_seconds",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_influence",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Turn text into sound effects for your videos, voice-overs or video games using the most advanced sound effects models in the world.\n\nParameters\n----------\ntext : str\n    The text that will get converted into a sound effect.\n\noutput_format : typing.Optional[TextToSoundEffectsConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nloop : typing.Optional[bool]\n    Whether to create a sound effect that loops smoothly. Only available for the 'eleven_text_to_sound_v2 model'.\n\nduration_seconds : typing.Optional[float]\n    The duration of the sound which will be generated in seconds. Must be at least 0.5 and at most 30. If set to None we will guess the optimal duration using the prompt. Defaults to None.\n\nprompt_influence : typing.Optional[float]\n    A higher prompt influence makes your generation follow the prompt more closely while also making generations less variable. Must be a value between 0 and 1. Defaults to 0.3.\n\nmodel_id : typing.Optional[str]\n    The model ID to use for the sound generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The generated sound effect as an MP3 file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 24
      },
      {
        "path": "client.text_to_speech.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechFullApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    The generated audio file\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_speech.convert(\n    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n    output_format=\"mp3_44100_128\",\n    text=\"The first move is what sets everything in motion.\",\n    model_id=\"eleven_multilingual_v2\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/client.py",
        "source_line": 48
      },
      {
        "path": "client.text_to_speech.convert_realtime",
        "name": "convert_realtime",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "Iterator",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "mp3_44100_128",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio.\n\nParameters:\n    - voice_id: str. Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\n    - text: typing.Iterator[str]. The text that will get converted into speech.\n\n    - model_id: typing.Optional[str]. Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\n    - voice_settings: typing.Optional[VoiceSettings]. Voice settings overriding stored setttings for the given voice. They are applied only on the given request.\n\n    - request_options: typing.Optional[RequestOptions]. Request-specific configuration.\n---\nfrom elevenlabs import PronunciationDictionaryVersionLocator, VoiceSettings\nfrom elevenlabs.client import ElevenLabs\n\ndef get_text() -> typing.Iterator[str]:\n    yield \"Hello, how are you?\"\n    yield \"I am fine, thank you.\"\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_speech.convert_realtime(\n    voice_id=\"string\",\n    text=get_text(),\n    model_id=\"string\",\n    voice_settings=VoiceSettings(\n        stability=1.1,\n        similarity_boost=1.1,\n        style=1.1,\n        use_speaker_boost=True,\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/realtime_tts.py",
        "source_line": 48
      },
      {
        "path": "client.text_to_speech.convert_with_timestamps",
        "name": "convert_with_timestamps",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AudioWithTimestampsResponse",
        "docstring": "Generate speech from text with precise character-level timing information for audio-text synchronization.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechConvertWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechFullWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAudioWithTimestampsResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_speech.convert_with_timestamps(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    enable_logging=True,\n    optimize_streaming_latency=1,\n    output_format=\"mp3_22050_32\",\n    text=\"This is a test for the API of ElevenLabs.\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/client.py",
        "source_line": 179
      },
      {
        "path": "client.text_to_speech.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio as an audio stream.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechStreamApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_speech.stream(\n    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n    output_format=\"mp3_44100_128\",\n    text=\"The first move is what sets everything in motion.\",\n    model_id=\"eleven_multilingual_v2\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/client.py",
        "source_line": 311
      },
      {
        "path": "client.text_to_speech.stream_with_timestamps",
        "name": "stream_with_timestamps",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts text into speech using a voice of your choice and returns a stream of JSONs containing audio as a base64 encoded string together with information on when which character was spoken.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechStreamWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechStreamWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nYields\n------\ntyping.Iterator[StreamingAudioChunkWithTimestampsResponse]\n    Stream of transcription chunks\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nresponse = client.text_to_speech.stream_with_timestamps(\n    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n    output_format=\"mp3_44100_128\",\n    text=\"The first move is what sets everything in motion.\",\n    model_id=\"eleven_multilingual_v2\",\n)\nfor chunk in response:\n    yield chunk",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/client.py",
        "source_line": 442
      },
      {
        "path": "client.text_to_speech.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechFullApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    The generated audio file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 46
      },
      {
        "path": "client.text_to_speech.with_raw_response.convert_with_timestamps",
        "name": "convert_with_timestamps",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Generate speech from text with precise character-level timing information for audio-text synchronization.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechConvertWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechFullWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AudioWithTimestampsResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/raw_client.py",
        "source_line": 206
      },
      {
        "path": "client.text_to_speech.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio as an audio stream.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechStreamApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 362
      },
      {
        "path": "client.text_to_speech.with_raw_response.stream_with_timestamps",
        "name": "stream_with_timestamps",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Converts text into speech using a voice of your choice and returns a stream of JSONs containing audio as a base64 encoded string together with information on when which character was spoken.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechStreamWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechStreamWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nYields\n------\ntyping.Iterator[HttpResponse[typing.Iterator[StreamingAudioChunkWithTimestampsResponse]]]\n    Stream of transcription chunks",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 522
      },
      {
        "path": "client.text_to_voice.create",
        "name": "create",
        "parameters": [
          {
            "name": "voice_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "generated_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "played_not_selected_voice_ids",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Voice",
        "docstring": "Create a voice from previously generated voice preview. This endpoint should be called after you fetched a generated_voice_id using POST /v1/text-to-voice/design or POST /v1/text-to-voice/:voice_id/remix.\n\nParameters\n----------\nvoice_name : str\n    Name to use for the created voice.\n\nvoice_description : str\n    Description to use for the created voice.\n\ngenerated_voice_id : str\n    The generated_voice_id to create, call POST /v1/text-to-voice/create-previews and fetch the generated_voice_id from the response header if don't have one yet.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Optional, metadata to add to the created voice. Defaults to None.\n\nplayed_not_selected_voice_ids : typing.Optional[typing.Sequence[str]]\n    List of voice ids that the user has played but not selected. Used for RLHF.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoice\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_voice.create(\n    voice_name=\"Sassy squeaky mouse\",\n    voice_description=\"A sassy squeaky mouse\",\n    generated_voice_id=\"37HceQefKmEi3bGovXjL\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/client.py",
        "source_line": 115
      },
      {
        "path": "client.text_to_voice.create_previews",
        "name": "create_previews",
        "parameters": [
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[TextToVoiceCreatePreviewsRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceDesignPreviewResponse",
        "docstring": "Create a voice from a text prompt.\n\nParameters\n----------\nvoice_description : str\n    Description to use for the created voice.\n\noutput_format : typing.Optional[TextToVoiceCreatePreviewsRequestOutputFormat]\n    The output format of the generated audio.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nquality : typing.Optional[float]\n    Higher quality results in better voice output but less variety.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceDesignPreviewResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_voice.create_previews(\n    output_format=\"mp3_22050_32\",\n    voice_description=\"A sassy squeaky mouse\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/client.py",
        "source_line": 40
      },
      {
        "path": "client.text_to_voice.design",
        "name": "design",
        "parameters": [
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[TextToVoiceDesignRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[VoiceDesignRequestModelModelId]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stream_previews",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_iteration_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "reference_audio_base_64",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_strength",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceDesignPreviewResponse",
        "docstring": "Design a voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n\nParameters\n----------\nvoice_description : str\n    Description to use for the created voice.\n\noutput_format : typing.Optional[TextToVoiceDesignRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[VoiceDesignRequestModelModelId]\n    Model to use for the voice generation. Possible values: eleven_multilingual_ttv_v2, eleven_ttv_v3.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nstream_previews : typing.Optional[bool]\n    Determines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\n\nremixing_session_id : typing.Optional[str]\n    The remixing session id.\n\nremixing_session_iteration_id : typing.Optional[str]\n    The id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\n\nquality : typing.Optional[float]\n    Higher quality results in better voice output but less variety.\n\nreference_audio_base_64 : typing.Optional[str]\n    Reference audio to use for the voice generation. The audio should be base64 encoded. Only supported when using the  eleven_ttv_v3 model.\n\nprompt_strength : typing.Optional[float]\n    Controls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceDesignPreviewResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_voice.design(\n    output_format=\"mp3_22050_32\",\n    voice_description=\"A sassy squeaky mouse\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/client.py",
        "source_line": 176
      },
      {
        "path": "client.text_to_voice.preview.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "generated_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream a voice preview that was created via the /v1/text-to-voice/design endpoint.\n\nParameters\n----------\ngenerated_voice_id : str\n    The generated_voice_id to stream.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_voice.preview.stream(\n    generated_voice_id=\"generated_voice_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/preview/client.py",
        "source_line": 25
      },
      {
        "path": "client.text_to_voice.preview.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "generated_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Stream a voice preview that was created via the /v1/text-to-voice/design endpoint.\n\nParameters\n----------\ngenerated_voice_id : str\n    The generated_voice_id to stream.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 21
      },
      {
        "path": "client.text_to_voice.remix",
        "name": "remix",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[TextToVoiceRemixRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stream_previews",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_iteration_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_strength",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceDesignPreviewResponse",
        "docstring": "Remix an existing voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nvoice_description : str\n    Description of the changes to make to the voice.\n\noutput_format : typing.Optional[TextToVoiceRemixRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nstream_previews : typing.Optional[bool]\n    Determines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\n\nremixing_session_id : typing.Optional[str]\n    The remixing session id.\n\nremixing_session_iteration_id : typing.Optional[str]\n    The id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\n\nprompt_strength : typing.Optional[float]\n    Controls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceDesignPreviewResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.text_to_voice.remix(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    output_format=\"mp3_22050_32\",\n    voice_description=\"Make the voice have a higher pitch.\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/client.py",
        "source_line": 281
      },
      {
        "path": "client.text_to_voice.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "voice_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "generated_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "played_not_selected_voice_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a voice from previously generated voice preview. This endpoint should be called after you fetched a generated_voice_id using POST /v1/text-to-voice/design or POST /v1/text-to-voice/:voice_id/remix.\n\nParameters\n----------\nvoice_name : str\n    Name to use for the created voice.\n\nvoice_description : str\n    Description to use for the created voice.\n\ngenerated_voice_id : str\n    The generated_voice_id to create, call POST /v1/text-to-voice/create-previews and fetch the generated_voice_id from the response header if don't have one yet.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Optional, metadata to add to the created voice. Defaults to None.\n\nplayed_not_selected_voice_ids : typing.Optional[typing.Sequence[str]]\n    List of voice ids that the user has played but not selected. Used for RLHF.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[Voice]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/raw_client.py",
        "source_line": 126
      },
      {
        "path": "client.text_to_voice.with_raw_response.create_previews",
        "name": "create_previews",
        "parameters": [
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a voice from a text prompt.\n\nParameters\n----------\nvoice_description : str\n    Description to use for the created voice.\n\noutput_format : typing.Optional[TextToVoiceCreatePreviewsRequestOutputFormat]\n    The output format of the generated audio.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nquality : typing.Optional[float]\n    Higher quality results in better voice output but less variety.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[VoiceDesignPreviewResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/raw_client.py",
        "source_line": 29
      },
      {
        "path": "client.text_to_voice.with_raw_response.design",
        "name": "design",
        "parameters": [
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stream_previews",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_iteration_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "reference_audio_base_64",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_strength",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Design a voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n\nParameters\n----------\nvoice_description : str\n    Description to use for the created voice.\n\noutput_format : typing.Optional[TextToVoiceDesignRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[VoiceDesignRequestModelModelId]\n    Model to use for the voice generation. Possible values: eleven_multilingual_ttv_v2, eleven_ttv_v3.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nstream_previews : typing.Optional[bool]\n    Determines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\n\nremixing_session_id : typing.Optional[str]\n    The remixing session id.\n\nremixing_session_iteration_id : typing.Optional[str]\n    The id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\n\nquality : typing.Optional[float]\n    Higher quality results in better voice output but less variety.\n\nreference_audio_base_64 : typing.Optional[str]\n    Reference audio to use for the voice generation. The audio should be base64 encoded. Only supported when using the  eleven_ttv_v3 model.\n\nprompt_strength : typing.Optional[float]\n    Controls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[VoiceDesignPreviewResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/raw_client.py",
        "source_line": 206
      },
      {
        "path": "client.text_to_voice.with_raw_response.remix",
        "name": "remix",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stream_previews",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_iteration_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_strength",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Remix an existing voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nvoice_description : str\n    Description of the changes to make to the voice.\n\noutput_format : typing.Optional[TextToVoiceRemixRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nstream_previews : typing.Optional[bool]\n    Determines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\n\nremixing_session_id : typing.Optional[str]\n    The remixing session id.\n\nremixing_session_iteration_id : typing.Optional[str]\n    The id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\n\nprompt_strength : typing.Optional[float]\n    Controls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[VoiceDesignPreviewResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/raw_client.py",
        "source_line": 333
      },
      {
        "path": "client.tokens.single_use.create",
        "name": "create",
        "parameters": [
          {
            "name": "token_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SingleUseTokenResponseModel",
        "docstring": "Generate a time limited single-use token with embedded authentication for frontend clients.\n\nParameters\n----------\ntoken_type : SingleUseTokenType\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSingleUseTokenResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.tokens.single_use.create(\n    token_type=\"realtime_scribe\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/tokens/single_use/client.py",
        "source_line": 27
      },
      {
        "path": "client.tokens.single_use.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "token_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Generate a time limited single-use token with embedded authentication for frontend clients.\n\nParameters\n----------\ntoken_type : SingleUseTokenType\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SingleUseTokenResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/tokens/single_use/raw_client.py",
        "source_line": 22
      },
      {
        "path": "client.usage.get",
        "name": "get",
        "parameters": [
          {
            "name": "start_unix",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_unix",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_workspace_metrics",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "breakdown_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "aggregation_interval",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "aggregation_bucket_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "metric",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "UsageCharactersResponseModel",
        "docstring": "Returns the usage metrics for the current user or the entire workspace they are part of. The response provides a time axis based on the specified aggregation interval (default: day), with usage values for each interval along that axis. Usage is broken down by the selected breakdown type. For example, breakdown type \"voice\" will return the usage of each voice for each interval along the time axis.\n\nParameters\n----------\nstart_unix : int\n    UTC Unix timestamp for the start of the usage window, in milliseconds. To include the first day of the window, the timestamp should be at 00:00:00 of that day.\n\nend_unix : int\n    UTC Unix timestamp for the end of the usage window, in milliseconds. To include the last day of the window, the timestamp should be at 23:59:59 of that day.\n\ninclude_workspace_metrics : typing.Optional[bool]\n    Whether or not to include the statistics of the entire workspace.\n\nbreakdown_type : typing.Optional[BreakdownTypes]\n    How to break down the information. Cannot be \"user\" if include_workspace_metrics is False.\n\naggregation_interval : typing.Optional[UsageAggregationInterval]\n    How to aggregate usage data over time. Can be \"hour\", \"day\", \"week\", \"month\", or \"cumulative\".\n\naggregation_bucket_size : typing.Optional[int]\n    Aggregation bucket size in seconds. Overrides the aggregation interval.\n\nmetric : typing.Optional[MetricType]\n    Which metric to aggregate.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nUsageCharactersResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.usage.get(\n    start_unix=1,\n    end_unix=1,\n    include_workspace_metrics=True,\n    breakdown_type=\"none\",\n    aggregation_interval=\"hour\",\n    aggregation_bucket_size=1,\n    metric=\"credits\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/usage/client.py",
        "source_line": 29
      },
      {
        "path": "client.usage.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "start_unix",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_unix",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_workspace_metrics",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "breakdown_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "aggregation_interval",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "aggregation_bucket_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "metric",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns the usage metrics for the current user or the entire workspace they are part of. The response provides a time axis based on the specified aggregation interval (default: day), with usage values for each interval along that axis. Usage is broken down by the selected breakdown type. For example, breakdown type \"voice\" will return the usage of each voice for each interval along the time axis.\n\nParameters\n----------\nstart_unix : int\n    UTC Unix timestamp for the start of the usage window, in milliseconds. To include the first day of the window, the timestamp should be at 00:00:00 of that day.\n\nend_unix : int\n    UTC Unix timestamp for the end of the usage window, in milliseconds. To include the last day of the window, the timestamp should be at 23:59:59 of that day.\n\ninclude_workspace_metrics : typing.Optional[bool]\n    Whether or not to include the statistics of the entire workspace.\n\nbreakdown_type : typing.Optional[BreakdownTypes]\n    How to break down the information. Cannot be \"user\" if include_workspace_metrics is False.\n\naggregation_interval : typing.Optional[UsageAggregationInterval]\n    How to aggregate usage data over time. Can be \"hour\", \"day\", \"week\", \"month\", or \"cumulative\".\n\naggregation_bucket_size : typing.Optional[int]\n    Aggregation bucket size in seconds. Overrides the aggregation interval.\n\nmetric : typing.Optional[MetricType]\n    Which metric to aggregate.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[UsageCharactersResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/usage/raw_client.py",
        "source_line": 23
      },
      {
        "path": "client.user.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "User",
        "docstring": "Gets information about the user\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nUser\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.user.get()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/user/client.py",
        "source_line": 33
      },
      {
        "path": "client.user.subscription.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Subscription",
        "docstring": "Gets extended information about the users subscription\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSubscription\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.user.subscription.get()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/user/subscription/client.py",
        "source_line": 26
      },
      {
        "path": "client.user.subscription.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets extended information about the users subscription\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[Subscription]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/user/subscription/raw_client.py",
        "source_line": 20
      },
      {
        "path": "client.user.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets information about the user\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[User]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/user/raw_client.py",
        "source_line": 20
      },
      {
        "path": "client.voices.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteVoiceResponseModel",
        "docstring": "Deletes a voice by its ID.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.delete(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 221
      },
      {
        "path": "client.voices.find_similar_voices",
        "name": "find_similar_voices",
        "parameters": [
          {
            "name": "audio_file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "similarity_threshold",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "top_k",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetLibraryVoicesResponse",
        "docstring": "Returns a list of shared voices similar to the provided audio sample. If neither similarity_threshold nor top_k is provided, we will apply default values.\n\nParameters\n----------\naudio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nsimilarity_threshold : typing.Optional[float]\n    Threshold for voice similarity between provided sample and library voices. Values range from 0 to 2. The smaller the value the more similar voices will be returned.\n\ntop_k : typing.Optional[int]\n    Number of most similar voices to return. If similarity_threshold is provided, less than this number of voices may be returned. Values range from 1 to 100.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetLibraryVoicesResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.find_similar_voices()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 503
      },
      {
        "path": "client.voices.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "with_settings",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Voice",
        "docstring": "Returns metadata about a specific voice.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nwith_settings : typing.Optional[bool]\n    This parameter is now deprecated. It is ignored and will be removed in a future version.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoice\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.get(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    with_settings=True,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 180
      },
      {
        "path": "client.voices.get_all",
        "name": "get_all",
        "parameters": [
          {
            "name": "show_legacy",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetVoicesResponse",
        "docstring": "Returns a list of all available voices for a user.\n\nParameters\n----------\nshow_legacy : typing.Optional[bool]\n    If set to true, legacy premade voices will be included in responses from /v1/voices\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetVoicesResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.get_all(\n    show_legacy=True,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 49
      },
      {
        "path": "client.voices.get_shared",
        "name": "get_shared",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "category",
            "type": "Optional[VoicesGetSharedRequestCategory]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "gender",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "age",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "accent",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "locale",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_cases",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "descriptives",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "featured",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "min_notice_period_days",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_custom_rates",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_live_moderated",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "reader_app_enabled",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "owner_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetLibraryVoicesResponse",
        "docstring": "Retrieves a list of shared voices.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many shared voices to return at maximum. Can not exceed 100, defaults to 30.\n\ncategory : typing.Optional[VoicesGetSharedRequestCategory]\n    Voice category used for filtering\n\ngender : typing.Optional[str]\n    Gender used for filtering\n\nage : typing.Optional[str]\n    Age used for filtering\n\naccent : typing.Optional[str]\n    Accent used for filtering\n\nlanguage : typing.Optional[str]\n    Language used for filtering\n\nlocale : typing.Optional[str]\n    Locale used for filtering\n\nsearch : typing.Optional[str]\n    Search term used for filtering\n\nuse_cases : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Use-case used for filtering\n\ndescriptives : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Search term used for filtering\n\nfeatured : typing.Optional[bool]\n    Filter featured voices\n\nmin_notice_period_days : typing.Optional[int]\n    Filter voices with a minimum notice period of the given number of days.\n\ninclude_custom_rates : typing.Optional[bool]\n    Include/exclude voices with custom rates\n\ninclude_live_moderated : typing.Optional[bool]\n    Include/exclude voices that are live moderated\n\nreader_app_enabled : typing.Optional[bool]\n    Filter voices that are enabled for the reader app\n\nowner_id : typing.Optional[str]\n    Filter voices by public owner ID\n\nsort : typing.Optional[str]\n    Sort criteria\n\npage : typing.Optional[int]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetLibraryVoicesResponse\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.get_shared(\n    page_size=1,\n    category=\"professional\",\n    gender=\"gender\",\n    age=\"age\",\n    accent=\"accent\",\n    language=\"language\",\n    locale=\"locale\",\n    search=\"search\",\n    featured=True,\n    min_notice_period_days=1,\n    include_custom_rates=True,\n    include_live_moderated=True,\n    reader_app_enabled=True,\n    owner_id=\"owner_id\",\n    sort=\"sort\",\n    page=1,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 365
      },
      {
        "path": "client.voices.ivc.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "files",
            "type": "List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceIvcResponseModel",
        "docstring": "Create a voice clone and add it to your Voices\n\nParameters\n----------\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\ndescription : typing.Optional[str]\n    A description of the voice.\n\nlabels : typing.Optional[str]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceIvcResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.ivc.create(\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/ivc/client.py",
        "source_line": 30
      },
      {
        "path": "client.voices.ivc.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "files",
            "type": "List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a voice clone and add it to your Voices\n\nParameters\n----------\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\ndescription : typing.Optional[str]\n    A description of the voice.\n\nlabels : typing.Optional[str]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddVoiceIvcResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/ivc/raw_client.py",
        "source_line": 24
      },
      {
        "path": "client.voices.pvc.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceResponseModel",
        "docstring": "Creates a new PVC voice with metadata but no samples\n\nParameters\n----------\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nlanguage : str\n    Language used in the samples.\n\ndescription : typing.Optional[str]\n    Description to use for the created voice.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.create(\n    name=\"John Smith\",\n    language=\"en\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/client.py",
        "source_line": 38
      },
      {
        "path": "client.voices.pvc.samples.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceSamplePreviewResponseModel",
        "docstring": "Retrieve the first 30 seconds of voice sample audio with or without noise removal.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceSamplePreviewResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.samples.audio.get(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n    remove_background_noise=True,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/audio/client.py",
        "source_line": 26
      },
      {
        "path": "client.voices.pvc.samples.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve the first 30 seconds of voice sample audio with or without noise removal.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[VoiceSamplePreviewResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/audio/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.voices.pvc.samples.create",
        "name": "create",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "files",
            "type": "List[core.File]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "List[VoiceSample]",
        "docstring": "Add audio samples to a PVC voice\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.List[VoiceSample]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.samples.create(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/client.py",
        "source_line": 42
      },
      {
        "path": "client.voices.pvc.samples.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteVoiceSampleResponseModel",
        "docstring": "Delete a sample from a PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteVoiceSampleResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.samples.delete(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/client.py",
        "source_line": 158
      },
      {
        "path": "client.voices.pvc.samples.speakers.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeakerAudioResponseModel",
        "docstring": "Retrieve the separated audio for a specific speaker.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nspeaker_id : str\n    Speaker ID to be used, you can use GET https://api.elevenlabs.io/v1/voices/{voice_id}/samples/{sample_id}/speakers to list all the available speakers for a sample.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeakerAudioResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.samples.speakers.audio.get(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n    speaker_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/audio/client.py",
        "source_line": 26
      },
      {
        "path": "client.voices.pvc.samples.speakers.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve the separated audio for a specific speaker.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nspeaker_id : str\n    Speaker ID to be used, you can use GET https://api.elevenlabs.io/v1/voices/{voice_id}/samples/{sample_id}/speakers to list all the available speakers for a sample.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SpeakerAudioResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/audio/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.voices.pvc.samples.speakers.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeakerSeparationResponseModel",
        "docstring": "Retrieve the status of the speaker separation process and the list of detected speakers if complete.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeakerSeparationResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.samples.speakers.get(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/client.py",
        "source_line": 34
      },
      {
        "path": "client.voices.pvc.samples.speakers.separate",
        "name": "separate",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "StartSpeakerSeparationResponseModel",
        "docstring": "Start speaker separation process for a sample\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nStartSpeakerSeparationResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.samples.speakers.separate(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/client.py",
        "source_line": 71
      },
      {
        "path": "client.voices.pvc.samples.speakers.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve the status of the speaker separation process and the list of detected speakers if complete.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[SpeakerSeparationResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/raw_client.py",
        "source_line": 22
      },
      {
        "path": "client.voices.pvc.samples.speakers.with_raw_response.separate",
        "name": "separate",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Start speaker separation process for a sample\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[StartSpeakerSeparationResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/raw_client.py",
        "source_line": 75
      },
      {
        "path": "client.voices.pvc.samples.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "selected_speaker_ids",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "trim_start_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "trim_end_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceResponseModel",
        "docstring": "Update a PVC voice sample - apply noise removal, select speaker, change trim times or file name.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nselected_speaker_ids : typing.Optional[typing.Sequence[str]]\n    Speaker IDs to be used for PVC training. Make sure you send all the speaker IDs you want to use for PVC training in one request because the last request will override the previous ones.\n\ntrim_start_time : typing.Optional[int]\n    The start time of the audio to be used for PVC training. Time should be in milliseconds\n\ntrim_end_time : typing.Optional[int]\n    The end time of the audio to be used for PVC training. Time should be in milliseconds\n\nfile_name : typing.Optional[str]\n    The name of the audio file to be used for PVC training.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.samples.update(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/client.py",
        "source_line": 88
      },
      {
        "path": "client.voices.pvc.samples.waveform.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceSampleVisualWaveformResponseModel",
        "docstring": "Retrieve the visual waveform of a voice sample.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceSampleVisualWaveformResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.samples.waveform.get(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/waveform/client.py",
        "source_line": 26
      },
      {
        "path": "client.voices.pvc.samples.waveform.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieve the visual waveform of a voice sample.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[VoiceSampleVisualWaveformResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/waveform/raw_client.py",
        "source_line": 21
      },
      {
        "path": "client.voices.pvc.samples.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "files",
            "type": "List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Add audio samples to a PVC voice\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.List[VoiceSample]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/raw_client.py",
        "source_line": 27
      },
      {
        "path": "client.voices.pvc.samples.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete a sample from a PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteVoiceSampleResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/raw_client.py",
        "source_line": 184
      },
      {
        "path": "client.voices.pvc.samples.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "selected_speaker_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "trim_start_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "trim_end_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update a PVC voice sample - apply noise removal, select speaker, change trim times or file name.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nselected_speaker_ids : typing.Optional[typing.Sequence[str]]\n    Speaker IDs to be used for PVC training. Make sure you send all the speaker IDs you want to use for PVC training in one request because the last request will override the previous ones.\n\ntrim_start_time : typing.Optional[int]\n    The start time of the audio to be used for PVC training. Time should be in milliseconds\n\ntrim_end_time : typing.Optional[int]\n    The end time of the audio to be used for PVC training. Time should be in milliseconds\n\nfile_name : typing.Optional[str]\n    The name of the audio file to be used for PVC training.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddVoiceResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/raw_client.py",
        "source_line": 96
      },
      {
        "path": "client.voices.pvc.train",
        "name": "train",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "StartPvcVoiceTrainingResponseModel",
        "docstring": "Start PVC training process for a voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nmodel_id : typing.Optional[str]\n    The model ID to use for the conversion.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nStartPvcVoiceTrainingResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.train(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/client.py",
        "source_line": 148
      },
      {
        "path": "client.voices.pvc.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceResponseModel",
        "docstring": "Edit PVC voice metadata\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nname : typing.Optional[str]\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nlanguage : typing.Optional[str]\n    Language used in the samples.\n\ndescription : typing.Optional[str]\n    Description to use for the created voice.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.update(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/client.py",
        "source_line": 89
      },
      {
        "path": "client.voices.pvc.verification.captcha.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Get captcha for PVC voice verification.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.verification.captcha.get(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/captcha/client.py",
        "source_line": 30
      },
      {
        "path": "client.voices.pvc.verification.captcha.verify",
        "name": "verify",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "recording",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VerifyPvcVoiceCaptchaResponseModel",
        "docstring": "Submit captcha verification for PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrecording : core.File\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVerifyPvcVoiceCaptchaResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.verification.captcha.verify(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/captcha/client.py",
        "source_line": 60
      },
      {
        "path": "client.voices.pvc.verification.captcha.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Get captcha for PVC voice verification.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[None]",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/captcha/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.voices.pvc.verification.captcha.with_raw_response.verify",
        "name": "verify",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "recording",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Submit captcha verification for PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrecording : core.File\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[VerifyPvcVoiceCaptchaResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/captcha/raw_client.py",
        "source_line": 65
      },
      {
        "path": "client.voices.pvc.verification.request",
        "name": "request",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "files",
            "type": "List[core.File]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RequestPvcManualVerificationResponseModel",
        "docstring": "Request manual verification for a PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nextra_text : typing.Optional[str]\n    Extra text to be used in the manual verification process.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRequestPvcManualVerificationResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.pvc.verification.request(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/client.py",
        "source_line": 36
      },
      {
        "path": "client.voices.pvc.verification.with_raw_response.request",
        "name": "request",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "files",
            "type": "List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Request manual verification for a PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nextra_text : typing.Optional[str]\n    Extra text to be used in the manual verification process.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[RequestPvcManualVerificationResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.voices.pvc.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Creates a new PVC voice with metadata but no samples\n\nParameters\n----------\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nlanguage : str\n    Language used in the samples.\n\ndescription : typing.Optional[str]\n    Description to use for the created voice.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddVoiceResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.voices.pvc.with_raw_response.train",
        "name": "train",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Start PVC training process for a voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nmodel_id : typing.Optional[str]\n    The model ID to use for the conversion.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[StartPvcVoiceTrainingResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/raw_client.py",
        "source_line": 179
      },
      {
        "path": "client.voices.pvc.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Edit PVC voice metadata\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nname : typing.Optional[str]\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nlanguage : typing.Optional[str]\n    Language used in the samples.\n\ndescription : typing.Optional[str]\n    Description to use for the created voice.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddVoiceResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/raw_client.py",
        "source_line": 100
      },
      {
        "path": "client.voices.samples.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Returns the audio corresponding to a sample attached to a voice.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nsample_id : str\n    ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[bytes]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.samples.audio.get(\n    voice_id=\"voice_id\",\n    sample_id=\"sample_id\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/samples/audio/client.py",
        "source_line": 25
      },
      {
        "path": "client.voices.samples.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Iterator",
        "docstring": "Returns the audio corresponding to a sample attached to a voice.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nsample_id : str\n    ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.Iterator[HttpResponse[typing.Iterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 21
      },
      {
        "path": "client.voices.search",
        "name": "search",
        "parameters": [
          {
            "name": "next_page_token",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_type",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "category",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "fine_tuning_state",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "collection_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_total_count",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_ids",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetVoicesV2Response",
        "docstring": "Gets a list of all available voices for a user with search, filtering and pagination.\n\nParameters\n----------\nnext_page_token : typing.Optional[str]\n    The next page token to use for pagination. Returned from the previous request. Use this in combination with the has_more flag for reliable pagination.\n\npage_size : typing.Optional[int]\n    How many voices to return at maximum. Can not exceed 100, defaults to 10. Page 0 may include more voices due to default voices being included.\n\nsearch : typing.Optional[str]\n    Search term to filter voices by. Searches in name, description, labels, category.\n\nsort : typing.Optional[str]\n    Which field to sort by, one of 'created_at_unix' or 'name'. 'created_at_unix' may not be available for older voices.\n\nsort_direction : typing.Optional[str]\n    Which direction to sort the voices in. 'asc' or 'desc'.\n\nvoice_type : typing.Optional[str]\n    Type of the voice to filter by. One of 'personal', 'community', 'default', 'workspace', 'non-default'. 'non-default' is equal to all but 'default'.\n\ncategory : typing.Optional[str]\n    Category of the voice to filter by. One of 'premade', 'cloned', 'generated', 'professional'\n\nfine_tuning_state : typing.Optional[str]\n    State of the voice's fine tuning to filter by. Applicable only to professional voices clones. One of 'draft', 'not_verified', 'not_started', 'queued', 'fine_tuning', 'fine_tuned', 'failed', 'delayed'\n\ncollection_id : typing.Optional[str]\n    Collection ID to filter voices by.\n\ninclude_total_count : typing.Optional[bool]\n    Whether to include the total count of voices found in the response. NOTE: The total_count value is a live snapshot and may change between requests as users create, modify, or delete voices. For pagination, rely on the has_more flag instead. Only enable this when you actually need the total count (e.g., for display purposes), as it incurs a performance cost.\n\nvoice_ids : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Voice IDs to lookup by. Maximum 100 voice IDs.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetVoicesV2Response\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.search(\n    next_page_token=\"next_page_token\",\n    page_size=1,\n    search=\"search\",\n    sort=\"sort\",\n    sort_direction=\"sort_direction\",\n    voice_type=\"voice_type\",\n    category=\"category\",\n    fine_tuning_state=\"fine_tuning_state\",\n    collection_id=\"collection_id\",\n    include_total_count=True,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 82
      },
      {
        "path": "client.voices.settings.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceSettings",
        "docstring": "Returns the settings for a specific voice. \"similarity_boost\" corresponds to\"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceSettings\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.settings.get(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/client.py",
        "source_line": 56
      },
      {
        "path": "client.voices.settings.get_default",
        "name": "get_default",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceSettings",
        "docstring": "Gets the default settings for voices. \"similarity_boost\" corresponds to\"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceSettings\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.settings.get_default()",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/client.py",
        "source_line": 30
      },
      {
        "path": "client.voices.settings.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request",
            "type": "VoiceSettings",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditVoiceSettingsResponseModel",
        "docstring": "Edit your settings for a specific voice. \"similarity_boost\" corresponds to \"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nrequest : VoiceSettings\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditVoiceSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs, VoiceSettings\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.settings.update(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    request=VoiceSettings(\n        stability=1.0,\n        use_speaker_boost=True,\n        similarity_boost=1.0,\n        style=0.0,\n        speed=1.0,\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/client.py",
        "source_line": 87
      },
      {
        "path": "client.voices.settings.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns the settings for a specific voice. \"similarity_boost\" corresponds to\"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[VoiceSettings]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/raw_client.py",
        "source_line": 60
      },
      {
        "path": "client.voices.settings.with_raw_response.get_default",
        "name": "get_default",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets the default settings for voices. \"similarity_boost\" corresponds to\"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[VoiceSettings]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/raw_client.py",
        "source_line": 26
      },
      {
        "path": "client.voices.settings.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request",
            "type": "VoiceSettings",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Edit your settings for a specific voice. \"similarity_boost\" corresponds to \"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nrequest : VoiceSettings\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[EditVoiceSettingsResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/raw_client.py",
        "source_line": 110
      },
      {
        "path": "client.voices.share",
        "name": "share",
        "parameters": [
          {
            "name": "public_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "new_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceResponseModel",
        "docstring": "Add a shared voice to your collection of Voices\n\nParameters\n----------\npublic_user_id : str\n    Public user ID used to publicly identify ElevenLabs users.\n\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nnew_name : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.share(\n    public_user_id=\"63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca\",\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    new_name=\"John Smith\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 319
      },
      {
        "path": "client.voices.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "files",
            "type": "Optional[List[core.File]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditVoiceResponseModel",
        "docstring": "Edit a voice created by you.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nfiles : typing.Optional[typing.List[core.File]]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\ndescription : typing.Optional[str]\n    A description of the voice.\n\nlabels : typing.Optional[str]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.voices.update(\n    voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 254
      },
      {
        "path": "client.voices.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Deletes a voice by its ID.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteVoiceResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 251
      },
      {
        "path": "client.voices.with_raw_response.find_similar_voices",
        "name": "find_similar_voices",
        "parameters": [
          {
            "name": "audio_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "similarity_threshold",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "top_k",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns a list of shared voices similar to the provided audio sample. If neither similarity_threshold nor top_k is provided, we will apply default values.\n\nParameters\n----------\naudio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nsimilarity_threshold : typing.Optional[float]\n    Threshold for voice similarity between provided sample and library voices. Values range from 0 to 2. The smaller the value the more similar voices will be returned.\n\ntop_k : typing.Optional[int]\n    Number of most similar voices to return. If similarity_threshold is provided, less than this number of voices may be returned. Values range from 1 to 100.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetLibraryVoicesResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 593
      },
      {
        "path": "client.voices.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "with_settings",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns metadata about a specific voice.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nwith_settings : typing.Optional[bool]\n    This parameter is now deprecated. It is ignored and will be removed in a future version.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[Voice]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 191
      },
      {
        "path": "client.voices.with_raw_response.get_all",
        "name": "get_all",
        "parameters": [
          {
            "name": "show_legacy",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Returns a list of all available voices for a user.\n\nParameters\n----------\nshow_legacy : typing.Optional[bool]\n    If set to true, legacy premade voices will be included in responses from /v1/voices\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetVoicesResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 32
      },
      {
        "path": "client.voices.with_raw_response.get_shared",
        "name": "get_shared",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "category",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "gender",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "age",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "accent",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "locale",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_cases",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "descriptives",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "featured",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "min_notice_period_days",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_custom_rates",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_live_moderated",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "reader_app_enabled",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "owner_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Retrieves a list of shared voices.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many shared voices to return at maximum. Can not exceed 100, defaults to 30.\n\ncategory : typing.Optional[VoicesGetSharedRequestCategory]\n    Voice category used for filtering\n\ngender : typing.Optional[str]\n    Gender used for filtering\n\nage : typing.Optional[str]\n    Age used for filtering\n\naccent : typing.Optional[str]\n    Accent used for filtering\n\nlanguage : typing.Optional[str]\n    Language used for filtering\n\nlocale : typing.Optional[str]\n    Locale used for filtering\n\nsearch : typing.Optional[str]\n    Search term used for filtering\n\nuse_cases : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Use-case used for filtering\n\ndescriptives : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Search term used for filtering\n\nfeatured : typing.Optional[bool]\n    Filter featured voices\n\nmin_notice_period_days : typing.Optional[int]\n    Filter voices with a minimum notice period of the given number of days.\n\ninclude_custom_rates : typing.Optional[bool]\n    Include/exclude voices with custom rates\n\ninclude_live_moderated : typing.Optional[bool]\n    Include/exclude voices that are live moderated\n\nreader_app_enabled : typing.Optional[bool]\n    Filter voices that are enabled for the reader app\n\nowner_id : typing.Optional[str]\n    Filter voices by public owner ID\n\nsort : typing.Optional[str]\n    Sort criteria\n\npage : typing.Optional[int]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetLibraryVoicesResponse]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 453
      },
      {
        "path": "client.voices.with_raw_response.search",
        "name": "search",
        "parameters": [
          {
            "name": "next_page_token",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_type",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "category",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "fine_tuning_state",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "collection_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_total_count",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_ids",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets a list of all available voices for a user with search, filtering and pagination.\n\nParameters\n----------\nnext_page_token : typing.Optional[str]\n    The next page token to use for pagination. Returned from the previous request. Use this in combination with the has_more flag for reliable pagination.\n\npage_size : typing.Optional[int]\n    How many voices to return at maximum. Can not exceed 100, defaults to 10. Page 0 may include more voices due to default voices being included.\n\nsearch : typing.Optional[str]\n    Search term to filter voices by. Searches in name, description, labels, category.\n\nsort : typing.Optional[str]\n    Which field to sort by, one of 'created_at_unix' or 'name'. 'created_at_unix' may not be available for older voices.\n\nsort_direction : typing.Optional[str]\n    Which direction to sort the voices in. 'asc' or 'desc'.\n\nvoice_type : typing.Optional[str]\n    Type of the voice to filter by. One of 'personal', 'community', 'default', 'workspace', 'non-default'. 'non-default' is equal to all but 'default'.\n\ncategory : typing.Optional[str]\n    Category of the voice to filter by. One of 'premade', 'cloned', 'generated', 'professional'\n\nfine_tuning_state : typing.Optional[str]\n    State of the voice's fine tuning to filter by. Applicable only to professional voices clones. One of 'draft', 'not_verified', 'not_started', 'queued', 'fine_tuning', 'fine_tuned', 'failed', 'delayed'\n\ncollection_id : typing.Optional[str]\n    Collection ID to filter voices by.\n\ninclude_total_count : typing.Optional[bool]\n    Whether to include the total count of voices found in the response. NOTE: The total_count value is a live snapshot and may change between requests as users create, modify, or delete voices. For pagination, rely on the has_more flag instead. Only enable this when you actually need the total count (e.g., for display purposes), as it incurs a performance cost.\n\nvoice_ids : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Voice IDs to lookup by. Maximum 100 voice IDs.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[GetVoicesV2Response]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 85
      },
      {
        "path": "client.voices.with_raw_response.share",
        "name": "share",
        "parameters": [
          {
            "name": "public_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "new_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Add a shared voice to your collection of Voices\n\nParameters\n----------\npublic_user_id : str\n    Public user ID used to publicly identify ElevenLabs users.\n\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nnew_name : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddVoiceResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 385
      },
      {
        "path": "client.voices.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "files",
            "type": "Optional[List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Edit a voice created by you.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nfiles : typing.Optional[typing.List[core.File]]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\ndescription : typing.Optional[str]\n    A description of the voice.\n\nlabels : typing.Optional[str]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[EditVoiceResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 301
      },
      {
        "path": "client.webhooks.construct_event",
        "name": "construct_event",
        "parameters": [
          {
            "name": "rawBody",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sig_header",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "secret",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          }
        ],
        "return_type": "Dict",
        "docstring": "Constructs a webhook event object from a payload and signature.\nVerifies the webhook signature to ensure the event came from ElevenLabs.\n\nArgs:\n    rawBody: The webhook request body. Must be the raw body, not a JSON object\n    sig_header: The signature header from the request\n    secret: Your webhook secret\n\nReturns:\n    The verified webhook event\n\nRaises:\n    BadRequestError: If the signature is invalid or missing",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks_custom.py",
        "source_line": 17
      },
      {
        "path": "client.webhooks.create",
        "name": "create",
        "parameters": [
          {
            "name": "settings",
            "type": "WebhookHmacSettings",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceCreateWebhookResponseModel",
        "docstring": "Create a new webhook for the workspace with the specified authentication type.\n\nParameters\n----------\nsettings : WebhookHmacSettings\n    Webhook settings object containing auth_type and corresponding configuration\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceCreateWebhookResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs, WebhookHmacSettings\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.webhooks.create(\n    settings=WebhookHmacSettings(\n        name=\"name\",\n        webhook_url=\"webhook_url\",\n    ),\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/client.py",
        "source_line": 66
      },
      {
        "path": "client.webhooks.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "webhook_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteWorkspaceWebhookResponseModel",
        "docstring": "Delete the specified workspace webhook\n\nParameters\n----------\nwebhook_id : str\n    The unique ID for the webhook\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteWorkspaceWebhookResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.webhooks.delete(\n    webhook_id=\"G007vmtq9uWYl7SUW9zGS8GZZa1K\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/client.py",
        "source_line": 102
      },
      {
        "path": "client.webhooks.list",
        "name": "list",
        "parameters": [
          {
            "name": "include_usages",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceWebhookListResponseModel",
        "docstring": "List all webhooks for a workspace\n\nParameters\n----------\ninclude_usages : typing.Optional[bool]\n    Whether to include active usages of the webhook, only usable by admins\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceWebhookListResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.webhooks.list(\n    include_usages=False,\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/client.py",
        "source_line": 33
      },
      {
        "path": "client.webhooks.update",
        "name": "update",
        "parameters": [
          {
            "name": "webhook_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "is_disabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PatchWorkspaceWebhookResponseModel",
        "docstring": "Update the specified workspace webhook\n\nParameters\n----------\nwebhook_id : str\n    The unique ID for the webhook\n\nis_disabled : bool\n    Whether to disable or enable the webhook\n\nname : str\n    The display name of the webhook (used for display purposes only).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPatchWorkspaceWebhookResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.webhooks.update(\n    webhook_id=\"G007vmtq9uWYl7SUW9zGS8GZZa1K\",\n    is_disabled=True,\n    name=\"My Callback Webhook\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/client.py",
        "source_line": 135
      },
      {
        "path": "client.webhooks.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "settings",
            "type": "WebhookHmacSettings",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Create a new webhook for the workspace with the specified authentication type.\n\nParameters\n----------\nsettings : WebhookHmacSettings\n    Webhook settings object containing auth_type and corresponding configuration\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[WorkspaceCreateWebhookResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/raw_client.py",
        "source_line": 82
      },
      {
        "path": "client.webhooks.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "webhook_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Delete the specified workspace webhook\n\nParameters\n----------\nwebhook_id : str\n    The unique ID for the webhook\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteWorkspaceWebhookResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/raw_client.py",
        "source_line": 141
      },
      {
        "path": "client.webhooks.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "include_usages",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "List all webhooks for a workspace\n\nParameters\n----------\ninclude_usages : typing.Optional[bool]\n    Whether to include active usages of the webhook, only usable by admins\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[WorkspaceWebhookListResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/raw_client.py",
        "source_line": 29
      },
      {
        "path": "client.webhooks.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "webhook_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "is_disabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Update the specified workspace webhook\n\nParameters\n----------\nwebhook_id : str\n    The unique ID for the webhook\n\nis_disabled : bool\n    Whether to disable or enable the webhook\n\nname : str\n    The display name of the webhook (used for display purposes only).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[PatchWorkspaceWebhookResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/raw_client.py",
        "source_line": 191
      },
      {
        "path": "client.workspace.groups.members.add",
        "name": "add",
        "parameters": [
          {
            "name": "group_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddWorkspaceGroupMemberResponseModel",
        "docstring": "Adds a member of your workspace to the specified group. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\ngroup_id : str\n    The ID of the target group.\n\nemail : str\n    The email of the target workspace member.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddWorkspaceGroupMemberResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.groups.members.add(\n    group_id=\"group_id\",\n    email=\"email\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/members/client.py",
        "source_line": 67
      },
      {
        "path": "client.workspace.groups.members.remove",
        "name": "remove",
        "parameters": [
          {
            "name": "group_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteWorkspaceGroupMemberResponseModel",
        "docstring": "Removes a member from the specified group. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\ngroup_id : str\n    The ID of the target group.\n\nemail : str\n    The email of the target workspace member.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteWorkspaceGroupMemberResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.groups.members.remove(\n    group_id=\"group_id\",\n    email=\"email\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/members/client.py",
        "source_line": 30
      },
      {
        "path": "client.workspace.groups.members.with_raw_response.add",
        "name": "add",
        "parameters": [
          {
            "name": "group_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Adds a member of your workspace to the specified group. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\ngroup_id : str\n    The ID of the target group.\n\nemail : str\n    The email of the target workspace member.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddWorkspaceGroupMemberResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/members/raw_client.py",
        "source_line": 85
      },
      {
        "path": "client.workspace.groups.members.with_raw_response.remove",
        "name": "remove",
        "parameters": [
          {
            "name": "group_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Removes a member from the specified group. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\ngroup_id : str\n    The ID of the target group.\n\nemail : str\n    The email of the target workspace member.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteWorkspaceGroupMemberResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/members/raw_client.py",
        "source_line": 25
      },
      {
        "path": "client.workspace.groups.search",
        "name": "search",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "List[WorkspaceGroupByNameResponseModel]",
        "docstring": "Searches for user groups in the workspace. Multiple or no groups may be returned.\n\nParameters\n----------\nname : str\n    Name of the target group.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.List[WorkspaceGroupByNameResponseModel]\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.groups.search(\n    name=\"name\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/client.py",
        "source_line": 33
      },
      {
        "path": "client.workspace.groups.with_raw_response.search",
        "name": "search",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Searches for user groups in the workspace. Multiple or no groups may be returned.\n\nParameters\n----------\nname : str\n    Name of the target group.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.List[WorkspaceGroupByNameResponseModel]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/raw_client.py",
        "source_line": 20
      },
      {
        "path": "client.workspace.invites.create",
        "name": "create",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_permission",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddWorkspaceInviteResponseModel",
        "docstring": "Sends an email invitation to join your workspace to the provided email. If the user doesn't have an account they will be prompted to create one. If the user accepts this invite they will be added as a user to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators. If the user is already in the workspace a 400 error will be returned.\n\nParameters\n----------\nemail : str\n    The email of the customer\n\ngroup_ids : typing.Optional[typing.Sequence[str]]\n    The group ids of the user\n\nworkspace_permission : typing.Optional[BodyInviteUserV1WorkspaceInvitesAddPostWorkspacePermission]\n    The workspace permission of the user\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddWorkspaceInviteResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.invites.create(\n    email=\"john.doe@testmail.com\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/client.py",
        "source_line": 33
      },
      {
        "path": "client.workspace.invites.create_batch",
        "name": "create_batch",
        "parameters": [
          {
            "name": "emails",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddWorkspaceInviteResponseModel",
        "docstring": "Sends email invitations to join your workspace to the provided emails. Requires all email addresses to be part of a verified domain. If the users don't have an account they will be prompted to create one. If the users accept these invites they will be added as users to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemails : typing.Sequence[str]\n    The email of the customer\n\ngroup_ids : typing.Optional[typing.Sequence[str]]\n    The group ids of the user\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddWorkspaceInviteResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.invites.create_batch(\n    emails=[\"emails\"],\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/client.py",
        "source_line": 79
      },
      {
        "path": "client.workspace.invites.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteWorkspaceInviteResponseModel",
        "docstring": "Invalidates an existing email invitation. The invitation will still show up in the inbox it has been delivered to, but activating it to join the workspace won't work. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemail : str\n    The email of the customer\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteWorkspaceInviteResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.invites.delete(\n    email=\"john.doe@testmail.com\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/client.py",
        "source_line": 119
      },
      {
        "path": "client.workspace.invites.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_permission",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Sends an email invitation to join your workspace to the provided email. If the user doesn't have an account they will be prompted to create one. If the user accepts this invite they will be added as a user to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators. If the user is already in the workspace a 400 error will be returned.\n\nParameters\n----------\nemail : str\n    The email of the customer\n\ngroup_ids : typing.Optional[typing.Sequence[str]]\n    The group ids of the user\n\nworkspace_permission : typing.Optional[BodyInviteUserV1WorkspaceInvitesAddPostWorkspacePermission]\n    The workspace permission of the user\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddWorkspaceInviteResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/raw_client.py",
        "source_line": 27
      },
      {
        "path": "client.workspace.invites.with_raw_response.create_batch",
        "name": "create_batch",
        "parameters": [
          {
            "name": "emails",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Sends email invitations to join your workspace to the provided emails. Requires all email addresses to be part of a verified domain. If the users don't have an account they will be prompted to create one. If the users accept these invites they will be added as users to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemails : typing.Sequence[str]\n    The email of the customer\n\ngroup_ids : typing.Optional[typing.Sequence[str]]\n    The group ids of the user\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[AddWorkspaceInviteResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/raw_client.py",
        "source_line": 97
      },
      {
        "path": "client.workspace.invites.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Invalidates an existing email invitation. The invitation will still show up in the inbox it has been delivered to, but activating it to join the workspace won't work. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemail : str\n    The email of the customer\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[DeleteWorkspaceInviteResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/raw_client.py",
        "source_line": 162
      },
      {
        "path": "client.workspace.members.update",
        "name": "update",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "is_locked",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_role",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "UpdateWorkspaceMemberResponseModel",
        "docstring": "Updates attributes of a workspace member. Apart from the email identifier, all parameters will remain unchanged unless specified. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemail : str\n    Email of the target user.\n\nis_locked : typing.Optional[bool]\n    Whether to lock or unlock the user account.\n\nworkspace_role : typing.Optional[BodyUpdateMemberV1WorkspaceMembersPostWorkspaceRole]\n    Role dictating permissions in the workspace.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nUpdateWorkspaceMemberResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.members.update(\n    email=\"email\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/members/client.py",
        "source_line": 32
      },
      {
        "path": "client.workspace.members.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "is_locked",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_role",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Updates attributes of a workspace member. Apart from the email identifier, all parameters will remain unchanged unless specified. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemail : str\n    Email of the target user.\n\nis_locked : typing.Optional[bool]\n    Whether to lock or unlock the user account.\n\nworkspace_role : typing.Optional[BodyUpdateMemberV1WorkspaceMembersPostWorkspaceRole]\n    Role dictating permissions in the workspace.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[UpdateWorkspaceMemberResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/members/raw_client.py",
        "source_line": 26
      },
      {
        "path": "client.workspace.resources.get",
        "name": "get",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ResourceMetadataResponseModel",
        "docstring": "Gets the metadata of a resource by ID.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nResourceMetadataResponseModel\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.resources.get(\n    resource_id=\"resource_id\",\n    resource_type=\"voice\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/client.py",
        "source_line": 33
      },
      {
        "path": "client.workspace.resources.share",
        "name": "share",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "role",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_email",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_api_key_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Grants a role on a workspace resource to a user or a group. It overrides any existing role this user/service account/group/workspace api key has on the resource. To target a user or service account, pass only the user email. The user must be in your workspace. To target a group, pass only the group id. To target a workspace api key, pass the api key id. The resource will be shared with the service account associated with the api key. You must have admin access to the resource to share it.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nrole : BodyShareWorkspaceResourceV1WorkspaceResourcesResourceIdSharePostRole\n    Role to update the target principal with.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nuser_email : typing.Optional[str]\n    The email of the user or service account.\n\ngroup_id : typing.Optional[str]\n    The ID of the target group. To target the permissions principals have by default on this resource, use the value 'default'.\n\nworkspace_api_key_id : typing.Optional[str]\n    The ID of the target workspace API key. This isn't the same as the key itself that would you pass in the header for authentication. Workspace admins can find this in the workspace settings UI.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.resources.share(\n    resource_id=\"resource_id\",\n    role=\"admin\",\n    resource_type=\"voice\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/client.py",
        "source_line": 74
      },
      {
        "path": "client.workspace.resources.unshare",
        "name": "unshare",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_email",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_api_key_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Removes any existing role on a workspace resource from a user, service account, group or workspace api key. To target a user or service account, pass only the user email. The user must be in your workspace. To target a group, pass only the group id. To target a workspace api key, pass the api key id. The resource will be unshared from the service account associated with the api key. You must have admin access to the resource to unshare it. You cannot remove permissions from the user who created the resource.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nuser_email : typing.Optional[str]\n    The email of the user or service account.\n\ngroup_id : typing.Optional[str]\n    The ID of the target group. To target the permissions principals have by default on this resource, use the value 'default'.\n\nworkspace_api_key_id : typing.Optional[str]\n    The ID of the target workspace API key. This isn't the same as the key itself that would you pass in the header for authentication. Workspace admins can find this in the workspace settings UI.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nfrom elevenlabs import ElevenLabs\n\nclient = ElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\nclient.workspace.resources.unshare(\n    resource_id=\"resource_id\",\n    resource_type=\"voice\",\n)",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/client.py",
        "source_line": 140
      },
      {
        "path": "client.workspace.resources.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Gets the metadata of a resource by ID.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[ResourceMetadataResponseModel]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/raw_client.py",
        "source_line": 28
      },
      {
        "path": "client.workspace.resources.with_raw_response.share",
        "name": "share",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "role",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_email",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_api_key_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Grants a role on a workspace resource to a user or a group. It overrides any existing role this user/service account/group/workspace api key has on the resource. To target a user or service account, pass only the user email. The user must be in your workspace. To target a group, pass only the group id. To target a workspace api key, pass the api key id. The resource will be shared with the service account associated with the api key. You must have admin access to the resource to share it.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nrole : BodyShareWorkspaceResourceV1WorkspaceResourcesResourceIdSharePostRole\n    Role to update the target principal with.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nuser_email : typing.Optional[str]\n    The email of the user or service account.\n\ngroup_id : typing.Optional[str]\n    The ID of the target group. To target the permissions principals have by default on this resource, use the value 'default'.\n\nworkspace_api_key_id : typing.Optional[str]\n    The ID of the target workspace API key. This isn't the same as the key itself that would you pass in the header for authentication. Workspace admins can find this in the workspace settings UI.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/raw_client.py",
        "source_line": 88
      },
      {
        "path": "client.workspace.resources.with_raw_response.unshare",
        "name": "unshare",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_email",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_api_key_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "HttpResponse",
        "docstring": "Removes any existing role on a workspace resource from a user, service account, group or workspace api key. To target a user or service account, pass only the user email. The user must be in your workspace. To target a group, pass only the group id. To target a workspace api key, pass the api key id. The resource will be unshared from the service account associated with the api key. You must have admin access to the resource to unshare it. You cannot remove permissions from the user who created the resource.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nuser_email : typing.Optional[str]\n    The email of the user or service account.\n\ngroup_id : typing.Optional[str]\n    The ID of the target group. To target the permissions principals have by default on this resource, use the value 'default'.\n\nworkspace_api_key_id : typing.Optional[str]\n    The ID of the target workspace API key. This isn't the same as the key itself that would you pass in the header for authentication. Workspace admins can find this in the workspace settings UI.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nHttpResponse[typing.Any]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/raw_client.py",
        "source_line": 174
      }
    ]
  },
  "async_client": {
    "name": "AsyncElevenLabs",
    "methods_count": 452,
    "methods": [
      {
        "path": "async_client.audio_isolation.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "preview_b_64",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Removes background noise from audio.\n\nParameters\n----------\naudio : core.File\n    See core.File for more documentation\n\nfile_format : typing.Optional[AudioIsolationConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\npreview_b_64 : typing.Optional[str]\n    Optional preview image base64 for tracking this generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_isolation/client.py",
        "source_line": 111
      },
      {
        "path": "async_client.audio_isolation.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Removes background noise from audio.\n\nParameters\n----------\naudio : core.File\n    See core.File for more documentation\n\nfile_format : typing.Optional[AudioIsolationStreamRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_isolation/client.py",
        "source_line": 147
      },
      {
        "path": "async_client.audio_isolation.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "preview_b_64",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Removes background noise from audio.\n\nParameters\n----------\naudio : core.File\n    See core.File for more documentation\n\nfile_format : typing.Optional[AudioIsolationConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\npreview_b_64 : typing.Optional[str]\n    Optional preview image base64 for tracking this generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 174
      },
      {
        "path": "async_client.audio_isolation.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Removes background noise from audio.\n\nParameters\n----------\naudio : core.File\n    See core.File for more documentation\n\nfile_format : typing.Optional[AudioIsolationStreamRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 249
      },
      {
        "path": "async_client.audio_native.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "image",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "small",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text_color",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "background_color",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sessionization",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AudioNativeCreateProjectResponseModel",
        "docstring": "Creates Audio Native enabled project, optionally starts conversion and returns project ID and embeddable HTML snippet.\n\nParameters\n----------\nname : str\n    Project name.\n\nimage : typing.Optional[str]\n    (Deprecated) Image URL used in the player. If not provided, default image set in the Player settings is used.\n\nauthor : typing.Optional[str]\n    Author used in the player and inserted at the start of the uploaded article. If not provided, the default author set in the Player settings is used.\n\ntitle : typing.Optional[str]\n    Title used in the player and inserted at the top of the uploaded article. If not provided, the default title set in the Player settings is used.\n\nsmall : typing.Optional[bool]\n    (Deprecated) Whether to use small player or not. If not provided, default value set in the Player settings is used.\n\ntext_color : typing.Optional[str]\n    Text color used in the player. If not provided, default text color set in the Player settings is used.\n\nbackground_color : typing.Optional[str]\n    Background color used in the player. If not provided, default background color set in the Player settings is used.\n\nsessionization : typing.Optional[int]\n    (Deprecated) Specifies for how many minutes to persist the session across page reloads. If not provided, default sessionization set in the Player settings is used.\n\nvoice_id : typing.Optional[str]\n    Voice ID used to voice the content. If not provided, default voice ID set in the Player settings is used.\n\nmodel_id : typing.Optional[str]\n    TTS Model ID used in the player. If not provided, default model ID set in the Player settings is used.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the project to audio or not.\n\napply_text_normalization : typing.Optional[AudioNativeCreateRequestApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\npronunciation_dictionary_locators : typing.Optional[typing.List[str]]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAudioNativeCreateProjectResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.audio_native.create(\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/client.py",
        "source_line": 241
      },
      {
        "path": "async_client.audio_native.get_settings",
        "name": "get_settings",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAudioNativeProjectSettingsResponseModel",
        "docstring": "Get player settings for the specific project.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAudioNativeProjectSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.audio_native.get_settings(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/client.py",
        "source_line": 358
      },
      {
        "path": "async_client.audio_native.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_publish",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AudioNativeEditContentResponseModel",
        "docstring": "Updates content for the specific AudioNative Project.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the project to audio or not.\n\nauto_publish : typing.Optional[bool]\n    Whether to auto publish the new project snapshot after it's converted.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAudioNativeEditContentResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.audio_native.update(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/client.py",
        "source_line": 399
      },
      {
        "path": "async_client.audio_native.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "image",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "small",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text_color",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "background_color",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sessionization",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Creates Audio Native enabled project, optionally starts conversion and returns project ID and embeddable HTML snippet.\n\nParameters\n----------\nname : str\n    Project name.\n\nimage : typing.Optional[str]\n    (Deprecated) Image URL used in the player. If not provided, default image set in the Player settings is used.\n\nauthor : typing.Optional[str]\n    Author used in the player and inserted at the start of the uploaded article. If not provided, the default author set in the Player settings is used.\n\ntitle : typing.Optional[str]\n    Title used in the player and inserted at the top of the uploaded article. If not provided, the default title set in the Player settings is used.\n\nsmall : typing.Optional[bool]\n    (Deprecated) Whether to use small player or not. If not provided, default value set in the Player settings is used.\n\ntext_color : typing.Optional[str]\n    Text color used in the player. If not provided, default text color set in the Player settings is used.\n\nbackground_color : typing.Optional[str]\n    Background color used in the player. If not provided, default background color set in the Player settings is used.\n\nsessionization : typing.Optional[int]\n    (Deprecated) Specifies for how many minutes to persist the session across page reloads. If not provided, default sessionization set in the Player settings is used.\n\nvoice_id : typing.Optional[str]\n    Voice ID used to voice the content. If not provided, default voice ID set in the Player settings is used.\n\nmodel_id : typing.Optional[str]\n    TTS Model ID used in the player. If not provided, default model ID set in the Player settings is used.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the project to audio or not.\n\napply_text_normalization : typing.Optional[AudioNativeCreateRequestApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\npronunciation_dictionary_locators : typing.Optional[typing.List[str]]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AudioNativeCreateProjectResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/raw_client.py",
        "source_line": 287
      },
      {
        "path": "async_client.audio_native.with_raw_response.get_settings",
        "name": "get_settings",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get player settings for the specific project.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetAudioNativeProjectSettingsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/raw_client.py",
        "source_line": 417
      },
      {
        "path": "async_client.audio_native.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_publish",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Updates content for the specific AudioNative Project.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the project to audio or not.\n\nauto_publish : typing.Optional[bool]\n    Whether to auto publish the new project snapshot after it's converted.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AudioNativeEditContentResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/audio_native/raw_client.py",
        "source_line": 467
      },
      {
        "path": "async_client.conversational_ai.add_to_knowledge_base",
        "name": "add_to_knowledge_base",
        "parameters": [
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddKnowledgeBaseResponseModel",
        "docstring": "Upload a file or webpage URL to create a knowledge base document. <br> <Note> After creating the document, update the agent's knowledge base by calling [Update agent](/docs/api-reference/agents/update). </Note>\n\nParameters\n----------\nagent_id : typing.Optional[str]\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nurl : typing.Optional[str]\n    URL to a page of documentation that the agent will have access to in order to interact with users.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddKnowledgeBaseResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.add_to_knowledge_base(\n        agent_id=\"agent_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/client.py",
        "source_line": 368
      },
      {
        "path": "async_client.conversational_ai.agents.create",
        "name": "create",
        "parameters": [
          {
            "name": "conversation_config",
            "type": "ConversationalConfig",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "platform_settings",
            "type": "Optional[AgentPlatformSettingsRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workflow",
            "type": "Optional[AgentWorkflowRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tags",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreateAgentResponseModel",
        "docstring": "Create an agent from a config object\n\nParameters\n----------\nconversation_config : ConversationalConfig\n    Conversation configuration for an agent\n\nplatform_settings : typing.Optional[AgentPlatformSettingsRequestModel]\n    Platform settings for the agent are all settings that aren't related to the conversation orchestration and content.\n\nworkflow : typing.Optional[AgentWorkflowRequestModel]\n    Workflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\ntags : typing.Optional[typing.Sequence[str]]\n    Tags to help classify and filter the agent\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreateAgentResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, ConversationalConfig\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.create(\n        conversation_config=ConversationalConfig(),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 588
      },
      {
        "path": "async_client.conversational_ai.agents.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "None",
        "docstring": "Delete an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.delete(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 696
      },
      {
        "path": "async_client.conversational_ai.agents.duplicate",
        "name": "duplicate",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreateAgentResponseModel",
        "docstring": "Create a new agent by duplicating an existing one\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreateAgentResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.duplicate(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 883
      },
      {
        "path": "async_client.conversational_ai.agents.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentResponseModel",
        "docstring": "Retrieve config for an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.get(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 655
      },
      {
        "path": "async_client.conversational_ai.agents.knowledge_base.size",
        "name": "size",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentKnowledgebaseSizeResponseModel",
        "docstring": "Returns the number of pages in the agent's knowledge base.\n\nParameters\n----------\nagent_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentKnowledgebaseSizeResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.knowledge_base.size(\n        agent_id=\"agent_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/knowledge_base/client.py",
        "source_line": 74
      },
      {
        "path": "async_client.conversational_ai.agents.knowledge_base.with_raw_response.size",
        "name": "size",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns the number of pages in the agent's knowledge base.\n\nParameters\n----------\nagent_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetAgentKnowledgebaseSizeResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/knowledge_base/raw_client.py",
        "source_line": 75
      },
      {
        "path": "async_client.conversational_ai.agents.link.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentLinkResponseModel",
        "docstring": "Get the current link used to share the agent with others\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentLinkResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.link.get(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/link/client.py",
        "source_line": 75
      },
      {
        "path": "async_client.conversational_ai.agents.link.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get the current link used to share the agent with others\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetAgentLinkResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/link/raw_client.py",
        "source_line": 76
      },
      {
        "path": "async_client.conversational_ai.agents.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "archived",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[SortDirection]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_by",
            "type": "Optional[AgentSortBy]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentsPageResponseModel",
        "docstring": "Returns a list of your agents and their metadata.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many Agents to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    Search by agents name.\n\narchived : typing.Optional[bool]\n    Filter agents by archived status\n\nsort_direction : typing.Optional[SortDirection]\n    The direction to sort the results\n\nsort_by : typing.Optional[AgentSortBy]\n    The field to sort the results by\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentsPageResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.list(\n        page_size=1,\n        search=\"search\",\n        archived=True,\n        sort_direction=\"asc\",\n        sort_by=\"name\",\n        cursor=\"cursor\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 806
      },
      {
        "path": "async_client.conversational_ai.agents.llm_usage.calculate",
        "name": "calculate",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "prompt_length",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "number_of_pages",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_enabled",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "LlmUsageCalculatorResponseModel",
        "docstring": "Calculates expected number of LLM tokens needed for the specified agent.\n\nParameters\n----------\nagent_id : str\n\nprompt_length : typing.Optional[int]\n    Length of the prompt in characters.\n\nnumber_of_pages : typing.Optional[int]\n    Pages of content in pdf documents OR urls in agent's Knowledge Base.\n\nrag_enabled : typing.Optional[bool]\n    Whether RAG is enabled.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nLlmUsageCalculatorResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.llm_usage.calculate(\n        agent_id=\"agent_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/llm_usage/client.py",
        "source_line": 98
      },
      {
        "path": "async_client.conversational_ai.agents.llm_usage.with_raw_response.calculate",
        "name": "calculate",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "prompt_length",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "number_of_pages",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_enabled",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Calculates expected number of LLM tokens needed for the specified agent.\n\nParameters\n----------\nagent_id : str\n\nprompt_length : typing.Optional[int]\n    Length of the prompt in characters.\n\nnumber_of_pages : typing.Optional[int]\n    Pages of content in pdf documents OR urls in agent's Knowledge Base.\n\nrag_enabled : typing.Optional[bool]\n    Whether RAG is enabled.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[LlmUsageCalculatorResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/llm_usage/raw_client.py",
        "source_line": 102
      },
      {
        "path": "async_client.conversational_ai.agents.run_tests",
        "name": "run_tests",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tests",
            "type": "Sequence[SingleTestRunRequestModel]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_config_override",
            "type": "Optional[AdhocAgentConfigOverrideForTestRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "branch_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestSuiteInvocationResponseModel",
        "docstring": "Run selected tests on the agent with provided configuration. If the agent configuration is provided, it will be used to override default agent configuration.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\ntests : typing.Sequence[SingleTestRunRequestModel]\n    List of tests to run on the agent\n\nagent_config_override : typing.Optional[AdhocAgentConfigOverrideForTestRequestModel]\n    Configuration overrides to use for testing. If not provided, the agent's default configuration will be used.\n\nbranch_id : typing.Optional[str]\n    ID of the branch to run the tests on. If not provided, the tests will be run on the agent default configuration.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestSuiteInvocationResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, SingleTestRunRequestModel\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.run_tests(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n        tests=[\n            SingleTestRunRequestModel(\n                test_id=\"test_id\",\n            )\n        ],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 1076
      },
      {
        "path": "async_client.conversational_ai.agents.simulate_conversation",
        "name": "simulate_conversation",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "simulation_specification",
            "type": "ConversationSimulationSpecification",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_evaluation_criteria",
            "type": "Optional[Sequence[PromptEvaluationCriteria]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "new_turns_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AgentSimulatedChatTestResponseModel",
        "docstring": "Run a conversation between the agent and a simulated user.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nsimulation_specification : ConversationSimulationSpecification\n    A specification detailing how the conversation should be simulated\n\nextra_evaluation_criteria : typing.Optional[typing.Sequence[PromptEvaluationCriteria]]\n    A list of evaluation criteria to test\n\nnew_turns_limit : typing.Optional[int]\n    Maximum number of new turns to generate in the conversation simulation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAgentSimulatedChatTestResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import (\n    AgentConfig,\n    AsyncElevenLabs,\n    ConversationSimulationSpecification,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.simulate_conversation(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n        simulation_specification=ConversationSimulationSpecification(\n            simulated_user_config=AgentConfig(\n                first_message=\"Hello, how can I help you today?\",\n                language=\"en\",\n                disable_first_message_interruptions=False,\n            ),\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 931
      },
      {
        "path": "async_client.conversational_ai.agents.simulate_conversation_stream",
        "name": "simulate_conversation_stream",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "simulation_specification",
            "type": "ConversationSimulationSpecification",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_evaluation_criteria",
            "type": "Optional[Sequence[PromptEvaluationCriteria]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "new_turns_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "None",
        "docstring": "Run a conversation between the agent and a simulated user and stream back the response. Response is streamed back as partial lists of messages that should be concatenated and once the conversation has complete a single final message with the conversation analysis will be sent.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nsimulation_specification : ConversationSimulationSpecification\n    A specification detailing how the conversation should be simulated\n\nextra_evaluation_criteria : typing.Optional[typing.Sequence[PromptEvaluationCriteria]]\n    A list of evaluation criteria to test\n\nnew_turns_limit : typing.Optional[int]\n    Maximum number of new turns to generate in the conversation simulation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import (\n    AgentConfig,\n    AsyncElevenLabs,\n    ConversationSimulationSpecification,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.simulate_conversation_stream(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n        simulation_specification=ConversationSimulationSpecification(\n            simulated_user_config=AgentConfig(\n                first_message=\"Hello, how can I help you today?\",\n                language=\"en\",\n                disable_first_message_interruptions=False,\n            ),\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 1004
      },
      {
        "path": "async_client.conversational_ai.agents.update",
        "name": "update",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "conversation_config",
            "type": "Optional[ConversationalConfig]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "platform_settings",
            "type": "Optional[AgentPlatformSettingsRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workflow",
            "type": "Optional[AgentWorkflowRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tags",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentResponseModel",
        "docstring": "Patches an Agent settings\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nconversation_config : typing.Optional[ConversationalConfig]\n    Conversation configuration for an agent\n\nplatform_settings : typing.Optional[AgentPlatformSettingsRequestModel]\n    Platform settings for the agent are all settings that aren't related to the conversation orchestration and content.\n\nworkflow : typing.Optional[AgentWorkflowRequestModel]\n    Workflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\ntags : typing.Optional[typing.Sequence[str]]\n    Tags to help classify and filter the agent\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.update(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/client.py",
        "source_line": 734
      },
      {
        "path": "async_client.conversational_ai.agents.widget.avatar.create",
        "name": "create",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "avatar_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PostAgentAvatarResponseModel",
        "docstring": "Sets the avatar for an agent displayed in the widget\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\navatar_file : core.File\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPostAgentAvatarResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.widget.avatar.create(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/widget/avatar/client.py",
        "source_line": 82
      },
      {
        "path": "async_client.conversational_ai.agents.widget.avatar.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "avatar_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Sets the avatar for an agent displayed in the widget\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\navatar_file : core.File\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PostAgentAvatarResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/widget/avatar/raw_client.py",
        "source_line": 89
      },
      {
        "path": "async_client.conversational_ai.agents.widget.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "conversation_signature",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetAgentEmbedResponseModel",
        "docstring": "Retrieve the widget configuration for an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nconversation_signature : typing.Optional[str]\n    An expiring token that enables a websocket conversation to start. These can be generated for an agent using the /v1/convai/conversation/get-signed-url endpoint\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetAgentEmbedResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.agents.widget.get(\n        agent_id=\"agent_3701k3ttaq12ewp8b7qv5rfyszkz\",\n        conversation_signature=\"conversation_signature\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/widget/client.py",
        "source_line": 102
      },
      {
        "path": "async_client.conversational_ai.agents.widget.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "conversation_signature",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve the widget configuration for an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nconversation_signature : typing.Optional[str]\n    An expiring token that enables a websocket conversation to start. These can be generated for an agent using the /v1/convai/conversation/get-signed-url endpoint\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetAgentEmbedResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/widget/raw_client.py",
        "source_line": 86
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "conversation_config",
            "type": "ConversationalConfig",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "platform_settings",
            "type": "Optional[AgentPlatformSettingsRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workflow",
            "type": "Optional[AgentWorkflowRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tags",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create an agent from a config object\n\nParameters\n----------\nconversation_config : ConversationalConfig\n    Conversation configuration for an agent\n\nplatform_settings : typing.Optional[AgentPlatformSettingsRequestModel]\n    Platform settings for the agent are all settings that aren't related to the conversation orchestration and content.\n\nworkflow : typing.Optional[AgentWorkflowRequestModel]\n    Workflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\ntags : typing.Optional[typing.Sequence[str]]\n    Tags to help classify and filter the agent\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[CreateAgentResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 686
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[None]",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 822
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.duplicate",
        "name": "duplicate",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a new agent by duplicating an existing one\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[CreateAgentResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 1035
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve config for an agent\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetAgentResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 772
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "archived",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_by",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns a list of your agents and their metadata.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many Agents to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    Search by agents name.\n\narchived : typing.Optional[bool]\n    Filter agents by archived status\n\nsort_direction : typing.Optional[SortDirection]\n    The direction to sort the results\n\nsort_by : typing.Optional[AgentSortBy]\n    The field to sort the results by\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetAgentsPageResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 954
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.run_tests",
        "name": "run_tests",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tests",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_config_override",
            "type": "Optional[AdhocAgentConfigOverrideForTestRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "branch_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Run selected tests on the agent with provided configuration. If the agent configuration is provided, it will be used to override default agent configuration.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\ntests : typing.Sequence[SingleTestRunRequestModel]\n    List of tests to run on the agent\n\nagent_config_override : typing.Optional[AdhocAgentConfigOverrideForTestRequestModel]\n    Configuration overrides to use for testing. If not provided, the agent's default configuration will be used.\n\nbranch_id : typing.Optional[str]\n    ID of the branch to run the tests on. If not provided, the tests will be run on the agent default configuration.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetTestSuiteInvocationResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 1251
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.simulate_conversation",
        "name": "simulate_conversation",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "simulation_specification",
            "type": "ConversationSimulationSpecification",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_evaluation_criteria",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "new_turns_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Run a conversation between the agent and a simulated user.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nsimulation_specification : ConversationSimulationSpecification\n    A specification detailing how the conversation should be simulated\n\nextra_evaluation_criteria : typing.Optional[typing.Sequence[PromptEvaluationCriteria]]\n    A list of evaluation criteria to test\n\nnew_turns_limit : typing.Optional[int]\n    Maximum number of new turns to generate in the conversation simulation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AgentSimulatedChatTestResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 1099
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.simulate_conversation_stream",
        "name": "simulate_conversation_stream",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "simulation_specification",
            "type": "ConversationSimulationSpecification",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_evaluation_criteria",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "new_turns_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Run a conversation between the agent and a simulated user and stream back the response. Response is streamed back as partial lists of messages that should be concatenated and once the conversation has complete a single final message with the conversation analysis will be sent.\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nsimulation_specification : ConversationSimulationSpecification\n    A specification detailing how the conversation should be simulated\n\nextra_evaluation_criteria : typing.Optional[typing.Sequence[PromptEvaluationCriteria]]\n    A list of evaluation criteria to test\n\nnew_turns_limit : typing.Optional[int]\n    Maximum number of new turns to generate in the conversation simulation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[None]",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 1179
      },
      {
        "path": "async_client.conversational_ai.agents.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "conversation_config",
            "type": "Optional[ConversationalConfig]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "platform_settings",
            "type": "Optional[AgentPlatformSettingsRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workflow",
            "type": "Optional[AgentWorkflowRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tags",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Patches an Agent settings\n\nParameters\n----------\nagent_id : str\n    The id of an agent. This is returned on agent creation.\n\nconversation_config : typing.Optional[ConversationalConfig]\n    Conversation configuration for an agent\n\nplatform_settings : typing.Optional[AgentPlatformSettingsRequestModel]\n    Platform settings for the agent are all settings that aren't related to the conversation orchestration and content.\n\nworkflow : typing.Optional[AgentWorkflowRequestModel]\n    Workflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\n\nname : typing.Optional[str]\n    A name to make the agent easier to find\n\ntags : typing.Optional[typing.Sequence[str]]\n    Tags to help classify and filter the agent\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetAgentResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/agents/raw_client.py",
        "source_line": 864
      },
      {
        "path": "async_client.conversational_ai.analytics.live_count.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetLiveCountResponse",
        "docstring": "Get the live count of the ongoing conversations.\n\nParameters\n----------\nagent_id : typing.Optional[str]\n    The id of an agent to restrict the analytics to.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetLiveCountResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.analytics.live_count.get(\n        agent_id=\"agent_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/analytics/live_count/client.py",
        "source_line": 75
      },
      {
        "path": "async_client.conversational_ai.analytics.live_count.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get the live count of the ongoing conversations.\n\nParameters\n----------\nagent_id : typing.Optional[str]\n    The id of an agent to restrict the analytics to.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetLiveCountResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/analytics/live_count/raw_client.py",
        "source_line": 78
      },
      {
        "path": "async_client.conversational_ai.batch_calls.cancel",
        "name": "cancel",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "BatchCallResponse",
        "docstring": "Cancel a running batch call and set all recipients to cancelled status.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nBatchCallResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.batch_calls.cancel(\n        batch_id=\"batch_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 386
      },
      {
        "path": "async_client.conversational_ai.batch_calls.create",
        "name": "create",
        "parameters": [
          {
            "name": "call_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "recipients",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "scheduled_time_unix",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "BatchCallResponse",
        "docstring": "Submit a batch call request to schedule calls for multiple recipients.\n\nParameters\n----------\ncall_name : str\n\nagent_id : str\n\nrecipients : typing.Sequence[OutboundCallRecipient]\n\nscheduled_time_unix : typing.Optional[int]\n\nagent_phone_number_id : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nBatchCallResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, OutboundCallRecipient\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.batch_calls.create(\n        call_name=\"call_name\",\n        agent_id=\"agent_id\",\n        recipients=[OutboundCallRecipient()],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 235
      },
      {
        "path": "async_client.conversational_ai.batch_calls.get",
        "name": "get",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "BatchCallDetailedResponse",
        "docstring": "Get detailed information about a batch call including all recipients.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nBatchCallDetailedResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.batch_calls.get(\n        batch_id=\"batch_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 346
      },
      {
        "path": "async_client.conversational_ai.batch_calls.list",
        "name": "list",
        "parameters": [
          {
            "name": "limit",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "last_doc",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceBatchCallsResponse",
        "docstring": "Get all batch calls for the current workspace.\n\nParameters\n----------\nlimit : typing.Optional[int]\n\nlast_doc : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceBatchCallsResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.batch_calls.list(\n        limit=1,\n        last_doc=\"last_doc\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 299
      },
      {
        "path": "async_client.conversational_ai.batch_calls.retry",
        "name": "retry",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "BatchCallResponse",
        "docstring": "Retry a batch call, calling failed and no-response recipients again.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nBatchCallResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.batch_calls.retry(\n        batch_id=\"batch_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/client.py",
        "source_line": 426
      },
      {
        "path": "async_client.conversational_ai.batch_calls.with_raw_response.cancel",
        "name": "cancel",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Cancel a running batch call and set all recipients to cancelled status.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[BatchCallResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 501
      },
      {
        "path": "async_client.conversational_ai.batch_calls.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "call_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "recipients",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "scheduled_time_unix",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Submit a batch call request to schedule calls for multiple recipients.\n\nParameters\n----------\ncall_name : str\n\nagent_id : str\n\nrecipients : typing.Sequence[OutboundCallRecipient]\n\nscheduled_time_unix : typing.Optional[int]\n\nagent_phone_number_id : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[BatchCallResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 316
      },
      {
        "path": "async_client.conversational_ai.batch_calls.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get detailed information about a batch call including all recipients.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[BatchCallDetailedResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 452
      },
      {
        "path": "async_client.conversational_ai.batch_calls.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "limit",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "last_doc",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get all batch calls for the current workspace.\n\nParameters\n----------\nlimit : typing.Optional[int]\n\nlast_doc : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[WorkspaceBatchCallsResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 393
      },
      {
        "path": "async_client.conversational_ai.batch_calls.with_raw_response.retry",
        "name": "retry",
        "parameters": [
          {
            "name": "batch_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retry a batch call, calling failed and no-response recipients again.\n\nParameters\n----------\nbatch_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[BatchCallResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/batch_calls/raw_client.py",
        "source_line": 550
      },
      {
        "path": "async_client.conversational_ai.conversations.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Get the audio recording of a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.conversations.audio.get(\n        conversation_id=\"conversation_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/audio/client.py",
        "source_line": 74
      },
      {
        "path": "async_client.conversational_ai.conversations.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Get the audio recording of a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 80
      },
      {
        "path": "async_client.conversational_ai.conversations.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.conversations.delete(\n        conversation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 640
      },
      {
        "path": "async_client.conversational_ai.conversations.feedback.create",
        "name": "create",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "feedback",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Send the feedback for the given conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nfeedback : typing.Optional[UserFeedbackScore]\n    Either 'like' or 'dislike' to indicate the feedback for the conversation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.conversations.feedback.create(\n        conversation_id=\"21m00Tcm4TlvDq8ikWAM\",\n        feedback=\"like\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/feedback/client.py",
        "source_line": 86
      },
      {
        "path": "async_client.conversational_ai.conversations.feedback.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "feedback",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Send the feedback for the given conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nfeedback : typing.Optional[UserFeedbackScore]\n    Either 'like' or 'dislike' to indicate the feedback for the conversation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/feedback/raw_client.py",
        "source_line": 95
      },
      {
        "path": "async_client.conversational_ai.conversations.get",
        "name": "get",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConversationResponseModel",
        "docstring": "Get the details of a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConversationResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.conversations.get(\n        conversation_id=\"123\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 599
      },
      {
        "path": "async_client.conversational_ai.conversations.get_signed_url",
        "name": "get_signed_url",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_conversation_id",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ConversationSignedUrlResponseModel",
        "docstring": "Get a signed url to start a conversation with an agent with an agent that requires authorization\n\nParameters\n----------\nagent_id : str\n    The id of the agent you're taking the action on.\n\ninclude_conversation_id : typing.Optional[bool]\n    Whether to include a conversation_id with the response. If included, the conversation_signature cannot be used again.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nConversationSignedUrlResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.conversations.get_signed_url(\n        agent_id=\"21m00Tcm4TlvDq8ikWAM\",\n        include_conversation_id=True,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 357
      },
      {
        "path": "async_client.conversational_ai.conversations.get_webrtc_token",
        "name": "get_webrtc_token",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "participant_name",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "TokenResponseModel",
        "docstring": "Get a WebRTC session token for real-time communication.\n\nParameters\n----------\nagent_id : str\n    The id of the agent you're taking the action on.\n\nparticipant_name : typing.Optional[str]\n    Optional custom participant name. If not provided, user ID will be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nTokenResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.conversations.get_webrtc_token(\n        agent_id=\"21m00Tcm4TlvDq8ikWAM\",\n        participant_name=\"participant_name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 408
      },
      {
        "path": "async_client.conversational_ai.conversations.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_successful",
            "type": "Optional[EvaluationSuccessResult]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_start_before_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_start_after_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_duration_min_secs",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_duration_max_secs",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rating_max",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rating_min",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "has_feedback_comment",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "evaluation_params",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "data_collection_params",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_names",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "summary_mode",
            "type": "Optional[ConversationsListRequestSummaryMode]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConversationsPageResponseModel",
        "docstring": "Get all conversations of agents that user owns. With option to restrict to a specific agent.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nagent_id : typing.Optional[str]\n    The id of the agent you're taking the action on.\n\ncall_successful : typing.Optional[EvaluationSuccessResult]\n    The result of the success evaluation\n\ncall_start_before_unix : typing.Optional[int]\n    Unix timestamp (in seconds) to filter conversations up to this start date.\n\ncall_start_after_unix : typing.Optional[int]\n    Unix timestamp (in seconds) to filter conversations after to this start date.\n\ncall_duration_min_secs : typing.Optional[int]\n    Minimum call duration in seconds.\n\ncall_duration_max_secs : typing.Optional[int]\n    Maximum call duration in seconds.\n\nrating_max : typing.Optional[int]\n    Maximum overall rating (1-5).\n\nrating_min : typing.Optional[int]\n    Minimum overall rating (1-5).\n\nhas_feedback_comment : typing.Optional[bool]\n    Filter conversations with user feedback comments.\n\nuser_id : typing.Optional[str]\n    Filter conversations by the user ID who initiated them.\n\nevaluation_params : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Evaluation filters. Repeat param. Format: criteria_id:result. Example: eval=value_framing:success\n\ndata_collection_params : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Data collection filters. Repeat param. Format: id:op:value where op is one of eq|neq|gt|gte|lt|lte|in|exists|missing. For in, pipe-delimit values.\n\ntool_names : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Filter conversations by tool names used during the call.\n\npage_size : typing.Optional[int]\n    How many conversations to return at maximum. Can not exceed 100, defaults to 30.\n\nsummary_mode : typing.Optional[ConversationsListRequestSummaryMode]\n    Whether to include transcript summaries in the response.\n\nsearch : typing.Optional[str]\n    Full-text or fuzzy search over transcript messages\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConversationsPageResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.conversations.list(\n        cursor=\"cursor\",\n        agent_id=\"agent_id\",\n        call_successful=\"success\",\n        call_start_before_unix=1,\n        call_start_after_unix=1,\n        call_duration_min_secs=1,\n        call_duration_max_secs=1,\n        rating_max=1,\n        rating_min=1,\n        has_feedback_comment=True,\n        user_id=\"user_id\",\n        page_size=1,\n        summary_mode=\"exclude\",\n        search=\"search\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/client.py",
        "source_line": 459
      },
      {
        "path": "async_client.conversational_ai.conversations.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 699
      },
      {
        "path": "async_client.conversational_ai.conversations.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "conversation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get the details of a particular conversation\n\nParameters\n----------\nconversation_id : str\n    The id of the conversation you're taking the action on.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetConversationResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 649
      },
      {
        "path": "async_client.conversational_ai.conversations.with_raw_response.get_signed_url",
        "name": "get_signed_url",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_conversation_id",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get a signed url to start a conversation with an agent with an agent that requires authorization\n\nParameters\n----------\nagent_id : str\n    The id of the agent you're taking the action on.\n\ninclude_conversation_id : typing.Optional[bool]\n    Whether to include a conversation_id with the response. If included, the conversation_signature cannot be used again.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ConversationSignedUrlResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 391
      },
      {
        "path": "async_client.conversational_ai.conversations.with_raw_response.get_webrtc_token",
        "name": "get_webrtc_token",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "participant_name",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get a WebRTC session token for real-time communication.\n\nParameters\n----------\nagent_id : str\n    The id of the agent you're taking the action on.\n\nparticipant_name : typing.Optional[str]\n    Optional custom participant name. If not provided, user ID will be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[TokenResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 452
      },
      {
        "path": "async_client.conversational_ai.conversations.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_successful",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_start_before_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_start_after_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_duration_min_secs",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "call_duration_max_secs",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rating_max",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rating_min",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "has_feedback_comment",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "evaluation_params",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "data_collection_params",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_names",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "summary_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get all conversations of agents that user owns. With option to restrict to a specific agent.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nagent_id : typing.Optional[str]\n    The id of the agent you're taking the action on.\n\ncall_successful : typing.Optional[EvaluationSuccessResult]\n    The result of the success evaluation\n\ncall_start_before_unix : typing.Optional[int]\n    Unix timestamp (in seconds) to filter conversations up to this start date.\n\ncall_start_after_unix : typing.Optional[int]\n    Unix timestamp (in seconds) to filter conversations after to this start date.\n\ncall_duration_min_secs : typing.Optional[int]\n    Minimum call duration in seconds.\n\ncall_duration_max_secs : typing.Optional[int]\n    Maximum call duration in seconds.\n\nrating_max : typing.Optional[int]\n    Maximum overall rating (1-5).\n\nrating_min : typing.Optional[int]\n    Minimum overall rating (1-5).\n\nhas_feedback_comment : typing.Optional[bool]\n    Filter conversations with user feedback comments.\n\nuser_id : typing.Optional[str]\n    Filter conversations by the user ID who initiated them.\n\nevaluation_params : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Evaluation filters. Repeat param. Format: criteria_id:result. Example: eval=value_framing:success\n\ndata_collection_params : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Data collection filters. Repeat param. Format: id:op:value where op is one of eq|neq|gt|gte|lt|lte|in|exists|missing. For in, pipe-delimit values.\n\ntool_names : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Filter conversations by tool names used during the call.\n\npage_size : typing.Optional[int]\n    How many conversations to return at maximum. Can not exceed 100, defaults to 30.\n\nsummary_mode : typing.Optional[ConversationsListRequestSummaryMode]\n    Whether to include transcript summaries in the response.\n\nsearch : typing.Optional[str]\n    Full-text or fuzzy search over transcript messages\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetConversationsPageResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/conversations/raw_client.py",
        "source_line": 513
      },
      {
        "path": "async_client.conversational_ai.dashboard.settings.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConvAiDashboardSettingsResponseModel",
        "docstring": "Retrieve Convai dashboard settings for the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConvAiDashboardSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.dashboard.settings.get()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/dashboard/settings/client.py",
        "source_line": 107
      },
      {
        "path": "async_client.conversational_ai.dashboard.settings.update",
        "name": "update",
        "parameters": [
          {
            "name": "charts",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConvAiDashboardSettingsResponseModel",
        "docstring": "Update Convai dashboard settings for the workspace\n\nParameters\n----------\ncharts : typing.Optional[typing.Sequence[PatchConvAiDashboardSettingsRequestChartsItem]]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConvAiDashboardSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.dashboard.settings.update()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/dashboard/settings/client.py",
        "source_line": 143
      },
      {
        "path": "async_client.conversational_ai.dashboard.settings.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve Convai dashboard settings for the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetConvAiDashboardSettingsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/dashboard/settings/raw_client.py",
        "source_line": 140
      },
      {
        "path": "async_client.conversational_ai.dashboard.settings.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "charts",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update Convai dashboard settings for the workspace\n\nParameters\n----------\ncharts : typing.Optional[typing.Sequence[PatchConvAiDashboardSettingsRequestChartsItem]]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetConvAiDashboardSettingsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/dashboard/settings/raw_client.py",
        "source_line": 187
      },
      {
        "path": "async_client.conversational_ai.delete_document_rag_index",
        "name": "delete_document_rag_index",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rag_index_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RagDocumentIndexResponseModel",
        "docstring": "Delete RAG index for the knowledgebase document.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrag_index_id : str\n    The id of RAG index of document from the knowledge base.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRagDocumentIndexResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.delete_document_rag_index(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n        rag_index_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/client.py",
        "source_line": 502
      },
      {
        "path": "async_client.conversational_ai.get_document_rag_indexes",
        "name": "get_document_rag_indexes",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RagDocumentIndexesResponseModel",
        "docstring": "Provides information about all RAG indexes of the specified knowledgebase document.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRagDocumentIndexesResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.get_document_rag_indexes(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/client.py",
        "source_line": 461
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.document.compute_rag_index",
        "name": "compute_rag_index",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "model",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RagDocumentIndexResponseModel",
        "docstring": "In case the document is not RAG indexed, it triggers rag indexing task, otherwise it just returns the current status.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nmodel : EmbeddingModelEnum\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRagDocumentIndexResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.document.compute_rag_index(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n        model=\"e5_mistral_7b_instruct\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/document/client.py",
        "source_line": 86
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.document.with_raw_response.compute_rag_index",
        "name": "compute_rag_index",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "model",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "In case the document is not RAG indexed, it triggers rag indexing task, otherwise it just returns the current status.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nmodel : EmbeddingModelEnum\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[RagDocumentIndexResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/document/raw_client.py",
        "source_line": 93
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.chunk.get",
        "name": "get",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chunk_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "KnowledgeBaseDocumentChunkResponseModel",
        "docstring": "Get details about a specific documentation part used by RAG.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nchunk_id : str\n    The id of a document RAG chunk from the knowledge base.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nKnowledgeBaseDocumentChunkResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.chunk.get(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n        chunk_id=\"chunk_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/chunk/client.py",
        "source_line": 79
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.chunk.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chunk_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get details about a specific documentation part used by RAG.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nchunk_id : str\n    The id of a document RAG chunk from the knowledge base.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[KnowledgeBaseDocumentChunkResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/chunk/raw_client.py",
        "source_line": 79
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.create_from_file",
        "name": "create_from_file",
        "parameters": [
          {
            "name": "file",
            "type": "core.File",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddKnowledgeBaseResponseModel",
        "docstring": "Create a knowledge base document generated form the uploaded file.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddKnowledgeBaseResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.create_from_file()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 462
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.create_from_text",
        "name": "create_from_text",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddKnowledgeBaseResponseModel",
        "docstring": "Create a knowledge base document containing the provided text.\n\nParameters\n----------\ntext : str\n    Text content to be added to the knowledge base.\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddKnowledgeBaseResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.create_from_text(\n        text=\"text\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 514
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.create_from_url",
        "name": "create_from_url",
        "parameters": [
          {
            "name": "url",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddKnowledgeBaseResponseModel",
        "docstring": "Create a knowledge base document generated by scraping the given webpage.\n\nParameters\n----------\nurl : str\n    URL to a page of documentation that the agent will have access to in order to interact with users.\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddKnowledgeBaseResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.create_from_url(\n        url=\"url\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 408
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "force",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a document from the knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nforce : typing.Optional[bool]\n    If set to true, the document will be deleted regardless of whether it is used by any agents and it will be deleted from the dependent agents.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.delete(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n        force=True,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 616
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.get",
        "name": "get",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DocumentsGetResponse",
        "docstring": "Get details about a specific documentation making up the agent's knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nagent_id : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDocumentsGetResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.get(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n        agent_id=\"agent_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 568
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.get_agents",
        "name": "get_agents",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetKnowledgeBaseDependentAgentsResponseModel",
        "docstring": "Get a list of agents depending on this knowledge base document\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetKnowledgeBaseDependentAgentsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.get_agents(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n        cursor=\"cursor\",\n        page_size=1,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 710
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.get_content",
        "name": "get_content",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "None",
        "docstring": "Get the entire content of a document from the knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.get_content(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 766
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.summaries.get",
        "name": "get",
        "parameters": [
          {
            "name": "document_ids",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Dict[str, Annotated]",
        "docstring": "Gets multiple knowledge base document summaries by their IDs.\n\nParameters\n----------\ndocument_ids : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    The ids of knowledge base documents.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Dict[str, SummariesGetResponseValue]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.summaries.get()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/summaries/client.py",
        "source_line": 76
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.summaries.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "document_ids",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets multiple knowledge base document summaries by their IDs.\n\nParameters\n----------\ndocument_ids : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    The ids of knowledge base documents.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Dict[str, SummariesGetResponseValue]]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/summaries/raw_client.py",
        "source_line": 81
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.update",
        "name": "update",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DocumentsUpdateResponse",
        "docstring": "Update the name of a document\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nname : str\n    A custom, human-readable name for the document.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDocumentsUpdateResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.documents.update(\n        documentation_id=\"21m00Tcm4TlvDq8ikWAM\",\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/client.py",
        "source_line": 665
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.with_raw_response.create_from_file",
        "name": "create_from_file",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a knowledge base document generated form the uploaded file.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddKnowledgeBaseResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 601
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.with_raw_response.create_from_text",
        "name": "create_from_text",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a knowledge base document containing the provided text.\n\nParameters\n----------\ntext : str\n    Text content to be added to the knowledge base.\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddKnowledgeBaseResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 671
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.with_raw_response.create_from_url",
        "name": "create_from_url",
        "parameters": [
          {
            "name": "url",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a knowledge base document generated by scraping the given webpage.\n\nParameters\n----------\nurl : str\n    URL to a page of documentation that the agent will have access to in order to interact with users.\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nparent_folder_id : typing.Optional[str]\n    If set, the created document or folder will be placed inside the given folder.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddKnowledgeBaseResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 531
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "force",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete a document from the knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nforce : typing.Optional[bool]\n    If set to true, the document will be deleted regardless of whether it is used by any agents and it will be deleted from the dependent agents.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 800
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get details about a specific documentation making up the agent's knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nagent_id : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DocumentsGetResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 741
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.with_raw_response.get_agents",
        "name": "get_agents",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get a list of agents depending on this knowledge base document\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetKnowledgeBaseDependentAgentsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 922
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.with_raw_response.get_content",
        "name": "get_content",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get the entire content of a document from the knowledge base\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[None]",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 987
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.documents.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update the name of a document\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nname : str\n    A custom, human-readable name for the document.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DocumentsUpdateResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/documents/raw_client.py",
        "source_line": 862
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.get_or_create_rag_indexes",
        "name": "get_or_create_rag_indexes",
        "parameters": [
          {
            "name": "items",
            "type": "Sequence[GetOrCreateRagIndexRequestModel]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Dict[str, KnowledgeBaseGetOrCreateRagIndexesResponseValue]",
        "docstring": "Retrieves and/or creates RAG indexes for multiple knowledge base documents in a single request.\n\nParameters\n----------\nitems : typing.Sequence[GetOrCreateRagIndexRequestModel]\n    List of requested RAG indexes.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Dict[str, KnowledgeBaseGetOrCreateRagIndexesResponseValue]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, GetOrCreateRagIndexRequestModel\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.get_or_create_rag_indexes(\n        items=[\n            GetOrCreateRagIndexRequestModel(\n                document_id=\"document_id\",\n                create_if_missing=True,\n                model=\"e5_mistral_7b_instruct\",\n            )\n        ],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/client.py",
        "source_line": 329
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "show_only_owned_documents",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "types",
            "type": "Optional[Union[KnowledgeBaseDocumentType, Sequence[KnowledgeBaseDocumentType]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "ancestor_folder_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "folders_first",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[SortDirection]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_by",
            "type": "Optional[KnowledgeBaseSortBy]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_typesense",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetKnowledgeBaseListResponseModel",
        "docstring": "Get a list of available knowledge base documents\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    If specified, the endpoint returns only such knowledge base documents whose names start with this string.\n\nshow_only_owned_documents : typing.Optional[bool]\n    If set to true, the endpoint will return only documents owned by you (and not shared from somebody else).\n\ntypes : typing.Optional[typing.Union[KnowledgeBaseDocumentType, typing.Sequence[KnowledgeBaseDocumentType]]]\n    If present, the endpoint will return only documents of the given types.\n\nparent_folder_id : typing.Optional[str]\n    If set, the endpoint will return only documents that are direct children of the given folder.\n\nancestor_folder_id : typing.Optional[str]\n    If set, the endpoint will return only documents that are descendants of the given folder.\n\nfolders_first : typing.Optional[bool]\n    Whether folders should be returned first in the list of documents.\n\nsort_direction : typing.Optional[SortDirection]\n    The direction to sort the results\n\nsort_by : typing.Optional[KnowledgeBaseSortBy]\n    The field to sort the results by\n\nuse_typesense : typing.Optional[bool]\n    If set to true, the endpoint will use typesense DB to search for the documents).\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetKnowledgeBaseListResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.knowledge_base.list(\n        page_size=1,\n        search=\"search\",\n        show_only_owned_documents=True,\n        parent_folder_id=\"parent_folder_id\",\n        ancestor_folder_id=\"ancestor_folder_id\",\n        folders_first=True,\n        sort_direction=\"asc\",\n        sort_by=\"name\",\n        use_typesense=True,\n        cursor=\"cursor\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/client.py",
        "source_line": 221
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.with_raw_response.get_or_create_rag_indexes",
        "name": "get_or_create_rag_indexes",
        "parameters": [
          {
            "name": "items",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieves and/or creates RAG indexes for multiple knowledge base documents in a single request.\n\nParameters\n----------\nitems : typing.Sequence[GetOrCreateRagIndexRequestModel]\n    List of requested RAG indexes.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Dict[str, KnowledgeBaseGetOrCreateRagIndexesResponseValue]]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/raw_client.py",
        "source_line": 314
      },
      {
        "path": "async_client.conversational_ai.knowledge_base.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "show_only_owned_documents",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "types",
            "type": "Union[Literal, Any, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "parent_folder_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "ancestor_folder_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "folders_first",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_by",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_typesense",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get a list of available knowledge base documents\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    If specified, the endpoint returns only such knowledge base documents whose names start with this string.\n\nshow_only_owned_documents : typing.Optional[bool]\n    If set to true, the endpoint will return only documents owned by you (and not shared from somebody else).\n\ntypes : typing.Optional[typing.Union[KnowledgeBaseDocumentType, typing.Sequence[KnowledgeBaseDocumentType]]]\n    If present, the endpoint will return only documents of the given types.\n\nparent_folder_id : typing.Optional[str]\n    If set, the endpoint will return only documents that are direct children of the given folder.\n\nancestor_folder_id : typing.Optional[str]\n    If set, the endpoint will return only documents that are descendants of the given folder.\n\nfolders_first : typing.Optional[bool]\n    Whether folders should be returned first in the list of documents.\n\nsort_direction : typing.Optional[SortDirection]\n    The direction to sort the results\n\nsort_by : typing.Optional[KnowledgeBaseSortBy]\n    The field to sort the results by\n\nuse_typesense : typing.Optional[bool]\n    If set to true, the endpoint will use typesense DB to search for the documents).\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetKnowledgeBaseListResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/knowledge_base/raw_client.py",
        "source_line": 206
      },
      {
        "path": "async_client.conversational_ai.llm_usage.calculate",
        "name": "calculate",
        "parameters": [
          {
            "name": "prompt_length",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "number_of_pages",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_enabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "LlmUsageCalculatorResponseModel",
        "docstring": "Returns a list of LLM models and the expected cost for using them based on the provided values.\n\nParameters\n----------\nprompt_length : int\n    Length of the prompt in characters.\n\nnumber_of_pages : int\n    Pages of content in PDF documents or URLs in the agent's knowledge base.\n\nrag_enabled : bool\n    Whether RAG is enabled.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nLlmUsageCalculatorResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.llm_usage.calculate(\n        prompt_length=1,\n        number_of_pages=1,\n        rag_enabled=True,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/llm_usage/client.py",
        "source_line": 96
      },
      {
        "path": "async_client.conversational_ai.llm_usage.with_raw_response.calculate",
        "name": "calculate",
        "parameters": [
          {
            "name": "prompt_length",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "number_of_pages",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_enabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns a list of LLM models and the expected cost for using them based on the provided values.\n\nParameters\n----------\nprompt_length : int\n    Length of the prompt in characters.\n\nnumber_of_pages : int\n    Pages of content in PDF documents or URLs in the agent's knowledge base.\n\nrag_enabled : bool\n    Whether RAG is enabled.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[LlmUsageCalculatorResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/llm_usage/raw_client.py",
        "source_line": 98
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.approval_policy.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Update the approval policy configuration for an MCP server. DEPRECATED: Use PATCH /mcp-servers/{id} endpoint instead.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\napproval_policy : McpApprovalPolicy\n    The approval mode to set for the MCP server\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.approval_policy.update(\n        mcp_server_id=\"mcp_server_id\",\n        approval_policy=\"auto_approve_all\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/approval_policy/client.py",
        "source_line": 89
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.approval_policy.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update the approval policy configuration for an MCP server. DEPRECATED: Use PATCH /mcp-servers/{id} endpoint instead.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\napproval_policy : McpApprovalPolicy\n    The approval mode to set for the MCP server\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/approval_policy/raw_client.py",
        "source_line": 94
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.create",
        "name": "create",
        "parameters": [
          {
            "name": "config",
            "type": "McpServerConfigInput",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Create a new MCP server configuration in the workspace.\n\nParameters\n----------\nconfig : McpServerConfigInput\n    Configuration details for the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, McpServerConfigInput\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.create(\n        config=McpServerConfigInput(\n            url=\"url\",\n            name=\"name\",\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 339
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a specific MCP server configuration from the workspace.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.delete(\n        mcp_server_id=\"mcp_server_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 424
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.get",
        "name": "get",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Retrieve a specific MCP server configuration from the workspace.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.get(\n        mcp_server_id=\"mcp_server_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 383
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServersResponseModel",
        "docstring": "Retrieve all MCP server configurations available in the workspace.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServersResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.list()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 305
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_approvals.create",
        "name": "create",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "input_schema",
            "type": "Optional[Dict[str, Any]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Add approval for a specific MCP tool when using per-tool approval mode.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    The name of the MCP tool\n\ntool_description : str\n    The description of the MCP tool\n\ninput_schema : typing.Optional[typing.Dict[str, typing.Any]]\n    The input schema of the MCP tool (the schema defined on the MCP server before ElevenLabs does any extra processing)\n\napproval_policy : typing.Optional[McpToolApprovalPolicy]\n    The tool-level approval policy\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.tool_approvals.create(\n        mcp_server_id=\"mcp_server_id\",\n        tool_name=\"tool_name\",\n        tool_description=\"tool_description\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_approvals/client.py",
        "source_line": 144
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_approvals.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Remove approval for a specific MCP tool when using per-tool approval mode.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to remove approval for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.tool_approvals.delete(\n        mcp_server_id=\"mcp_server_id\",\n        tool_name=\"tool_name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_approvals/client.py",
        "source_line": 213
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_approvals.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "input_schema",
            "type": "Optional[Dict[str, Any]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Add approval for a specific MCP tool when using per-tool approval mode.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    The name of the MCP tool\n\ntool_description : str\n    The description of the MCP tool\n\ninput_schema : typing.Optional[typing.Dict[str, typing.Any]]\n    The input schema of the MCP tool (the schema defined on the MCP server before ElevenLabs does any extra processing)\n\napproval_policy : typing.Optional[McpToolApprovalPolicy]\n    The tool-level approval policy\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_approvals/raw_client.py",
        "source_line": 162
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_approvals.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Remove approval for a specific MCP tool when using per-tool approval mode.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to remove approval for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_approvals/raw_client.py",
        "source_line": 241
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_configs.create",
        "name": "create",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "assignments",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Create configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    The name of the MCP tool\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    If set, overrides the server's tool_call_sound setting for this tool\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    If set, overrides the server's tool_call_sound_behavior setting for this tool\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nassignments : typing.Optional[typing.Sequence[DynamicVariableAssignment]]\n    Dynamic variable assignments for this MCP tool\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.tool_configs.create(\n        mcp_server_id=\"mcp_server_id\",\n        tool_name=\"tool_name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/client.py",
        "source_line": 274
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_configs.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Remove configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to remove config overrides for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.tool_configs.delete(\n        mcp_server_id=\"mcp_server_id\",\n        tool_name=\"tool_name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/client.py",
        "source_line": 402
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_configs.get",
        "name": "get",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpToolConfigOverride",
        "docstring": "Retrieve configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to retrieve config overrides for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpToolConfigOverride\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.tool_configs.get(\n        mcp_server_id=\"mcp_server_id\",\n        tool_name=\"tool_name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/client.py",
        "source_line": 357
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_configs.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "assignments",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Update configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to update config overrides for.\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    If set, overrides the server's tool_call_sound setting for this tool\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    If set, overrides the server's tool_call_sound_behavior setting for this tool\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nassignments : typing.Optional[typing.Sequence[DynamicVariableAssignment]]\n    Dynamic variable assignments for this MCP tool\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.tool_configs.update(\n        mcp_server_id=\"mcp_server_id\",\n        tool_name=\"tool_name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/client.py",
        "source_line": 447
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_configs.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "assignments",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    The name of the MCP tool\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    If set, overrides the server's tool_call_sound setting for this tool\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    If set, overrides the server's tool_call_sound_behavior setting for this tool\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nassignments : typing.Optional[typing.Sequence[DynamicVariableAssignment]]\n    Dynamic variable assignments for this MCP tool\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/raw_client.py",
        "source_line": 367
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_configs.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Remove configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to remove config overrides for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/raw_client.py",
        "source_line": 538
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_configs.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to retrieve config overrides for.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpToolConfigOverride]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/raw_client.py",
        "source_line": 474
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tool_configs.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "tool_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "assignments",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update configuration overrides for a specific MCP tool.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\ntool_name : str\n    Name of the MCP tool to update config overrides for.\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    If set, overrides the server's tool_call_sound setting for this tool\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    If set, overrides the server's tool_call_sound_behavior setting for this tool\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nassignments : typing.Optional[typing.Sequence[DynamicVariableAssignment]]\n    Dynamic variable assignments for this MCP tool\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tool_configs/raw_client.py",
        "source_line": 591
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tools.list",
        "name": "list",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ListMcpToolsResponseModel",
        "docstring": "Retrieve all tools available for a specific MCP server configuration.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nListMcpToolsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.tools.list(\n        mcp_server_id=\"mcp_server_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tools/client.py",
        "source_line": 75
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.tools.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve all tools available for a specific MCP server configuration.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ListMcpToolsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/tools/raw_client.py",
        "source_line": 76
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "approval_policy",
            "type": "Optional[McpApprovalPolicy]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Optional[ToolCallSoundType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Optional[ToolCallSoundBehavior]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Optional[ToolExecutionMode]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_headers",
            "type": "Optional[Dict[str, Optional[McpServerConfigUpdateRequestModelRequestHeadersValue]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "McpServerResponseModel",
        "docstring": "Update the configuration settings for an MCP server.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\napproval_policy : typing.Optional[McpApprovalPolicy]\n    The approval mode to set for the MCP server\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    Predefined tool call sound type to play during tool execution for all tools from this MCP server\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    Determines when the tool call sound should play for all tools from this MCP server\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nrequest_headers : typing.Optional[typing.Dict[str, typing.Optional[McpServerConfigUpdateRequestModelRequestHeadersValue]]]\n    The headers to include in requests to the MCP server\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMcpServerResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.mcp_servers.update(\n        mcp_server_id=\"mcp_server_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/client.py",
        "source_line": 465
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "config",
            "type": "McpServerConfigInput",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a new MCP server configuration in the workspace.\n\nParameters\n----------\nconfig : McpServerConfigInput\n    Configuration details for the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 392
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete a specific MCP server configuration from the workspace.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 501
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve a specific MCP server configuration from the workspace.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 451
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve all MCP server configurations available in the workspace.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServersResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 345
      },
      {
        "path": "async_client.conversational_ai.mcp_servers.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "mcp_server_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "approval_policy",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_pre_tool_speech",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_interruptions",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_sound_behavior",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "execution_mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_headers",
            "type": "Optional[Dict[str, Union[str, ConvAiSecretLocator, ConvAiDynamicVariable, NoneType]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update the configuration settings for an MCP server.\n\nParameters\n----------\nmcp_server_id : str\n    ID of the MCP Server.\n\napproval_policy : typing.Optional[McpApprovalPolicy]\n    The approval mode to set for the MCP server\n\nforce_pre_tool_speech : typing.Optional[bool]\n    If set, overrides the server's force_pre_tool_speech setting for this tool\n\ndisable_interruptions : typing.Optional[bool]\n    If set, overrides the server's disable_interruptions setting for this tool\n\ntool_call_sound : typing.Optional[ToolCallSoundType]\n    Predefined tool call sound type to play during tool execution for all tools from this MCP server\n\ntool_call_sound_behavior : typing.Optional[ToolCallSoundBehavior]\n    Determines when the tool call sound should play for all tools from this MCP server\n\nexecution_mode : typing.Optional[ToolExecutionMode]\n    If set, overrides the server's execution_mode setting for this tool\n\nrequest_headers : typing.Optional[typing.Dict[str, typing.Optional[McpServerConfigUpdateRequestModelRequestHeadersValue]]]\n    The headers to include in requests to the MCP server\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[McpServerResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/mcp_servers/raw_client.py",
        "source_line": 553
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.create",
        "name": "create",
        "parameters": [
          {
            "name": "request",
            "type": "Annotated",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreatePhoneNumberResponseModel",
        "docstring": "Import Phone Number from provider configuration (Twilio or SIP trunk)\n\nParameters\n----------\nrequest : PhoneNumbersCreateRequestBody\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreatePhoneNumberResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\nfrom elevenlabs.conversational_ai.phone_numbers import (\n    PhoneNumbersCreateRequestBody_Twilio,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.phone_numbers.create(\n        request=PhoneNumbersCreateRequestBody_Twilio(\n            phone_number=\"phone_number\",\n            label=\"label\",\n            sid=\"sid\",\n            token=\"token\",\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 275
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete Phone Number by ID\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.phone_numbers.delete(\n        phone_number_id=\"TeaqRRdTcIfIu2i7BYfT\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 364
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.get",
        "name": "get",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Annotated",
        "docstring": "Retrieve Phone Number details by ID\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPhoneNumbersGetResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.phone_numbers.get(\n        phone_number_id=\"TeaqRRdTcIfIu2i7BYfT\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 323
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "List[Annotated]",
        "docstring": "Retrieve all Phone Numbers\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.List[PhoneNumbersListResponseItem]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.phone_numbers.list()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 239
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.update",
        "name": "update",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "inbound_trunk_config",
            "type": "Optional[InboundSipTrunkConfigRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "outbound_trunk_config",
            "type": "Optional[OutboundSipTrunkConfigRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "livekit_stack",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Annotated",
        "docstring": "Update assigned agent of a phone number\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nagent_id : typing.Optional[str]\n\ninbound_trunk_config : typing.Optional[InboundSipTrunkConfigRequestModel]\n\noutbound_trunk_config : typing.Optional[OutboundSipTrunkConfigRequestModel]\n\nlivekit_stack : typing.Optional[LivekitStackType]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPhoneNumbersUpdateResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.phone_numbers.update(\n        phone_number_id=\"TeaqRRdTcIfIu2i7BYfT\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/client.py",
        "source_line": 405
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "request",
            "type": "Annotated",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Import Phone Number from provider configuration (Twilio or SIP trunk)\n\nParameters\n----------\nrequest : PhoneNumbersCreateRequestBody\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[CreatePhoneNumberResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 368
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete Phone Number by ID\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 474
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve Phone Number details by ID\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PhoneNumbersGetResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 424
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve all Phone Numbers\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.List[PhoneNumbersListResponseItem]]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 321
      },
      {
        "path": "async_client.conversational_ai.phone_numbers.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "inbound_trunk_config",
            "type": "Optional[InboundSipTrunkConfigRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "outbound_trunk_config",
            "type": "Optional[OutboundSipTrunkConfigRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "livekit_stack",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update assigned agent of a phone number\n\nParameters\n----------\nphone_number_id : str\n    The id of an agent. This is returned on agent creation.\n\nagent_id : typing.Optional[str]\n\ninbound_trunk_config : typing.Optional[InboundSipTrunkConfigRequestModel]\n\noutbound_trunk_config : typing.Optional[OutboundSipTrunkConfigRequestModel]\n\nlivekit_stack : typing.Optional[LivekitStackType]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PhoneNumbersUpdateResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/phone_numbers/raw_client.py",
        "source_line": 526
      },
      {
        "path": "async_client.conversational_ai.rag_index_overview",
        "name": "rag_index_overview",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RagIndexOverviewResponseModel",
        "docstring": "Provides total size and other information of RAG indexes used by knowledgebase documents\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRagIndexOverviewResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.rag_index_overview()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/client.py",
        "source_line": 425
      },
      {
        "path": "async_client.conversational_ai.secrets.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "value",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PostWorkspaceSecretResponseModel",
        "docstring": "Create a new secret for the workspace\n\nParameters\n----------\nname : str\n\nvalue : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPostWorkspaceSecretResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.secrets.create(\n        name=\"name\",\n        value=\"value\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/client.py",
        "source_line": 210
      },
      {
        "path": "async_client.conversational_ai.secrets.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "secret_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a workspace secret if it's not in use\n\nParameters\n----------\nsecret_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.secrets.delete(\n        secret_id=\"secret_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/client.py",
        "source_line": 253
      },
      {
        "path": "async_client.conversational_ai.secrets.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetWorkspaceSecretsResponseModel",
        "docstring": "Get all workspace secrets for the user\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetWorkspaceSecretsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.secrets.list()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/client.py",
        "source_line": 174
      },
      {
        "path": "async_client.conversational_ai.secrets.update",
        "name": "update",
        "parameters": [
          {
            "name": "secret_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "value",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PostWorkspaceSecretResponseModel",
        "docstring": "Update an existing secret for the workspace\n\nParameters\n----------\nsecret_id : str\n\nname : str\n\nvalue : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPostWorkspaceSecretResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.secrets.update(\n        secret_id=\"secret_id\",\n        name=\"name\",\n        value=\"value\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/client.py",
        "source_line": 290
      },
      {
        "path": "async_client.conversational_ai.secrets.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "value",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a new secret for the workspace\n\nParameters\n----------\nname : str\n\nvalue : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PostWorkspaceSecretResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/raw_client.py",
        "source_line": 285
      },
      {
        "path": "async_client.conversational_ai.secrets.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "secret_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete a workspace secret if it's not in use\n\nParameters\n----------\nsecret_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[None]",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/raw_client.py",
        "source_line": 345
      },
      {
        "path": "async_client.conversational_ai.secrets.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get all workspace secrets for the user\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetWorkspaceSecretsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/raw_client.py",
        "source_line": 238
      },
      {
        "path": "async_client.conversational_ai.secrets.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "secret_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "value",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update an existing secret for the workspace\n\nParameters\n----------\nsecret_id : str\n\nname : str\n\nvalue : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PostWorkspaceSecretResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/secrets/raw_client.py",
        "source_line": 386
      },
      {
        "path": "async_client.conversational_ai.settings.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConvAiSettingsResponseModel",
        "docstring": "Retrieve Convai settings for the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConvAiSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.settings.get()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/settings/client.py",
        "source_line": 127
      },
      {
        "path": "async_client.conversational_ai.settings.update",
        "name": "update",
        "parameters": [
          {
            "name": "conversation_initiation_client_data_webhook",
            "type": "Optional[ConversationInitiationClientDataWebhook]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhooks",
            "type": "Optional[ConvAiWebhooks]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "can_use_mcp_servers",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_retention_period_days",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_livekit_stack",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetConvAiSettingsResponseModel",
        "docstring": "Update Convai settings for the workspace\n\nParameters\n----------\nconversation_initiation_client_data_webhook : typing.Optional[ConversationInitiationClientDataWebhook]\n\nwebhooks : typing.Optional[ConvAiWebhooks]\n\ncan_use_mcp_servers : typing.Optional[bool]\n    Whether the workspace can use MCP servers\n\nrag_retention_period_days : typing.Optional[int]\n\ndefault_livekit_stack : typing.Optional[LivekitStackType]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetConvAiSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.settings.update()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/settings/client.py",
        "source_line": 161
      },
      {
        "path": "async_client.conversational_ai.settings.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve Convai settings for the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetConvAiSettingsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/settings/raw_client.py",
        "source_line": 161
      },
      {
        "path": "async_client.conversational_ai.settings.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "conversation_initiation_client_data_webhook",
            "type": "Optional[ConversationInitiationClientDataWebhook]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhooks",
            "type": "Optional[ConvAiWebhooks]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "can_use_mcp_servers",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "rag_retention_period_days",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_livekit_stack",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update Convai settings for the workspace\n\nParameters\n----------\nconversation_initiation_client_data_webhook : typing.Optional[ConversationInitiationClientDataWebhook]\n\nwebhooks : typing.Optional[ConvAiWebhooks]\n\ncan_use_mcp_servers : typing.Optional[bool]\n    Whether the workspace can use MCP servers\n\nrag_retention_period_days : typing.Optional[int]\n\ndefault_livekit_stack : typing.Optional[LivekitStackType]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetConvAiSettingsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/settings/raw_client.py",
        "source_line": 208
      },
      {
        "path": "async_client.conversational_ai.sip_trunk.outbound_call",
        "name": "outbound_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SipTrunkOutboundCallResponse",
        "docstring": "Handle an outbound call via SIP trunk\n\nParameters\n----------\nagent_id : str\n\nagent_phone_number_id : str\n\nto_number : str\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSipTrunkOutboundCallResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.sip_trunk.outbound_call(\n        agent_id=\"agent_id\",\n        agent_phone_number_id=\"agent_phone_number_id\",\n        to_number=\"to_number\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/sip_trunk/client.py",
        "source_line": 98
      },
      {
        "path": "async_client.conversational_ai.sip_trunk.with_raw_response.outbound_call",
        "name": "outbound_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Handle an outbound call via SIP trunk\n\nParameters\n----------\nagent_id : str\n\nagent_phone_number_id : str\n\nto_number : str\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SipTrunkOutboundCallResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/sip_trunk/raw_client.py",
        "source_line": 105
      },
      {
        "path": "async_client.conversational_ai.tests.create",
        "name": "create",
        "parameters": [
          {
            "name": "chat_history",
            "type": "Sequence[ConversationHistoryTranscriptCommonModelInput]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_condition",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_examples",
            "type": "Sequence[AgentSuccessfulResponseExample]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "failure_examples",
            "type": "Sequence[AgentFailureResponseExample]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_parameters",
            "type": "Optional[UnitTestToolCallEvaluationModelInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dynamic_variables",
            "type": "Optional[Dict[str, Optional[CreateUnitTestRequestDynamicVariablesValue]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "type",
            "type": "Optional[UnitTestCommonModelType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_conversation_metadata",
            "type": "Optional[TestFromConversationMetadataInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreateUnitTestResponseModel",
        "docstring": "Creates a new agent response test.\n\nParameters\n----------\nchat_history : typing.Sequence[ConversationHistoryTranscriptCommonModelInput]\n\nsuccess_condition : str\n    A prompt that evaluates whether the agent's response is successful. Should return True or False.\n\nsuccess_examples : typing.Sequence[AgentSuccessfulResponseExample]\n    Non-empty list of example responses that should be considered successful\n\nfailure_examples : typing.Sequence[AgentFailureResponseExample]\n    Non-empty list of example responses that should be considered failures\n\nname : str\n\ntool_call_parameters : typing.Optional[UnitTestToolCallEvaluationModelInput]\n    How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated.\n\ndynamic_variables : typing.Optional[typing.Dict[str, typing.Optional[CreateUnitTestRequestDynamicVariablesValue]]]\n    Dynamic variables to replace in the agent config during testing\n\ntype : typing.Optional[UnitTestCommonModelType]\n\nfrom_conversation_metadata : typing.Optional[TestFromConversationMetadataInput]\n    Metadata of a conversation this test was created from (if applicable).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreateUnitTestResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import (\n    AgentFailureResponseExample,\n    AgentSuccessfulResponseExample,\n    AsyncElevenLabs,\n    ConversationHistoryTranscriptCommonModelInput,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.create(\n        chat_history=[\n            ConversationHistoryTranscriptCommonModelInput(\n                role=\"user\",\n                time_in_call_secs=1,\n            )\n        ],\n        success_condition=\"success_condition\",\n        success_examples=[\n            AgentSuccessfulResponseExample(\n                response=\"response\",\n            )\n        ],\n        failure_examples=[\n            AgentFailureResponseExample(\n                response=\"response\",\n            )\n        ],\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 421
      },
      {
        "path": "async_client.conversational_ai.tests.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Deletes an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.delete(\n        test_id=\"TeaqRRdTcIfIu2i7BYfT\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 684
      },
      {
        "path": "async_client.conversational_ai.tests.get",
        "name": "get",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetUnitTestResponseModel",
        "docstring": "Gets an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetUnitTestResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.get(\n        test_id=\"TeaqRRdTcIfIu2i7BYfT\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 529
      },
      {
        "path": "async_client.conversational_ai.tests.invocations.get",
        "name": "get",
        "parameters": [
          {
            "name": "test_invocation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestSuiteInvocationResponseModel",
        "docstring": "Gets a test invocation by ID.\n\nParameters\n----------\ntest_invocation_id : str\n    The id of a test invocation. This is returned when tests are run.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestSuiteInvocationResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.invocations.get(\n        test_invocation_id=\"test_invocation_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/client.py",
        "source_line": 245
      },
      {
        "path": "async_client.conversational_ai.tests.invocations.list",
        "name": "list",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestInvocationsPageResponseModel",
        "docstring": "Lists all test invocations with pagination support and optional search filtering.\n\nParameters\n----------\nagent_id : str\n    Filter by agent ID\n\npage_size : typing.Optional[int]\n    How many Tests to return at maximum. Can not exceed 100, defaults to 30.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestInvocationsPageResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.invocations.list(\n        agent_id=\"agent_id\",\n        page_size=1,\n        cursor=\"cursor\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/client.py",
        "source_line": 189
      },
      {
        "path": "async_client.conversational_ai.tests.invocations.resubmit",
        "name": "resubmit",
        "parameters": [
          {
            "name": "test_invocation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "test_run_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_config_override",
            "type": "Optional[AdhocAgentConfigOverrideForTestRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "branch_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Resubmits specific test runs from a test invocation.\n\nParameters\n----------\ntest_invocation_id : str\n    The id of a test invocation. This is returned when tests are run.\n\ntest_run_ids : typing.Sequence[str]\n    List of test run IDs to resubmit\n\nagent_id : str\n    Agent ID to resubmit tests for\n\nagent_config_override : typing.Optional[AdhocAgentConfigOverrideForTestRequestModel]\n    Configuration overrides to use for testing. If not provided, the agent's default configuration will be used.\n\nbranch_id : typing.Optional[str]\n    ID of the branch to run the tests on. If not provided, the tests will be run on the agent default configuration.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.invocations.resubmit(\n        test_invocation_id=\"test_invocation_id\",\n        test_run_ids=[\"test_run_ids\"],\n        agent_id=\"agent_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/client.py",
        "source_line": 286
      },
      {
        "path": "async_client.conversational_ai.tests.invocations.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "test_invocation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets a test invocation by ID.\n\nParameters\n----------\ntest_invocation_id : str\n    The id of a test invocation. This is returned when tests are run.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetTestSuiteInvocationResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/raw_client.py",
        "source_line": 299
      },
      {
        "path": "async_client.conversational_ai.tests.invocations.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Lists all test invocations with pagination support and optional search filtering.\n\nParameters\n----------\nagent_id : str\n    Filter by agent ID\n\npage_size : typing.Optional[int]\n    How many Tests to return at maximum. Can not exceed 100, defaults to 30.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetTestInvocationsPageResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/raw_client.py",
        "source_line": 233
      },
      {
        "path": "async_client.conversational_ai.tests.invocations.with_raw_response.resubmit",
        "name": "resubmit",
        "parameters": [
          {
            "name": "test_invocation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "test_run_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_config_override",
            "type": "Optional[AdhocAgentConfigOverrideForTestRequestModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "branch_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Resubmits specific test runs from a test invocation.\n\nParameters\n----------\ntest_invocation_id : str\n    The id of a test invocation. This is returned when tests are run.\n\ntest_run_ids : typing.Sequence[str]\n    List of test run IDs to resubmit\n\nagent_id : str\n    Agent ID to resubmit tests for\n\nagent_config_override : typing.Optional[AdhocAgentConfigOverrideForTestRequestModel]\n    Configuration overrides to use for testing. If not provided, the agent's default configuration will be used.\n\nbranch_id : typing.Optional[str]\n    ID of the branch to run the tests on. If not provided, the tests will be run on the agent default configuration.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/invocations/raw_client.py",
        "source_line": 349
      },
      {
        "path": "async_client.conversational_ai.tests.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestsPageResponseModel",
        "docstring": "Lists all agent response tests with pagination support and optional search filtering.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many Tests to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    Search query to filter tests by name.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestsPageResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.list(\n        cursor=\"cursor\",\n        page_size=1,\n        search=\"search\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 764
      },
      {
        "path": "async_client.conversational_ai.tests.summaries",
        "name": "summaries",
        "parameters": [
          {
            "name": "test_ids",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetTestsSummariesByIdsResponseModel",
        "docstring": "Gets multiple agent response tests by their IDs. Returns a dictionary mapping test IDs to test summaries.\n\nParameters\n----------\ntest_ids : typing.Sequence[str]\n    List of test IDs to fetch. No duplicates allowed.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetTestsSummariesByIdsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.summaries(\n        test_ids=[\"test_id_1\", \"test_id_2\"],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 723
      },
      {
        "path": "async_client.conversational_ai.tests.update",
        "name": "update",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chat_history",
            "type": "Sequence[ConversationHistoryTranscriptCommonModelInput]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_condition",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_examples",
            "type": "Sequence[AgentSuccessfulResponseExample]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "failure_examples",
            "type": "Sequence[AgentFailureResponseExample]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_parameters",
            "type": "Optional[UnitTestToolCallEvaluationModelInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dynamic_variables",
            "type": "Optional[Dict[str, Optional[UpdateUnitTestRequestDynamicVariablesValue]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "type",
            "type": "Optional[UnitTestCommonModelType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_conversation_metadata",
            "type": "Optional[TestFromConversationMetadataInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetUnitTestResponseModel",
        "docstring": "Updates an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nchat_history : typing.Sequence[ConversationHistoryTranscriptCommonModelInput]\n\nsuccess_condition : str\n    A prompt that evaluates whether the agent's response is successful. Should return True or False.\n\nsuccess_examples : typing.Sequence[AgentSuccessfulResponseExample]\n    Non-empty list of example responses that should be considered successful\n\nfailure_examples : typing.Sequence[AgentFailureResponseExample]\n    Non-empty list of example responses that should be considered failures\n\nname : str\n\ntool_call_parameters : typing.Optional[UnitTestToolCallEvaluationModelInput]\n    How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated.\n\ndynamic_variables : typing.Optional[typing.Dict[str, typing.Optional[UpdateUnitTestRequestDynamicVariablesValue]]]\n    Dynamic variables to replace in the agent config during testing\n\ntype : typing.Optional[UnitTestCommonModelType]\n\nfrom_conversation_metadata : typing.Optional[TestFromConversationMetadataInput]\n    Metadata of a conversation this test was created from (if applicable).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetUnitTestResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import (\n    AgentFailureResponseExample,\n    AgentSuccessfulResponseExample,\n    AsyncElevenLabs,\n    ConversationHistoryTranscriptCommonModelInput,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tests.update(\n        test_id=\"TeaqRRdTcIfIu2i7BYfT\",\n        chat_history=[\n            ConversationHistoryTranscriptCommonModelInput(\n                role=\"user\",\n                time_in_call_secs=1,\n            )\n        ],\n        success_condition=\"success_condition\",\n        success_examples=[\n            AgentSuccessfulResponseExample(\n                response=\"response\",\n            )\n        ],\n        failure_examples=[\n            AgentFailureResponseExample(\n                response=\"response\",\n            )\n        ],\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/client.py",
        "source_line": 570
      },
      {
        "path": "async_client.conversational_ai.tests.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "chat_history",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_condition",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_examples",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "failure_examples",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_parameters",
            "type": "Optional[UnitTestToolCallEvaluationModelInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dynamic_variables",
            "type": "Optional[Dict[str, Union[str, int, float, bool, NoneType]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "type",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_conversation_metadata",
            "type": "Optional[TestFromConversationMetadataInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Creates a new agent response test.\n\nParameters\n----------\nchat_history : typing.Sequence[ConversationHistoryTranscriptCommonModelInput]\n\nsuccess_condition : str\n    A prompt that evaluates whether the agent's response is successful. Should return True or False.\n\nsuccess_examples : typing.Sequence[AgentSuccessfulResponseExample]\n    Non-empty list of example responses that should be considered successful\n\nfailure_examples : typing.Sequence[AgentFailureResponseExample]\n    Non-empty list of example responses that should be considered failures\n\nname : str\n\ntool_call_parameters : typing.Optional[UnitTestToolCallEvaluationModelInput]\n    How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated.\n\ndynamic_variables : typing.Optional[typing.Dict[str, typing.Optional[CreateUnitTestRequestDynamicVariablesValue]]]\n    Dynamic variables to replace in the agent config during testing\n\ntype : typing.Optional[UnitTestCommonModelType]\n\nfrom_conversation_metadata : typing.Optional[TestFromConversationMetadataInput]\n    Metadata of a conversation this test was created from (if applicable).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[CreateUnitTestResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 504
      },
      {
        "path": "async_client.conversational_ai.tests.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Deletes an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 792
      },
      {
        "path": "async_client.conversational_ai.tests.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetUnitTestResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 621
      },
      {
        "path": "async_client.conversational_ai.tests.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Lists all agent response tests with pagination support and optional search filtering.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many Tests to return at maximum. Can not exceed 100, defaults to 30.\n\nsearch : typing.Optional[str]\n    Search query to filter tests by name.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetTestsPageResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 901
      },
      {
        "path": "async_client.conversational_ai.tests.with_raw_response.summaries",
        "name": "summaries",
        "parameters": [
          {
            "name": "test_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets multiple agent response tests by their IDs. Returns a dictionary mapping test IDs to test summaries.\n\nParameters\n----------\ntest_ids : typing.Sequence[str]\n    List of test IDs to fetch. No duplicates allowed.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetTestsSummariesByIdsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 844
      },
      {
        "path": "async_client.conversational_ai.tests.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "test_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chat_history",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_condition",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "success_examples",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "failure_examples",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tool_call_parameters",
            "type": "Optional[UnitTestToolCallEvaluationModelInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dynamic_variables",
            "type": "Optional[Dict[str, Union[str, int, float, bool, NoneType]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "type",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_conversation_metadata",
            "type": "Optional[TestFromConversationMetadataInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Updates an agent response test by ID.\n\nParameters\n----------\ntest_id : str\n    The id of a chat response test. This is returned on test creation.\n\nchat_history : typing.Sequence[ConversationHistoryTranscriptCommonModelInput]\n\nsuccess_condition : str\n    A prompt that evaluates whether the agent's response is successful. Should return True or False.\n\nsuccess_examples : typing.Sequence[AgentSuccessfulResponseExample]\n    Non-empty list of example responses that should be considered successful\n\nfailure_examples : typing.Sequence[AgentFailureResponseExample]\n    Non-empty list of example responses that should be considered failures\n\nname : str\n\ntool_call_parameters : typing.Optional[UnitTestToolCallEvaluationModelInput]\n    How to evaluate the agent's tool call (if any). If empty, the tool call is not evaluated.\n\ndynamic_variables : typing.Optional[typing.Dict[str, typing.Optional[UpdateUnitTestRequestDynamicVariablesValue]]]\n    Dynamic variables to replace in the agent config during testing\n\ntype : typing.Optional[UnitTestCommonModelType]\n\nfrom_conversation_metadata : typing.Optional[TestFromConversationMetadataInput]\n    Metadata of a conversation this test was created from (if applicable).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetUnitTestResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tests/raw_client.py",
        "source_line": 671
      },
      {
        "path": "async_client.conversational_ai.tools.create",
        "name": "create",
        "parameters": [
          {
            "name": "request",
            "type": "ToolRequestModel",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ToolResponseModel",
        "docstring": "Add a new tool to the available tools in the workspace.\n\nParameters\n----------\nrequest : ToolRequestModel\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nToolResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import (\n    AsyncElevenLabs,\n    ToolRequestModel,\n    ToolRequestModelToolConfig_Client,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tools.create(\n        request=ToolRequestModel(\n            tool_config=ToolRequestModelToolConfig_Client(\n                name=\"name\",\n                description=\"description\",\n                expects_response=False,\n            ),\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 306
      },
      {
        "path": "async_client.conversational_ai.tools.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete tool from the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tools.delete(\n        tool_id=\"tool_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 395
      },
      {
        "path": "async_client.conversational_ai.tools.get",
        "name": "get",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ToolResponseModel",
        "docstring": "Get tool that is available in the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nToolResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tools.get(\n        tool_id=\"tool_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 356
      },
      {
        "path": "async_client.conversational_ai.tools.get_dependent_agents",
        "name": "get_dependent_agents",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetToolDependentAgentsResponseModel",
        "docstring": "Get a list of agents depending on this tool\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetToolDependentAgentsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tools.get_dependent_agents(\n        tool_id=\"tool_id\",\n        cursor=\"cursor\",\n        page_size=1,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 488
      },
      {
        "path": "async_client.conversational_ai.tools.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ToolsResponseModel",
        "docstring": "Get all available tools in the workspace.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nToolsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tools.list()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 272
      },
      {
        "path": "async_client.conversational_ai.tools.update",
        "name": "update",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request",
            "type": "ToolRequestModel",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ToolResponseModel",
        "docstring": "Update tool that is available in the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest : ToolRequestModel\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nToolResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import (\n    AsyncElevenLabs,\n    ToolRequestModel,\n    ToolRequestModelToolConfig_Client,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.tools.update(\n        tool_id=\"tool_id\",\n        request=ToolRequestModel(\n            tool_config=ToolRequestModelToolConfig_Client(\n                name=\"name\",\n                description=\"description\",\n                expects_response=False,\n            ),\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/client.py",
        "source_line": 434
      },
      {
        "path": "async_client.conversational_ai.tools.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "request",
            "type": "ToolRequestModel",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Add a new tool to the available tools in the workspace.\n\nParameters\n----------\nrequest : ToolRequestModel\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ToolResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 407
      },
      {
        "path": "async_client.conversational_ai.tools.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete tool from the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 513
      },
      {
        "path": "async_client.conversational_ai.tools.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get tool that is available in the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ToolResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 463
      },
      {
        "path": "async_client.conversational_ai.tools.with_raw_response.get_dependent_agents",
        "name": "get_dependent_agents",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get a list of agents depending on this tool\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many documents to return at maximum. Can not exceed 100, defaults to 30.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetToolDependentAgentsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 624
      },
      {
        "path": "async_client.conversational_ai.tools.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get all available tools in the workspace.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ToolsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 360
      },
      {
        "path": "async_client.conversational_ai.tools.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "tool_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request",
            "type": "ToolRequestModel",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update tool that is available in the workspace.\n\nParameters\n----------\ntool_id : str\n    ID of the requested tool.\n\nrequest : ToolRequestModel\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ToolResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/tools/raw_client.py",
        "source_line": 565
      },
      {
        "path": "async_client.conversational_ai.twilio.outbound_call",
        "name": "outbound_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "TwilioOutboundCallResponse",
        "docstring": "Handle an outbound call via Twilio\n\nParameters\n----------\nagent_id : str\n\nagent_phone_number_id : str\n\nto_number : str\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nTwilioOutboundCallResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.twilio.outbound_call(\n        agent_id=\"agent_id\",\n        agent_phone_number_id=\"agent_phone_number_id\",\n        to_number=\"to_number\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/twilio/client.py",
        "source_line": 156
      },
      {
        "path": "async_client.conversational_ai.twilio.register_call",
        "name": "register_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Register a Twilio call and return TwiML to connect the call\n\nParameters\n----------\nagent_id : str\n\nfrom_number : str\n\nto_number : str\n\ndirection : typing.Optional[BodyRegisterATwilioCallAndReturnTwiMlV1ConvaiTwilioRegisterCallPostDirection]\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.conversational_ai.twilio.register_call(\n        agent_id=\"agent_id\",\n        from_number=\"from_number\",\n        to_number=\"to_number\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/twilio/client.py",
        "source_line": 216
      },
      {
        "path": "async_client.conversational_ai.twilio.with_raw_response.outbound_call",
        "name": "outbound_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "agent_phone_number_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Handle an outbound call via Twilio\n\nParameters\n----------\nagent_id : str\n\nagent_phone_number_id : str\n\nto_number : str\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[TwilioOutboundCallResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/twilio/raw_client.py",
        "source_line": 179
      },
      {
        "path": "async_client.conversational_ai.twilio.with_raw_response.register_call",
        "name": "register_call",
        "parameters": [
          {
            "name": "agent_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "to_number",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "conversation_initiation_client_data",
            "type": "Optional[ConversationInitiationClientDataRequestInput]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Register a Twilio call and return TwiML to connect the call\n\nParameters\n----------\nagent_id : str\n\nfrom_number : str\n\nto_number : str\n\ndirection : typing.Optional[BodyRegisterATwilioCallAndReturnTwiMlV1ConvaiTwilioRegisterCallPostDirection]\n\nconversation_initiation_client_data : typing.Optional[ConversationInitiationClientDataRequestInput]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[None]",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/twilio/raw_client.py",
        "source_line": 254
      },
      {
        "path": "async_client.conversational_ai.with_raw_response.add_to_knowledge_base",
        "name": "add_to_knowledge_base",
        "parameters": [
          {
            "name": "agent_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Upload a file or webpage URL to create a knowledge base document. <br> <Note> After creating the document, update the agent's knowledge base by calling [Update agent](/docs/api-reference/agents/update). </Note>\n\nParameters\n----------\nagent_id : typing.Optional[str]\n\nname : typing.Optional[str]\n    A custom, human-readable name for the document.\n\nurl : typing.Optional[str]\n    URL to a page of documentation that the agent will have access to in order to interact with users.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddKnowledgeBaseResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/raw_client.py",
        "source_line": 259
      },
      {
        "path": "async_client.conversational_ai.with_raw_response.delete_document_rag_index",
        "name": "delete_document_rag_index",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rag_index_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete RAG index for the knowledgebase document.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrag_index_id : str\n    The id of RAG index of document from the knowledge base.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[RagDocumentIndexResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/raw_client.py",
        "source_line": 432
      },
      {
        "path": "async_client.conversational_ai.with_raw_response.get_document_rag_indexes",
        "name": "get_document_rag_indexes",
        "parameters": [
          {
            "name": "documentation_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Provides information about all RAG indexes of the specified knowledgebase document.\n\nParameters\n----------\ndocumentation_id : str\n    The id of a document from the knowledge base. This is returned on document addition.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[RagDocumentIndexesResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/raw_client.py",
        "source_line": 382
      },
      {
        "path": "async_client.conversational_ai.with_raw_response.rag_index_overview",
        "name": "rag_index_overview",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Provides total size and other information of RAG indexes used by knowledgebase documents\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[RagIndexOverviewResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/conversational_ai/raw_client.py",
        "source_line": 335
      },
      {
        "path": "async_client.dubbing.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language_code",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Returns dub as a streamed MP3 or MP4 file. If this dub has been edited using Dubbing Studio you need to use the resource render endpoint as this endpoint only returns the original automatic dub result.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage_code : str\n    ID of the language.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The dubbed audio or video file\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.audio.get(\n        dubbing_id=\"dubbing_id\",\n        language_code=\"language_code\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/audio/client.py",
        "source_line": 78
      },
      {
        "path": "async_client.dubbing.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language_code",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Returns dub as a streamed MP3 or MP4 file. If this dub has been edited using Dubbing Studio you need to use the resource render endpoint as this endpoint only returns the original automatic dub result.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage_code : str\n    ID of the language.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The dubbed audio or video file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 119
      },
      {
        "path": "async_client.dubbing.create",
        "name": "create",
        "parameters": [
          {
            "name": "file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "csv_file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "foreground_audio_file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "background_audio_file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_lang",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_lang",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_accent",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "num_speakers",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "watermark",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "start_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "highest_resolution",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "drop_background_audio",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_profanity_filter",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dubbing_studio",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_voice_cloning",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mode",
            "type": "Optional[DubbingCreateRequestMode]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "csv_fps",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DoDubbingResponse",
        "docstring": "Dubs a provided audio or video file into given language.\n\nParameters\n----------\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\ncsv_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nforeground_audio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nbackground_audio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nname : typing.Optional[str]\n    Name of the dubbing project.\n\nsource_url : typing.Optional[str]\n    URL of the source video/audio file.\n\nsource_lang : typing.Optional[str]\n    Source language. Expects a valid iso639-1 or iso639-3 language code.\n\ntarget_lang : typing.Optional[str]\n    The Target language to dub the content into. Expects a valid iso639-1 or iso639-3 language code.\n\ntarget_accent : typing.Optional[str]\n    [Experimental] An accent to apply when selecting voices from the library and to use to inform translation of the dialect to prefer.\n\nnum_speakers : typing.Optional[int]\n    Number of speakers to use for the dubbing. Set to 0 to automatically detect the number of speakers\n\nwatermark : typing.Optional[bool]\n    Whether to apply watermark to the output video.\n\nstart_time : typing.Optional[int]\n    Start time of the source video/audio file.\n\nend_time : typing.Optional[int]\n    End time of the source video/audio file.\n\nhighest_resolution : typing.Optional[bool]\n    Whether to use the highest resolution available.\n\ndrop_background_audio : typing.Optional[bool]\n    An advanced setting. Whether to drop background audio from the final dub. This can improve dub quality where it's known that audio shouldn't have a background track such as for speeches or monologues.\n\nuse_profanity_filter : typing.Optional[bool]\n    [BETA] Whether transcripts should have profanities censored with the words '[censored]'\n\ndubbing_studio : typing.Optional[bool]\n    Whether to prepare dub for edits in dubbing studio or edits as a dubbing resource.\n\ndisable_voice_cloning : typing.Optional[bool]\n    Instead of using a voice clone in dubbing, use a similar voice from the ElevenLabs Voice Library. Voices used from the library will contribute towards a workspace's custom voices limit, and if there aren't enough available slots the dub will fail. Using this feature requires the caller to have the 'add_voice_from_voice_library' permission on their workspace to access new voices.\n\nmode : typing.Optional[DubbingCreateRequestMode]\n    The mode in which to run this Dubbing job. Defaults to automatic, use manual if specifically providing a CSV transcript to use.\n\ncsv_fps : typing.Optional[float]\n    Frames per second to use when parsing a CSV file for dubbing. If not provided, FPS will be inferred from timecodes.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDoDubbingResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.create()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/client.py",
        "source_line": 433
      },
      {
        "path": "async_client.dubbing.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteDubbingResponseModel",
        "docstring": "Deletes a dubbing project.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteDubbingResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.delete(\n        dubbing_id=\"dubbing_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/client.py",
        "source_line": 614
      },
      {
        "path": "async_client.dubbing.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DubbingMetadataResponse",
        "docstring": "Returns metadata about a dubbing project, including whether it's still in progress or not\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDubbingMetadataResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.get(\n        dubbing_id=\"dubbing_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/client.py",
        "source_line": 573
      },
      {
        "path": "async_client.dubbing.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dubbing_status",
            "type": "Optional[DubbingListRequestDubbingStatus]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "filter_by_creator",
            "type": "Optional[DubbingListRequestFilterByCreator]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "order_by",
            "type": "Optional[Literal['created_at']]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "order_direction",
            "type": "Optional[DubbingListRequestOrderDirection]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DubbingMetadataPageResponseModel",
        "docstring": "List the dubs you have access to.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many dubs to return at maximum. Can not exceed 200, defaults to 100.\n\ndubbing_status : typing.Optional[DubbingListRequestDubbingStatus]\n    What state the dub is currently in.\n\nfilter_by_creator : typing.Optional[DubbingListRequestFilterByCreator]\n    Filters who created the resources being listed, whether it was the user running the request or someone else that shared the resource with them.\n\norder_by : typing.Optional[typing.Literal[\"created_at\"]]\n    The field to use for ordering results from this query.\n\norder_direction : typing.Optional[DubbingListRequestOrderDirection]\n    The order direction to use for results from this query.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDubbingMetadataPageResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.list(\n        cursor=\"cursor\",\n        page_size=1,\n        dubbing_status=\"dubbing\",\n        filter_by_creator=\"personal\",\n        order_direction=\"DESCENDING\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/client.py",
        "source_line": 357
      },
      {
        "path": "async_client.dubbing.resource.dub",
        "name": "dub",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentDubResponse",
        "docstring": "Regenerate the dubs for either the entire resource or the specified segments/languages. Will automatically transcribe and translate any missing transcriptions and translations.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Dub only this list of segments.\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Dub only these languages for each segment.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentDubResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.dub(\n        dubbing_id=\"dubbing_id\",\n        segments=[\"segments\"],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 555
      },
      {
        "path": "async_client.dubbing.resource.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DubbingResource",
        "docstring": "Given a dubbing ID generated from the '/v1/dubbing' endpoint with studio enabled, returns the dubbing resource.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDubbingResource\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.get(\n        dubbing_id=\"dubbing_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 358
      },
      {
        "path": "async_client.dubbing.resource.language.add",
        "name": "add",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "LanguageAddedResponse",
        "docstring": "Adds the given ElevenLab Turbo V2/V2.5 language code to the resource. Does not automatically generate transcripts/translations/audio.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage : typing.Optional[str]\n    The Target language.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nLanguageAddedResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.language.add(\n        dubbing_id=\"dubbing_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/language/client.py",
        "source_line": 85
      },
      {
        "path": "async_client.dubbing.resource.language.with_raw_response.add",
        "name": "add",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Adds the given ElevenLab Turbo V2/V2.5 language code to the resource. Does not automatically generate transcripts/translations/audio.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage : typing.Optional[str]\n    The Target language.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[LanguageAddedResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/language/raw_client.py",
        "source_line": 93
      },
      {
        "path": "async_client.dubbing.resource.migrate_segments",
        "name": "migrate_segments",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_ids",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentMigrationResponse",
        "docstring": "Change the attribution of one or more segments to a different speaker.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_ids : typing.Sequence[str]\n\nspeaker_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentMigrationResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.migrate_segments(\n        dubbing_id=\"dubbing_id\",\n        segment_ids=[\"segment_ids\"],\n        speaker_id=\"speaker_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 397
      },
      {
        "path": "async_client.dubbing.resource.render",
        "name": "render",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "ResourceRenderRequestLanguage",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "render_type",
            "type": "RenderType",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "normalize_volume",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DubbingRenderResponseModel",
        "docstring": "Regenerate the output media for a language using the latest Studio state. Please ensure all segments have been dubbed before rendering, otherwise they will be omitted. Renders are generated asynchronously, and to check the status of all renders please use the 'Get Dubbing Resource' endpoint.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage : ResourceRenderRequestLanguage\n    The target language code to render, eg. 'es'. To render the source track use 'original'.\n\nrender_type : RenderType\n    The type of the render. One of ['mp4', 'aac', 'mp3', 'wav', 'aaf', 'tracks_zip', 'clips_zip']\n\nnormalize_volume : typing.Optional[bool]\n    Whether to normalize the volume of the rendered audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDubbingRenderResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.render(\n        dubbing_id=\"dubbing_id\",\n        language=\"original\",\n        render_type=\"mp4\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 610
      },
      {
        "path": "async_client.dubbing.resource.segment.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentDeleteResponse",
        "docstring": "Deletes a single segment from the dubbing.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_id : str\n    ID of the segment\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentDeleteResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.segment.delete(\n        dubbing_id=\"dubbing_id\",\n        segment_id=\"segment_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/segment/client.py",
        "source_line": 217
      },
      {
        "path": "async_client.dubbing.resource.segment.update",
        "name": "update",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "start_time",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentUpdateResponse",
        "docstring": "Modifies a single segment with new text and/or start/end times. Will update the values for only a specific language of a segment. Does not automatically regenerate the dub.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_id : str\n    ID of the segment\n\nlanguage : str\n    ID of the language.\n\nstart_time : typing.Optional[float]\n\nend_time : typing.Optional[float]\n\ntext : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentUpdateResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.segment.update(\n        dubbing_id=\"dubbing_id\",\n        segment_id=\"segment_id\",\n        language=\"language\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/segment/client.py",
        "source_line": 146
      },
      {
        "path": "async_client.dubbing.resource.segment.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Deletes a single segment from the dubbing.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_id : str\n    ID of the segment\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SegmentDeleteResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/segment/raw_client.py",
        "source_line": 241
      },
      {
        "path": "async_client.dubbing.resource.segment.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "start_time",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Modifies a single segment with new text and/or start/end times. Will update the values for only a specific language of a segment. Does not automatically regenerate the dub.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_id : str\n    ID of the segment\n\nlanguage : str\n    ID of the language.\n\nstart_time : typing.Optional[float]\n\nend_time : typing.Optional[float]\n\ntext : typing.Optional[str]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SegmentUpdateResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/segment/raw_client.py",
        "source_line": 162
      },
      {
        "path": "async_client.dubbing.resource.speaker.create",
        "name": "create",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_stability",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_similarity",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_style",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeakerCreatedResponse",
        "docstring": "Parameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_name : typing.Optional[str]\n    Name to attribute to this speaker.\n\nvoice_id : typing.Optional[str]\n    Either the identifier of a voice from the ElevenLabs voice library, or one of ['track-clone', 'clip-clone'].\n\nvoice_stability : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\n\nvoice_similarity : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nvoice_style : typing.Optional[float]\n    For models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeakerCreatedResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.speaker.create(\n        dubbing_id=\"dubbing_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/client.py",
        "source_line": 320
      },
      {
        "path": "async_client.dubbing.resource.speaker.find_similar_voices",
        "name": "find_similar_voices",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SimilarVoicesForSpeakerResponse",
        "docstring": "Fetch the top 10 similar voices to a speaker, including the voice IDs, names, descriptions, and, where possible, a sample audio recording.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSimilarVoicesForSpeakerResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.speaker.find_similar_voices(\n        dubbing_id=\"dubbing_id\",\n        speaker_id=\"speaker_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/client.py",
        "source_line": 390
      },
      {
        "path": "async_client.dubbing.resource.speaker.segment.create",
        "name": "create",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "start_time",
            "type": "float",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "float",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "translations",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentCreateResponse",
        "docstring": "Creates a new segment in dubbing resource with a start and end time for the speaker in every available language. Does not automatically generate transcripts/translations/audio.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nstart_time : float\n\nend_time : float\n\ntext : typing.Optional[str]\n\ntranslations : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentCreateResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.speaker.segment.create(\n        dubbing_id=\"dubbing_id\",\n        speaker_id=\"speaker_id\",\n        start_time=1.1,\n        end_time=1.1,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/segment/client.py",
        "source_line": 108
      },
      {
        "path": "async_client.dubbing.resource.speaker.segment.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "start_time",
            "type": "float",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "float",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "translations",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Creates a new segment in dubbing resource with a start and end time for the speaker in every available language. Does not automatically generate transcripts/translations/audio.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nstart_time : float\n\nend_time : float\n\ntext : typing.Optional[str]\n\ntranslations : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SegmentCreateResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/segment/raw_client.py",
        "source_line": 108
      },
      {
        "path": "async_client.dubbing.resource.speaker.update",
        "name": "update",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_stability",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_similarity",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_style",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeakerUpdatedResponse",
        "docstring": "Amend the metadata associated with a speaker, such as their voice. Both voice cloning and using voices from the ElevenLabs library are supported.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nspeaker_name : typing.Optional[str]\n    Name to attribute to this speaker.\n\nvoice_id : typing.Optional[str]\n    Either the identifier of a voice from the ElevenLabs voice library, or one of ['track-clone', 'clip-clone'].\n\nvoice_stability : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\n\nvoice_similarity : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nvoice_style : typing.Optional[float]\n    For models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Languages to apply these changes to. If empty, will apply to all languages.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeakerUpdatedResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.speaker.update(\n        dubbing_id=\"dubbing_id\",\n        speaker_id=\"speaker_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/client.py",
        "source_line": 237
      },
      {
        "path": "async_client.dubbing.resource.speaker.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_stability",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_similarity",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_style",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Parameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_name : typing.Optional[str]\n    Name to attribute to this speaker.\n\nvoice_id : typing.Optional[str]\n    Either the identifier of a voice from the ElevenLabs voice library, or one of ['track-clone', 'clip-clone'].\n\nvoice_stability : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\n\nvoice_similarity : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nvoice_style : typing.Optional[float]\n    For models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SpeakerCreatedResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/raw_client.py",
        "source_line": 352
      },
      {
        "path": "async_client.dubbing.resource.speaker.with_raw_response.find_similar_voices",
        "name": "find_similar_voices",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Fetch the top 10 similar voices to a speaker, including the voice IDs, names, descriptions, and, where possible, a sample audio recording.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SimilarVoicesForSpeakerResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/raw_client.py",
        "source_line": 434
      },
      {
        "path": "async_client.dubbing.resource.speaker.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_stability",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_similarity",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_style",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Amend the metadata associated with a speaker, such as their voice. Both voice cloning and using voices from the ElevenLabs library are supported.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nspeaker_id : str\n    ID of the speaker.\n\nspeaker_name : typing.Optional[str]\n    Name to attribute to this speaker.\n\nvoice_id : typing.Optional[str]\n    Either the identifier of a voice from the ElevenLabs voice library, or one of ['track-clone', 'clip-clone'].\n\nvoice_stability : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\n\nvoice_similarity : typing.Optional[float]\n    For models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nvoice_style : typing.Optional[float]\n    For models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Languages to apply these changes to. If empty, will apply to all languages.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SpeakerUpdatedResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/speaker/raw_client.py",
        "source_line": 259
      },
      {
        "path": "async_client.dubbing.resource.transcribe",
        "name": "transcribe",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentTranscriptionResponse",
        "docstring": "Regenerate the transcriptions for the specified segments. Does not automatically regenerate translations or dubs.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Transcribe this specific list of segments.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentTranscriptionResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.transcribe(\n        dubbing_id=\"dubbing_id\",\n        segments=[\"segments\"],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 451
      },
      {
        "path": "async_client.dubbing.resource.translate",
        "name": "translate",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence[str]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SegmentTranslationResponse",
        "docstring": "Regenerate the translations for either the entire resource or the specified segments/languages. Will automatically transcribe missing transcriptions. Will not automatically regenerate the dubs.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Translate only this list of segments.\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Translate only these languages for each segment.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSegmentTranslationResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.resource.translate(\n        dubbing_id=\"dubbing_id\",\n        segments=[\"segments\"],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/client.py",
        "source_line": 500
      },
      {
        "path": "async_client.dubbing.resource.with_raw_response.dub",
        "name": "dub",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Regenerate the dubs for either the entire resource or the specified segments/languages. Will automatically transcribe and translate any missing transcriptions and translations.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Dub only this list of segments.\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Dub only these languages for each segment.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SegmentDubResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 678
      },
      {
        "path": "async_client.dubbing.resource.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Given a dubbing ID generated from the '/v1/dubbing' endpoint with studio enabled, returns the dubbing resource.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DubbingResource]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 428
      },
      {
        "path": "async_client.dubbing.resource.with_raw_response.migrate_segments",
        "name": "migrate_segments",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segment_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Change the attribution of one or more segments to a different speaker.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegment_ids : typing.Sequence[str]\n\nspeaker_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SegmentMigrationResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 478
      },
      {
        "path": "async_client.dubbing.resource.with_raw_response.render",
        "name": "render",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language",
            "type": "Union[str, Literal]",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "render_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "normalize_volume",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Regenerate the output media for a language using the latest Studio state. Please ensure all segments have been dubbed before rendering, otherwise they will be omitted. Renders are generated asynchronously, and to check the status of all renders please use the 'Get Dubbing Resource' endpoint.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage : ResourceRenderRequestLanguage\n    The target language code to render, eg. 'es'. To render the source track use 'original'.\n\nrender_type : RenderType\n    The type of the render. One of ['mp4', 'aac', 'mp3', 'wav', 'aaf', 'tracks_zip', 'clips_zip']\n\nnormalize_volume : typing.Optional[bool]\n    Whether to normalize the volume of the rendered audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DubbingRenderResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 747
      },
      {
        "path": "async_client.dubbing.resource.with_raw_response.transcribe",
        "name": "transcribe",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Regenerate the transcriptions for the specified segments. Does not automatically regenerate translations or dubs.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Transcribe this specific list of segments.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SegmentTranscriptionResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 545
      },
      {
        "path": "async_client.dubbing.resource.with_raw_response.translate",
        "name": "translate",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "segments",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "languages",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Regenerate the translations for either the entire resource or the specified segments/languages. Will automatically transcribe missing transcriptions. Will not automatically regenerate the dubs.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nsegments : typing.Sequence[str]\n    Translate only this list of segments.\n\nlanguages : typing.Optional[typing.Sequence[str]]\n    Translate only these languages for each segment.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SegmentTranslationResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/resource/raw_client.py",
        "source_line": 609
      },
      {
        "path": "async_client.dubbing.transcript.get_transcript_for_dub",
        "name": "get_transcript_for_dub",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language_code",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "format_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Union[DubbingTranscriptResponseModel, str]",
        "docstring": "Returns transcript for the dub as an SRT or WEBVTT file.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage_code : str\n    ID of the language.\n\nformat_type : typing.Optional[TranscriptGetTranscriptForDubRequestFormatType]\n    Format to return transcript in. For subtitles use either 'srt' or 'webvtt', and for a full transcript use 'json'. The 'json' format is not yet supported for Dubbing Studio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nTranscriptGetTranscriptForDubResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.dubbing.transcript.get_transcript_for_dub(\n        dubbing_id=\"dubbing_id\",\n        language_code=\"language_code\",\n        format_type=\"srt\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/transcript/client.py",
        "source_line": 91
      },
      {
        "path": "async_client.dubbing.transcript.with_raw_response.get_transcript_for_dub",
        "name": "get_transcript_for_dub",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "language_code",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "format_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns transcript for the dub as an SRT or WEBVTT file.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nlanguage_code : str\n    ID of the language.\n\nformat_type : typing.Optional[TranscriptGetTranscriptForDubRequestFormatType]\n    Format to return transcript in. For subtitles use either 'srt' or 'webvtt', and for a full transcript use 'json'. The 'json' format is not yet supported for Dubbing Studio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[TranscriptGetTranscriptForDubResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/transcript/raw_client.py",
        "source_line": 127
      },
      {
        "path": "async_client.dubbing.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "csv_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "foreground_audio_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "background_audio_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_lang",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_lang",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_accent",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "num_speakers",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "watermark",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "start_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "highest_resolution",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "drop_background_audio",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_profanity_filter",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dubbing_studio",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "disable_voice_cloning",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mode",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "csv_fps",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Dubs a provided audio or video file into given language.\n\nParameters\n----------\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\ncsv_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nforeground_audio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nbackground_audio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nname : typing.Optional[str]\n    Name of the dubbing project.\n\nsource_url : typing.Optional[str]\n    URL of the source video/audio file.\n\nsource_lang : typing.Optional[str]\n    Source language. Expects a valid iso639-1 or iso639-3 language code.\n\ntarget_lang : typing.Optional[str]\n    The Target language to dub the content into. Expects a valid iso639-1 or iso639-3 language code.\n\ntarget_accent : typing.Optional[str]\n    [Experimental] An accent to apply when selecting voices from the library and to use to inform translation of the dialect to prefer.\n\nnum_speakers : typing.Optional[int]\n    Number of speakers to use for the dubbing. Set to 0 to automatically detect the number of speakers\n\nwatermark : typing.Optional[bool]\n    Whether to apply watermark to the output video.\n\nstart_time : typing.Optional[int]\n    Start time of the source video/audio file.\n\nend_time : typing.Optional[int]\n    End time of the source video/audio file.\n\nhighest_resolution : typing.Optional[bool]\n    Whether to use the highest resolution available.\n\ndrop_background_audio : typing.Optional[bool]\n    An advanced setting. Whether to drop background audio from the final dub. This can improve dub quality where it's known that audio shouldn't have a background track such as for speeches or monologues.\n\nuse_profanity_filter : typing.Optional[bool]\n    [BETA] Whether transcripts should have profanities censored with the words '[censored]'\n\ndubbing_studio : typing.Optional[bool]\n    Whether to prepare dub for edits in dubbing studio or edits as a dubbing resource.\n\ndisable_voice_cloning : typing.Optional[bool]\n    Instead of using a voice clone in dubbing, use a similar voice from the ElevenLabs Voice Library. Voices used from the library will contribute towards a workspace's custom voices limit, and if there aren't enough available slots the dub will fail. Using this feature requires the caller to have the 'add_voice_from_voice_library' permission on their workspace to access new voices.\n\nmode : typing.Optional[DubbingCreateRequestMode]\n    The mode in which to run this Dubbing job. Defaults to automatic, use manual if specifically providing a CSV transcript to use.\n\ncsv_fps : typing.Optional[float]\n    Frames per second to use when parsing a CSV file for dubbing. If not provided, FPS will be inferred from timecodes.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DoDubbingResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/raw_client.py",
        "source_line": 454
      },
      {
        "path": "async_client.dubbing.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Deletes a dubbing project.\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteDubbingResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/raw_client.py",
        "source_line": 659
      },
      {
        "path": "async_client.dubbing.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "dubbing_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns metadata about a dubbing project, including whether it's still in progress or not\n\nParameters\n----------\ndubbing_id : str\n    ID of the dubbing project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DubbingMetadataResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/raw_client.py",
        "source_line": 609
      },
      {
        "path": "async_client.dubbing.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "dubbing_status",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "filter_by_creator",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "order_by",
            "type": "Optional[Literal]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "order_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "List the dubs you have access to.\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many dubs to return at maximum. Can not exceed 200, defaults to 100.\n\ndubbing_status : typing.Optional[DubbingListRequestDubbingStatus]\n    What state the dub is currently in.\n\nfilter_by_creator : typing.Optional[DubbingListRequestFilterByCreator]\n    Filters who created the resources being listed, whether it was the user running the request or someone else that shared the resource with them.\n\norder_by : typing.Optional[typing.Literal[\"created_at\"]]\n    The field to use for ordering results from this query.\n\norder_direction : typing.Optional[DubbingListRequestOrderDirection]\n    The order direction to use for results from this query.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DubbingMetadataPageResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/dubbing/raw_client.py",
        "source_line": 373
      },
      {
        "path": "async_client.forced_alignment.create",
        "name": "create",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enabled_spooled_file",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ForcedAlignmentResponseModel",
        "docstring": "Force align an audio file to text. Use this endpoint to get the timing information for each character and word in an audio file based on a provided text transcript.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\ntext : str\n    The text to align with the audio. The input text can be in any format, however diarization is not supported at this time.\n\nenabled_spooled_file : typing.Optional[bool]\n    If true, the file will be streamed to the server and processed in chunks. This is useful for large files that cannot be loaded into memory. The default is false.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nForcedAlignmentResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.forced_alignment.create(\n        text=\"text\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/forced_alignment/client.py",
        "source_line": 92
      },
      {
        "path": "async_client.forced_alignment.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enabled_spooled_file",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Force align an audio file to text. Use this endpoint to get the timing information for each character and word in an audio file based on a provided text transcript.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\ntext : str\n    The text to align with the audio. The input text can be in any format, however diarization is not supported at this time.\n\nenabled_spooled_file : typing.Optional[bool]\n    If true, the file will be streamed to the server and processed in chunks. This is useful for large files that cannot be loaded into memory. The default is false.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ForcedAlignmentResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/forced_alignment/raw_client.py",
        "source_line": 99
      },
      {
        "path": "async_client.history.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteHistoryItemResponse",
        "docstring": "Delete a history item by its ID\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteHistoryItemResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.history.delete(\n        history_item_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 413
      },
      {
        "path": "async_client.history.download",
        "name": "download",
        "parameters": [
          {
            "name": "history_item_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Download one or more history items. If one history item ID is provided, we will return a single audio file. If more than one history item IDs are provided, we will provide the history items packed into a .zip file.\n\nParameters\n----------\nhistory_item_ids : typing.Sequence[str]\n    A list of history items to download, you can get IDs of history items and other metadata using the GET https://api.elevenlabs.io/v1/history endpoint.\n\noutput_format : typing.Optional[str]\n    Output format to transcode the audio file, can be wav or default.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The requested audio file, or a zip file containing multiple audio files when multiple history items are requested.\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.history.download(\n        history_item_ids=[\"history_item_ids\", \"history_item_ids\"],\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 496
      },
      {
        "path": "async_client.history.get",
        "name": "get",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeechHistoryItemResponse",
        "docstring": "Retrieves a history item.\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeechHistoryItemResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.history.get(\n        history_item_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 372
      },
      {
        "path": "async_client.history.get_audio",
        "name": "get_audio",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Returns the audio of an history item.\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The audio file of the history item.\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.history.get_audio(\n        history_item_id=\"history_item_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 454
      },
      {
        "path": "async_client.history.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "start_after_history_item_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "date_before_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "date_after_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetSpeechHistoryResponse",
        "docstring": "Returns a list of your generated audio.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many history items to return at maximum. Can not exceed 1000, defaults to 100.\n\nstart_after_history_item_id : typing.Optional[str]\n    After which ID to start fetching, use this parameter to paginate across a large collection of history items. In case this parameter is not provided history items will be fetched starting from the most recently created one ordered descending by their creation date.\n\nvoice_id : typing.Optional[str]\n    ID of the voice to be filtered for. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nmodel_id : typing.Optional[str]\n    Search term used for filtering history items. If provided, source becomes required.\n\ndate_before_unix : typing.Optional[int]\n    Unix timestamp to filter history items before this date (exclusive).\n\ndate_after_unix : typing.Optional[int]\n    Unix timestamp to filter history items after this date (inclusive).\n\nsort_direction : typing.Optional[HistoryListRequestSortDirection]\n    Sort direction for the results.\n\nsearch : typing.Optional[str]\n    search term used for filtering\n\nsource : typing.Optional[HistoryListRequestSource]\n    Source of the generated history item\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetSpeechHistoryResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.history.list(\n        page_size=1,\n        start_after_history_item_id=\"start_after_history_item_id\",\n        voice_id=\"voice_id\",\n        model_id=\"model_id\",\n        date_before_unix=1,\n        date_after_unix=1,\n        sort_direction=\"asc\",\n        search=\"search\",\n        source=\"TTS\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/client.py",
        "source_line": 277
      },
      {
        "path": "async_client.history.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete a history item by its ID\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteHistoryItemResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/raw_client.py",
        "source_line": 512
      },
      {
        "path": "async_client.history.with_raw_response.download",
        "name": "download",
        "parameters": [
          {
            "name": "history_item_ids",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Download one or more history items. If one history item ID is provided, we will return a single audio file. If more than one history item IDs are provided, we will provide the history items packed into a .zip file.\n\nParameters\n----------\nhistory_item_ids : typing.Sequence[str]\n    A list of history items to download, you can get IDs of history items and other metadata using the GET https://api.elevenlabs.io/v1/history endpoint.\n\noutput_format : typing.Optional[str]\n    Output format to transcode the audio file, can be wav or default.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The requested audio file, or a zip file containing multiple audio files when multiple history items are requested.",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 617
      },
      {
        "path": "async_client.history.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieves a history item.\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SpeechHistoryItemResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/raw_client.py",
        "source_line": 462
      },
      {
        "path": "async_client.history.with_raw_response.get_audio",
        "name": "get_audio",
        "parameters": [
          {
            "name": "history_item_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Returns the audio of an history item.\n\nParameters\n----------\nhistory_item_id : str\n    ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The audio file of the history item.",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 562
      },
      {
        "path": "async_client.history.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "start_after_history_item_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "date_before_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "date_after_unix",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns a list of your generated audio.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many history items to return at maximum. Can not exceed 1000, defaults to 100.\n\nstart_after_history_item_id : typing.Optional[str]\n    After which ID to start fetching, use this parameter to paginate across a large collection of history items. In case this parameter is not provided history items will be fetched starting from the most recently created one ordered descending by their creation date.\n\nvoice_id : typing.Optional[str]\n    ID of the voice to be filtered for. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nmodel_id : typing.Optional[str]\n    Search term used for filtering history items. If provided, source becomes required.\n\ndate_before_unix : typing.Optional[int]\n    Unix timestamp to filter history items before this date (exclusive).\n\ndate_after_unix : typing.Optional[int]\n    Unix timestamp to filter history items after this date (inclusive).\n\nsort_direction : typing.Optional[HistoryListRequestSortDirection]\n    Sort direction for the results.\n\nsearch : typing.Optional[str]\n    search term used for filtering\n\nsource : typing.Optional[HistoryListRequestSource]\n    Source of the generated history item\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetSpeechHistoryResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/history/raw_client.py",
        "source_line": 366
      },
      {
        "path": "async_client.models.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "List[Model]",
        "docstring": "Gets a list of available models.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.List[Model]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.models.list()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/models/client.py",
        "source_line": 68
      },
      {
        "path": "async_client.models.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets a list of available models.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.List[Model]]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/models/raw_client.py",
        "source_line": 70
      },
      {
        "path": "async_client.music.compose",
        "name": "compose",
        "parameters": [
          {
            "name": "output_format",
            "type": "Optional[MusicComposeRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal['music_v1']]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "respect_sections_durations",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator[bytes]",
        "docstring": "Compose a song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicComposeRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nrespect_sections_durations : typing.Optional[bool]\n    Controls how strictly section durations in the `composition_plan` are enforced. Only used with `composition_plan`. When set to true, the model will precisely respect each section's `duration_ms` from the plan. When set to false, the model may adjust individual section durations which will generally lead to better generation quality and improved latency, while always preserving the total song duration from the plan.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The generated audio file in the format specified\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.music.compose()\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/client.py",
        "source_line": 331
      },
      {
        "path": "async_client.music.compose_detailed",
        "name": "compose_detailed",
        "parameters": [
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "MultipartResponse",
        "docstring": "Compose a song from a prompt or a composition plan with detailed response parsing.\nThis method calls the original compose_detailed and then parses the stream response.\n\nReturns a MultipartResponse containing parsed JSON metadata, audio bytes, and filename.",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music_custom.py",
        "source_line": 167
      },
      {
        "path": "async_client.music.composition_plan.create",
        "name": "create",
        "parameters": [
          {
            "name": "prompt",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "MusicPrompt",
        "docstring": "Create a composition plan for music generation. Usage of this endpoint does not cost any credits but is subject to rate limiting depending on your tier.\n\nParameters\n----------\nprompt : str\n    A simple text prompt to compose a plan from.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the composition plan to generate in milliseconds. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nsource_composition_plan : typing.Optional[MusicPrompt]\n    An optional composition plan to use as a source for the new composition plan.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nMusicPrompt\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.music.composition_plan.create(\n        prompt=\"prompt\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/composition_plan/client.py",
        "source_line": 99
      },
      {
        "path": "async_client.music.composition_plan.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "prompt",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a composition plan for music generation. Usage of this endpoint does not cost any credits but is subject to rate limiting depending on your tier.\n\nParameters\n----------\nprompt : str\n    A simple text prompt to compose a plan from.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the composition plan to generate in milliseconds. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nsource_composition_plan : typing.Optional[MusicPrompt]\n    An optional composition plan to use as a source for the new composition plan.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[MusicPrompt]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/composition_plan/raw_client.py",
        "source_line": 106
      },
      {
        "path": "async_client.music.separate_stems",
        "name": "separate_stems",
        "parameters": [
          {
            "name": "file",
            "type": "core.File",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[MusicSeparateStemsRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stem_variation_id",
            "type": "Optional[MusicSeparateStemsRequestStemVariationId]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator[bytes]",
        "docstring": "Separate an audio file into individual stems. This endpoint might have high latency, depending on the length of the audio file.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\noutput_format : typing.Optional[MusicSeparateStemsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nstem_variation_id : typing.Optional[MusicSeparateStemsRequestStemVariationId]\n    The id of the stem variation to use.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    ZIP archive containing separated audio stems. Each stem is provided as a separate audio file in the requested output format.",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/client.py",
        "source_line": 579
      },
      {
        "path": "async_client.music.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "output_format",
            "type": "Optional[MusicStreamRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal['music_v1']]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator[bytes]",
        "docstring": "Stream a composed song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Streaming audio data in the format specified\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.music.stream()\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/music/client.py",
        "source_line": 503
      },
      {
        "path": "async_client.music.with_raw_response.compose",
        "name": "compose",
        "parameters": [
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "respect_sections_durations",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Compose a song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicComposeRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nrespect_sections_durations : typing.Optional[bool]\n    Controls how strictly section durations in the `composition_plan` are enforced. Only used with `composition_plan`. When set to true, the model will precisely respect each section's `duration_ms` from the plan. When set to false, the model may adjust individual section durations which will generally lead to better generation quality and improved latency, while always preserving the total song duration from the plan.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The generated audio file in the format specified",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 431
      },
      {
        "path": "async_client.music.with_raw_response.compose_detailed",
        "name": "compose_detailed",
        "parameters": [
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "with_timestamps",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Compose a song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicComposeDetailedRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nwith_timestamps : typing.Optional[bool]\n    Whether to return the timestamps of the words in the generated song.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Multipart/mixed response with JSON metadata and binary audio file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 540
      },
      {
        "path": "async_client.music.with_raw_response.separate_stems",
        "name": "separate_stems",
        "parameters": [
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stem_variation_id",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sign_with_c_2_pa",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Separate an audio file into individual stems. This endpoint might have high latency, depending on the length of the audio file.\n\nParameters\n----------\nfile : core.File\n    See core.File for more documentation\n\noutput_format : typing.Optional[MusicSeparateStemsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nstem_variation_id : typing.Optional[MusicSeparateStemsRequestStemVariationId]\n    The id of the stem variation to use.\n\nsign_with_c_2_pa : typing.Optional[bool]\n    Whether to sign the generated song with C2PA. Applicable only for mp3 files.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    ZIP archive containing separated audio stems. Each stem is provided as a separate audio file in the requested output format.",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 748
      },
      {
        "path": "async_client.music.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "composition_plan",
            "type": "Optional[MusicPrompt]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "music_length_ms",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[Literal]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "force_instrumental",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "store_for_inpainting",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream a composed song from a prompt or a composition plan.\n\nParameters\n----------\noutput_format : typing.Optional[MusicStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nprompt : typing.Optional[str]\n    A simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\n\ncomposition_plan : typing.Optional[MusicPrompt]\n    A detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\n\nmusic_length_ms : typing.Optional[int]\n    The length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 300000ms. Optional - if not provided, the model will choose a length based on the prompt.\n\nmodel_id : typing.Optional[typing.Literal[\"music_v1\"]]\n    The model to use for the generation.\n\nforce_instrumental : typing.Optional[bool]\n    If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\n\nstore_for_inpainting : typing.Optional[bool]\n    Whether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Streaming audio data in the format specified",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 649
      },
      {
        "path": "async_client.pronunciation_dictionaries.create_from_file",
        "name": "create_from_file",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_access",
            "type": "Optional[PronunciationDictionariesCreateFromFileRequestWorkspaceAccess]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddPronunciationDictionaryResponseModel",
        "docstring": "Creates a new pronunciation dictionary from a lexicon .PLS file\n\nParameters\n----------\nname : str\n    The name of the pronunciation dictionary, used for identification only.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\ndescription : typing.Optional[str]\n    A description of the pronunciation dictionary, used for identification only.\n\nworkspace_access : typing.Optional[PronunciationDictionariesCreateFromFileRequestWorkspaceAccess]\n    Should be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddPronunciationDictionaryResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.pronunciation_dictionaries.create_from_file(\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 370
      },
      {
        "path": "async_client.pronunciation_dictionaries.create_from_rules",
        "name": "create_from_rules",
        "parameters": [
          {
            "name": "rules",
            "type": "Sequence[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_access",
            "type": "Optional[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostWorkspaceAccess]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddPronunciationDictionaryResponseModel",
        "docstring": "Creates a new pronunciation dictionary from provided rules.\n\nParameters\n----------\nrules : typing.Sequence[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem]\n    List of pronunciation rules. Rule can be either:\n        an alias rule: {'string_to_replace': 'a', 'type': 'alias', 'alias': 'b', }\n        or a phoneme rule: {'string_to_replace': 'a', 'type': 'phoneme', 'phoneme': 'b', 'alphabet': 'ipa' }\n\nname : str\n    The name of the pronunciation dictionary, used for identification only.\n\ndescription : typing.Optional[str]\n    A description of the pronunciation dictionary, used for identification only.\n\nworkspace_access : typing.Optional[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostWorkspaceAccess]\n    Should be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddPronunciationDictionaryResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\nfrom elevenlabs.pronunciation_dictionaries import (\n    BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem_Alias,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.pronunciation_dictionaries.create_from_rules(\n        rules=[\n            BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem_Alias(\n                string_to_replace=\"Thailand\",\n                alias=\"tie-land\",\n            )\n        ],\n        name=\"My Dictionary\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 432
      },
      {
        "path": "async_client.pronunciation_dictionaries.download",
        "name": "download",
        "parameters": [
          {
            "name": "dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "version_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator[bytes]",
        "docstring": "Get a PLS file with a pronunciation dictionary version rules\n\nParameters\n----------\ndictionary_id : str\n    The id of the pronunciation dictionary\n\nversion_id : str\n    The id of the pronunciation dictionary version\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The PLS file containing pronunciation dictionary rules\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.pronunciation_dictionaries.download(\n        dictionary_id=\"dictionary_id\",\n        version_id=\"version_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 602
      },
      {
        "path": "async_client.pronunciation_dictionaries.get",
        "name": "get",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetPronunciationDictionaryMetadataResponse",
        "docstring": "Get metadata for a pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetPronunciationDictionaryMetadataResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.pronunciation_dictionaries.get(\n        pronunciation_dictionary_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 507
      },
      {
        "path": "async_client.pronunciation_dictionaries.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[PronunciationDictionariesListRequestSort]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetPronunciationDictionariesMetadataResponseModel",
        "docstring": "Get a list of the pronunciation dictionaries you have access to and their metadata\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many pronunciation dictionaries to return at maximum. Can not exceed 100, defaults to 30.\n\nsort : typing.Optional[PronunciationDictionariesListRequestSort]\n    Which field to sort by, one of 'created_at_unix' or 'name'.\n\nsort_direction : typing.Optional[str]\n    Which direction to sort the voices in. 'ascending' or 'descending'.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetPronunciationDictionariesMetadataResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.pronunciation_dictionaries.list(\n        cursor=\"cursor\",\n        page_size=1,\n        sort=\"creation_time_unix\",\n        sort_direction=\"sort_direction\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 648
      },
      {
        "path": "async_client.pronunciation_dictionaries.rules.add",
        "name": "add",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rules",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PronunciationDictionaryRulesResponseModel",
        "docstring": "Add rules to the pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrules : typing.Sequence[PronunciationDictionaryRule]\n    List of pronunciation rules. Rule can be either:\n        an alias rule: {'string_to_replace': 'a', 'type': 'alias', 'alias': 'b', }\n        or a phoneme rule: {'string_to_replace': 'a', 'type': 'phoneme', 'phoneme': 'b', 'alphabet': 'ipa' }\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPronunciationDictionaryRulesResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\nfrom elevenlabs.pronunciation_dictionaries.rules import (\n    PronunciationDictionaryRule_Alias,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.pronunciation_dictionaries.rules.add(\n        pronunciation_dictionary_id=\"21m00Tcm4TlvDq8ikWAM\",\n        rules=[\n            PronunciationDictionaryRule_Alias(\n                string_to_replace=\"Thailand\",\n                alias=\"tie-land\",\n            )\n        ],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/rules/client.py",
        "source_line": 140
      },
      {
        "path": "async_client.pronunciation_dictionaries.rules.remove",
        "name": "remove",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rule_strings",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PronunciationDictionaryRulesResponseModel",
        "docstring": "Remove rules from the pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrule_strings : typing.Sequence[str]\n    List of strings to remove from the pronunciation dictionary.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPronunciationDictionaryRulesResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.pronunciation_dictionaries.rules.remove(\n        pronunciation_dictionary_id=\"21m00Tcm4TlvDq8ikWAM\",\n        rule_strings=[\"rule_strings\"],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/rules/client.py",
        "source_line": 201
      },
      {
        "path": "async_client.pronunciation_dictionaries.rules.with_raw_response.add",
        "name": "add",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rules",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Add rules to the pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrules : typing.Sequence[PronunciationDictionaryRule]\n    List of pronunciation rules. Rule can be either:\n        an alias rule: {'string_to_replace': 'a', 'type': 'alias', 'alias': 'b', }\n        or a phoneme rule: {'string_to_replace': 'a', 'type': 'phoneme', 'phoneme': 'b', 'alphabet': 'ipa' }\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PronunciationDictionaryRulesResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/rules/raw_client.py",
        "source_line": 163
      },
      {
        "path": "async_client.pronunciation_dictionaries.rules.with_raw_response.remove",
        "name": "remove",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "rule_strings",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Remove rules from the pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrule_strings : typing.Sequence[str]\n    List of strings to remove from the pronunciation dictionary.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PronunciationDictionaryRulesResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/rules/raw_client.py",
        "source_line": 231
      },
      {
        "path": "async_client.pronunciation_dictionaries.update",
        "name": "update",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "archived",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetPronunciationDictionaryMetadataResponse",
        "docstring": "Partially update the pronunciation dictionary without changing the version\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\narchived : typing.Optional[bool]\n    The name of the pronunciation dictionary, used for identification only.\n\nname : typing.Optional[str]\n    The name of the pronunciation dictionary, used for identification only.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetPronunciationDictionaryMetadataResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.pronunciation_dictionaries.update(\n        pronunciation_dictionary_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/client.py",
        "source_line": 548
      },
      {
        "path": "async_client.pronunciation_dictionaries.with_raw_response.create_from_file",
        "name": "create_from_file",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_access",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Creates a new pronunciation dictionary from a lexicon .PLS file\n\nParameters\n----------\nname : str\n    The name of the pronunciation dictionary, used for identification only.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\ndescription : typing.Optional[str]\n    A description of the pronunciation dictionary, used for identification only.\n\nworkspace_access : typing.Optional[PronunciationDictionariesCreateFromFileRequestWorkspaceAccess]\n    Should be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddPronunciationDictionaryResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 453
      },
      {
        "path": "async_client.pronunciation_dictionaries.with_raw_response.create_from_rules",
        "name": "create_from_rules",
        "parameters": [
          {
            "name": "rules",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_access",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Creates a new pronunciation dictionary from provided rules.\n\nParameters\n----------\nrules : typing.Sequence[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostRulesItem]\n    List of pronunciation rules. Rule can be either:\n        an alias rule: {'string_to_replace': 'a', 'type': 'alias', 'alias': 'b', }\n        or a phoneme rule: {'string_to_replace': 'a', 'type': 'phoneme', 'phoneme': 'b', 'alphabet': 'ipa' }\n\nname : str\n    The name of the pronunciation dictionary, used for identification only.\n\ndescription : typing.Optional[str]\n    A description of the pronunciation dictionary, used for identification only.\n\nworkspace_access : typing.Optional[BodyAddAPronunciationDictionaryV1PronunciationDictionariesAddFromRulesPostWorkspaceAccess]\n    Should be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddPronunciationDictionaryResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 528
      },
      {
        "path": "async_client.pronunciation_dictionaries.with_raw_response.download",
        "name": "download",
        "parameters": [
          {
            "name": "dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "version_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Get a PLS file with a pronunciation dictionary version rules\n\nParameters\n----------\ndictionary_id : str\n    The id of the pronunciation dictionary\n\nversion_id : str\n    The id of the pronunciation dictionary version\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The PLS file containing pronunciation dictionary rules",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 732
      },
      {
        "path": "async_client.pronunciation_dictionaries.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get metadata for a pronunciation dictionary\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetPronunciationDictionaryMetadataResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 613
      },
      {
        "path": "async_client.pronunciation_dictionaries.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "cursor",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get a list of the pronunciation dictionaries you have access to and their metadata\n\nParameters\n----------\ncursor : typing.Optional[str]\n    Used for fetching next page. Cursor is returned in the response.\n\npage_size : typing.Optional[int]\n    How many pronunciation dictionaries to return at maximum. Can not exceed 100, defaults to 30.\n\nsort : typing.Optional[PronunciationDictionariesListRequestSort]\n    Which field to sort by, one of 'created_at_unix' or 'name'.\n\nsort_direction : typing.Optional[str]\n    Which direction to sort the voices in. 'ascending' or 'descending'.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetPronunciationDictionariesMetadataResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 790
      },
      {
        "path": "async_client.pronunciation_dictionaries.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "pronunciation_dictionary_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "archived",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Partially update the pronunciation dictionary without changing the version\n\nParameters\n----------\npronunciation_dictionary_id : str\n    The id of the pronunciation dictionary\n\narchived : typing.Optional[bool]\n    The name of the pronunciation dictionary, used for identification only.\n\nname : typing.Optional[str]\n    The name of the pronunciation dictionary, used for identification only.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetPronunciationDictionaryMetadataResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/pronunciation_dictionaries/raw_client.py",
        "source_line": 663
      },
      {
        "path": "async_client.samples.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteSampleResponse",
        "docstring": "Removes a sample by its ID.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nsample_id : str\n    ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteSampleResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.samples.delete(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/samples/client.py",
        "source_line": 79
      },
      {
        "path": "async_client.samples.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Removes a sample by its ID.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nsample_id : str\n    ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteSampleResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/samples/raw_client.py",
        "source_line": 79
      },
      {
        "path": "async_client.save_a_voice_preview",
        "name": "save_a_voice_preview",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "None",
        "docstring": "Add a generated voice to the voice library.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.save_a_voice_preview()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/base_client.py",
        "source_line": 462
      },
      {
        "path": "async_client.service_accounts.api_keys.create",
        "name": "create",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "permissions",
            "type": "Union[List[Union[Literal, Any]], Literal]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "character_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceCreateApiKeyResponseModel",
        "docstring": "Create a new API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\nname : str\n\npermissions : BodyCreateServiceAccountApiKeyV1ServiceAccountsServiceAccountUserIdApiKeysPostPermissions\n    The permissions of the XI API.\n\ncharacter_limit : typing.Optional[int]\n    The character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceCreateApiKeyResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.service_accounts.api_keys.create(\n        service_account_user_id=\"service_account_user_id\",\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/client.py",
        "source_line": 277
      },
      {
        "path": "async_client.service_accounts.api_keys.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "api_key_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete an existing API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\napi_key_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.service_accounts.api_keys.delete(\n        service_account_user_id=\"service_account_user_id\",\n        api_key_id=\"api_key_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/client.py",
        "source_line": 338
      },
      {
        "path": "async_client.service_accounts.api_keys.list",
        "name": "list",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceApiKeyListResponseModel",
        "docstring": "Get all API keys for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceApiKeyListResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.service_accounts.api_keys.list(\n        service_account_user_id=\"service_account_user_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/client.py",
        "source_line": 237
      },
      {
        "path": "async_client.service_accounts.api_keys.update",
        "name": "update",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "api_key_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "is_enabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "permissions",
            "type": "Union[List[Union[Literal, Any]], Literal]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "character_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Update an existing API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\napi_key_id : str\n\nis_enabled : bool\n    Whether to enable or disable the API key.\n\nname : str\n    The name of the XI API key to use (used for identification purposes only).\n\npermissions : BodyEditServiceAccountApiKeyV1ServiceAccountsServiceAccountUserIdApiKeysApiKeyIdPatchPermissions\n    The permissions of the XI API.\n\ncharacter_limit : typing.Optional[int]\n    The character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.service_accounts.api_keys.update(\n        service_account_user_id=\"service_account_user_id\",\n        api_key_id=\"api_key_id\",\n        is_enabled=True,\n        name=\"Sneaky Fox\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/client.py",
        "source_line": 381
      },
      {
        "path": "async_client.service_accounts.api_keys.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "permissions",
            "type": "Union[List[Union[Literal, Any]], Literal]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "character_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a new API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\nname : str\n\npermissions : BodyCreateServiceAccountApiKeyV1ServiceAccountsServiceAccountUserIdApiKeysPostPermissions\n    The permissions of the XI API.\n\ncharacter_limit : typing.Optional[int]\n    The character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[WorkspaceCreateApiKeyResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/raw_client.py",
        "source_line": 351
      },
      {
        "path": "async_client.service_accounts.api_keys.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "api_key_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete an existing API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\napi_key_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/raw_client.py",
        "source_line": 427
      },
      {
        "path": "async_client.service_accounts.api_keys.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get all API keys for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[WorkspaceApiKeyListResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/raw_client.py",
        "source_line": 302
      },
      {
        "path": "async_client.service_accounts.api_keys.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "service_account_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "api_key_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "is_enabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "permissions",
            "type": "Union[List[Union[Literal, Any]], Literal]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "character_limit",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update an existing API key for a service account\n\nParameters\n----------\nservice_account_user_id : str\n\napi_key_id : str\n\nis_enabled : bool\n    Whether to enable or disable the API key.\n\nname : str\n    The name of the XI API key to use (used for identification purposes only).\n\npermissions : BodyEditServiceAccountApiKeyV1ServiceAccountsServiceAccountUserIdApiKeysApiKeyIdPatchPermissions\n    The permissions of the XI API.\n\ncharacter_limit : typing.Optional[int]\n    The character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/api_keys/raw_client.py",
        "source_line": 480
      },
      {
        "path": "async_client.service_accounts.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceServiceAccountListResponseModel",
        "docstring": "List all service accounts in the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceServiceAccountListResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.service_accounts.list()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/client.py",
        "source_line": 87
      },
      {
        "path": "async_client.service_accounts.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "List all service accounts in the workspace\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[WorkspaceServiceAccountListResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/service_accounts/raw_client.py",
        "source_line": 72
      },
      {
        "path": "async_client.speech_to_speech.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Transform audio from one voice to another. Maintain full control over emotion, timing and delivery.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\naudio : core.File\n    See core.File for more documentation\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[SpeechToSpeechConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\n\nvoice_settings : typing.Optional[str]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nremove_background_noise : typing.Optional[bool]\n    If set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\n\nfile_format : typing.Optional[SpeechToSpeechConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The generated audio file\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.speech_to_speech.convert(\n        voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n        output_format=\"mp3_44100_128\",\n        model_id=\"eleven_multilingual_sts_v2\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_speech/client.py",
        "source_line": 235
      },
      {
        "path": "async_client.speech_to_speech.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream audio from one voice to another. Maintain full control over emotion, timing and delivery.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\naudio : core.File\n    See core.File for more documentation\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[SpeechToSpeechStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\n\nvoice_settings : typing.Optional[str]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nremove_background_noise : typing.Optional[bool]\n    If set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\n\nfile_format : typing.Optional[SpeechToSpeechStreamRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.speech_to_speech.stream(\n        voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n        output_format=\"mp3_44100_128\",\n        model_id=\"eleven_multilingual_sts_v2\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_speech/client.py",
        "source_line": 337
      },
      {
        "path": "async_client.speech_to_speech.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Transform audio from one voice to another. Maintain full control over emotion, timing and delivery.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\naudio : core.File\n    See core.File for more documentation\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[SpeechToSpeechConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\n\nvoice_settings : typing.Optional[str]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nremove_background_noise : typing.Optional[bool]\n    If set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\n\nfile_format : typing.Optional[SpeechToSpeechConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The generated audio file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 268
      },
      {
        "path": "async_client.speech_to_speech.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "audio",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream audio from one voice to another. Maintain full control over emotion, timing and delivery.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\naudio : core.File\n    See core.File for more documentation\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[SpeechToSpeechStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\n\nvoice_settings : typing.Optional[str]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nremove_background_noise : typing.Optional[bool]\n    If set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\n\nfile_format : typing.Optional[SpeechToSpeechStreamRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 386
      },
      {
        "path": "async_client.speech_to_text.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "model_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tag_audio_events",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "num_speakers",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "timestamps_granularity",
            "type": "Optional[SpeechToTextConvertRequestTimestampsGranularity]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "diarize",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "diarization_threshold",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "additional_formats",
            "type": "Optional[AdditionalFormats]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Optional[SpeechToTextConvertRequestFileFormat]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cloud_storage_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "temperature",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_multi_channel",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook_metadata",
            "type": "Optional[SpeechToTextConvertRequestWebhookMetadata]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeechToTextConvertResponse",
        "docstring": "Transcribe an audio or video file. If webhook is set to true, the request will be processed asynchronously and results sent to configured webhooks. When use_multi_channel is true and the provided audio has multiple channels, a 'transcripts' object with separate transcripts for each channel is returned. Otherwise, returns a single transcript. The optional webhook_metadata parameter allows you to attach custom data that will be included in webhook responses for request correlation and tracking.\n\nParameters\n----------\nmodel_id : str\n    The ID of the model to use for transcription, currently only 'scribe_v1' and 'scribe_v1_experimental' are available.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean log and transcript storage features are unavailable for this request. Zero retention mode may only be used by enterprise customers.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nlanguage_code : typing.Optional[str]\n    An ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file. Can sometimes improve transcription performance if known beforehand. Defaults to null, in this case the language is predicted automatically.\n\ntag_audio_events : typing.Optional[bool]\n    Whether to tag audio events like (laughter), (footsteps), etc. in the transcription.\n\nnum_speakers : typing.Optional[int]\n    The maximum amount of speakers talking in the uploaded file. Can help with predicting who speaks when. The maximum amount of speakers that can be predicted is 32. Defaults to null, in this case the amount of speakers is set to the maximum value the model supports.\n\ntimestamps_granularity : typing.Optional[SpeechToTextConvertRequestTimestampsGranularity]\n    The granularity of the timestamps in the transcription. 'word' provides word-level timestamps and 'character' provides character-level timestamps per word.\n\ndiarize : typing.Optional[bool]\n    Whether to annotate which speaker is currently talking in the uploaded file.\n\ndiarization_threshold : typing.Optional[float]\n    Diarization threshold to apply during speaker diarization. A higher value means there will be a lower chance of one speaker being diarized as two different speakers but also a higher chance of two different speakers being diarized as one speaker (less total speakers predicted). A low value means there will be a higher chance of one speaker being diarized as two different speakers but also a lower chance of two different speakers being diarized as one speaker (more total speakers predicted). Can only be set when diarize=True and num_speakers=None. Defaults to None, in which case we will choose a threshold based on the model_id (0.22 usually).\n\nadditional_formats : typing.Optional[AdditionalFormats]\n    A list of additional formats to export the transcript to.\n\nfile_format : typing.Optional[SpeechToTextConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\ncloud_storage_url : typing.Optional[str]\n    The HTTPS URL of the file to transcribe. Exactly one of the file or cloud_storage_url parameters must be provided. The file must be accessible via HTTPS and the file size must be less than 2GB. Any valid HTTPS URL is accepted, including URLs from cloud storage providers (AWS S3, Google Cloud Storage, Cloudflare R2, etc.), CDNs, or any other HTTPS source. URLs can be pre-signed or include authentication tokens in query parameters.\n\nwebhook : typing.Optional[bool]\n    Whether to send the transcription result to configured speech-to-text webhooks.  If set the request will return early without the transcription, which will be delivered later via webhook.\n\nwebhook_id : typing.Optional[str]\n    Optional specific webhook ID to send the transcription result to. Only valid when webhook is set to true. If not provided, transcription will be sent to all configured speech-to-text webhooks.\n\ntemperature : typing.Optional[float]\n    Controls the randomness of the transcription output. Accepts values between 0.0 and 2.0, where higher values result in more diverse and less deterministic results. If omitted, we will use a temperature based on the model you selected which is usually 0.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be an integer between 0 and 2147483647.\n\nuse_multi_channel : typing.Optional[bool]\n    Whether the audio file contains multiple channels where each channel contains a single speaker. When enabled, each channel will be transcribed independently and the results will be combined. Each word in the response will include a 'channel_index' field indicating which channel it was spoken on. A maximum of 5 channels is supported.\n\nwebhook_metadata : typing.Optional[SpeechToTextConvertRequestWebhookMetadata]\n    Optional metadata to be included in the webhook response. This should be a JSON string representing an object with a maximum depth of 2 levels and maximum size of 16KB. Useful for tracking internal IDs, job references, or other contextual information.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeechToTextConvertResponse\n    Synchronous transcription result\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.speech_to_text.convert(\n        enable_logging=True,\n        model_id=\"model_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/client.py",
        "source_line": 191
      },
      {
        "path": "async_client.speech_to_text.transcripts.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "transcription_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Delete a previously generated transcript by its ID.\n\nParameters\n----------\ntranscription_id : str\n    The unique ID of the transcript to delete\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Delete completed successfully.\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.speech_to_text.transcripts.delete(\n        transcription_id=\"transcription_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/transcripts/client.py",
        "source_line": 147
      },
      {
        "path": "async_client.speech_to_text.transcripts.get",
        "name": "get",
        "parameters": [
          {
            "name": "transcription_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Union[SpeechToTextChunkResponseModel, MultichannelSpeechToTextResponseModel]",
        "docstring": "Retrieve a previously generated transcript by its ID.\n\nParameters\n----------\ntranscription_id : str\n    The unique ID of the transcript to retrieve\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nTranscriptsGetResponse\n    The transcript data\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.speech_to_text.transcripts.get(\n        transcription_id=\"transcription_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/transcripts/client.py",
        "source_line": 106
      },
      {
        "path": "async_client.speech_to_text.transcripts.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "transcription_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete a previously generated transcript by its ID.\n\nParameters\n----------\ntranscription_id : str\n    The unique ID of the transcript to delete\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Delete completed successfully.",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/transcripts/raw_client.py",
        "source_line": 235
      },
      {
        "path": "async_client.speech_to_text.transcripts.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "transcription_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve a previously generated transcript by its ID.\n\nParameters\n----------\ntranscription_id : str\n    The unique ID of the transcript to retrieve\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[TranscriptsGetResponse]\n    The transcript data",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/transcripts/raw_client.py",
        "source_line": 163
      },
      {
        "path": "async_client.speech_to_text.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "model_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "tag_audio_events",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "num_speakers",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "timestamps_granularity",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "diarize",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "diarization_threshold",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "additional_formats",
            "type": "Optional[List[Annotated]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "cloud_storage_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "temperature",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_multi_channel",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "webhook_metadata",
            "type": "Union[str, Dict[str, Any], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Transcribe an audio or video file. If webhook is set to true, the request will be processed asynchronously and results sent to configured webhooks. When use_multi_channel is true and the provided audio has multiple channels, a 'transcripts' object with separate transcripts for each channel is returned. Otherwise, returns a single transcript. The optional webhook_metadata parameter allows you to attach custom data that will be included in webhook responses for request correlation and tracking.\n\nParameters\n----------\nmodel_id : str\n    The ID of the model to use for transcription, currently only 'scribe_v1' and 'scribe_v1_experimental' are available.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean log and transcript storage features are unavailable for this request. Zero retention mode may only be used by enterprise customers.\n\nfile : typing.Optional[core.File]\n    See core.File for more documentation\n\nlanguage_code : typing.Optional[str]\n    An ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file. Can sometimes improve transcription performance if known beforehand. Defaults to null, in this case the language is predicted automatically.\n\ntag_audio_events : typing.Optional[bool]\n    Whether to tag audio events like (laughter), (footsteps), etc. in the transcription.\n\nnum_speakers : typing.Optional[int]\n    The maximum amount of speakers talking in the uploaded file. Can help with predicting who speaks when. The maximum amount of speakers that can be predicted is 32. Defaults to null, in this case the amount of speakers is set to the maximum value the model supports.\n\ntimestamps_granularity : typing.Optional[SpeechToTextConvertRequestTimestampsGranularity]\n    The granularity of the timestamps in the transcription. 'word' provides word-level timestamps and 'character' provides character-level timestamps per word.\n\ndiarize : typing.Optional[bool]\n    Whether to annotate which speaker is currently talking in the uploaded file.\n\ndiarization_threshold : typing.Optional[float]\n    Diarization threshold to apply during speaker diarization. A higher value means there will be a lower chance of one speaker being diarized as two different speakers but also a higher chance of two different speakers being diarized as one speaker (less total speakers predicted). A low value means there will be a higher chance of one speaker being diarized as two different speakers but also a lower chance of two different speakers being diarized as one speaker (more total speakers predicted). Can only be set when diarize=True and num_speakers=None. Defaults to None, in which case we will choose a threshold based on the model_id (0.22 usually).\n\nadditional_formats : typing.Optional[AdditionalFormats]\n    A list of additional formats to export the transcript to.\n\nfile_format : typing.Optional[SpeechToTextConvertRequestFileFormat]\n    The format of input audio. Options are 'pcm_s16le_16' or 'other' For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\n\ncloud_storage_url : typing.Optional[str]\n    The HTTPS URL of the file to transcribe. Exactly one of the file or cloud_storage_url parameters must be provided. The file must be accessible via HTTPS and the file size must be less than 2GB. Any valid HTTPS URL is accepted, including URLs from cloud storage providers (AWS S3, Google Cloud Storage, Cloudflare R2, etc.), CDNs, or any other HTTPS source. URLs can be pre-signed or include authentication tokens in query parameters.\n\nwebhook : typing.Optional[bool]\n    Whether to send the transcription result to configured speech-to-text webhooks.  If set the request will return early without the transcription, which will be delivered later via webhook.\n\nwebhook_id : typing.Optional[str]\n    Optional specific webhook ID to send the transcription result to. Only valid when webhook is set to true. If not provided, transcription will be sent to all configured speech-to-text webhooks.\n\ntemperature : typing.Optional[float]\n    Controls the randomness of the transcription output. Accepts values between 0.0 and 2.0, where higher values result in more diverse and less deterministic results. If omitted, we will use a temperature based on the model you selected which is usually 0.\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be an integer between 0 and 2147483647.\n\nuse_multi_channel : typing.Optional[bool]\n    Whether the audio file contains multiple channels where each channel contains a single speaker. When enabled, each channel will be transcribed independently and the results will be combined. Each word in the response will include a 'channel_index' field indicating which channel it was spoken on. A maximum of 5 channels is supported.\n\nwebhook_metadata : typing.Optional[SpeechToTextConvertRequestWebhookMetadata]\n    Optional metadata to be included in the webhook response. This should be a JSON string representing an object with a maximum depth of 2 levels and maximum size of 16KB. Useful for tracking internal IDs, job references, or other contextual information.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SpeechToTextConvertResponse]\n    Synchronous transcription result",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/speech_to_text/raw_client.py",
        "source_line": 186
      },
      {
        "path": "async_client.studio.create_podcast",
        "name": "create_podcast",
        "parameters": [
          {
            "name": "model_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mode",
            "type": "BodyCreatePodcastV1StudioPodcastsPostMode",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source",
            "type": "BodyCreatePodcastV1StudioPodcastsPostSource",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "safety_identifier",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality_preset",
            "type": "Optional[BodyCreatePodcastV1StudioPodcastsPostQualityPreset]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "duration_scale",
            "type": "Optional[BodyCreatePodcastV1StudioPodcastsPostDurationScale]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "intro",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "outro",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "instructions_prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "highlights",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "callback_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Optional[BodyCreatePodcastV1StudioPodcastsPostApplyTextNormalization]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PodcastProjectResponseModel",
        "docstring": "Create and auto-convert a podcast project. Currently, the LLM cost is covered by us but you will still be charged for the audio generation. In the future, you will be charged for both the LLM and audio generation costs.\n\nParameters\n----------\nmodel_id : str\n    The ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\n\nmode : BodyCreatePodcastV1StudioPodcastsPostMode\n    The type of podcast to generate. Can be 'conversation', an interaction between two voices, or 'bulletin', a monologue.\n\nsource : BodyCreatePodcastV1StudioPodcastsPostSource\n    The source content for the Podcast.\n\nsafety_identifier : typing.Optional[str]\n    Used for moderation. Your workspace must be allowlisted to use this feature.\n\nquality_preset : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostQualityPreset]\n    Output quality of the generated audio. Must be one of:\n    standard - standard output format, 128kbps with 44.1kHz sample rate.\n    high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. Using this setting increases the credit cost by 20%.\n    ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. Using this setting increases the credit cost by 50%.\n    ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format. Using this setting increases the credit cost by 100%.\n\nduration_scale : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostDurationScale]\n    Duration of the generated podcast. Must be one of:\n    short - produces podcasts shorter than 3 minutes.\n    default - produces podcasts roughly between 3-7 minutes.\n    long - produces podcasts longer than 7 minutes.\n\nlanguage : typing.Optional[str]\n    An optional language of the Studio project. Two-letter language code (ISO 639-1).\n\nintro : typing.Optional[str]\n    The intro text that will always be added to the beginning of the podcast.\n\noutro : typing.Optional[str]\n    The outro text that will always be added to the end of the podcast.\n\ninstructions_prompt : typing.Optional[str]\n    Additional instructions prompt for the podcast generation used to adjust the podcast's style and tone.\n\nhighlights : typing.Optional[typing.Sequence[str]]\n    A brief summary or highlights of the Studio project's content, providing key points or themes. This should be between 10 and 70 characters.\n\ncallback_url : typing.Optional[str]\n\n        A url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion\n        Messages:\n        1. When project was converted successfully:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"success\",\n            project_snapshot_id: \"22m00Tcm4TlvDq8ikMAT\",\n            error_details: None,\n          }\n        }\n        2. When project conversion failed:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"error\",\n            project_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n        3. When chapter was converted successfully:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"success\",\n            chapter_snapshot_id: \"23m00Tcm4TlvDq8ikMAV\",\n            error_details: None,\n          }\n        }\n        4. When chapter conversion failed:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"error\",\n            chapter_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n\napply_text_normalization : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPodcastProjectResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import (\n    AsyncElevenLabs,\n    PodcastConversationModeData,\n    PodcastTextSource,\n)\nfrom elevenlabs.studio import (\n    BodyCreatePodcastV1StudioPodcastsPostMode_Conversation,\n)\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.create_podcast(\n        safety_identifier=\"safety-identifier\",\n        model_id=\"eleven_multilingual_v2\",\n        mode=BodyCreatePodcastV1StudioPodcastsPostMode_Conversation(\n            conversation=PodcastConversationModeData(\n                host_voice_id=\"aw1NgEzBg83R7vgmiJt6\",\n                guest_voice_id=\"aw1NgEzBg83R7vgmiJt7\",\n            ),\n        ),\n        source=PodcastTextSource(\n            text=\"This is a test podcast.\",\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/client.py",
        "source_line": 254
      },
      {
        "path": "async_client.studio.projects.chapters.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ConvertChapterResponseModel",
        "docstring": "Starts conversion of a specific chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nConvertChapterResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.convert(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 550
      },
      {
        "path": "async_client.studio.projects.chapters.create",
        "name": "create",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddChapterResponseModel",
        "docstring": "Creates a new chapter either as blank or from a URL.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nname : str\n    The name of the chapter, used for identification only.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddChapterResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.create(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        name=\"Chapter 1\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 346
      },
      {
        "path": "async_client.studio.projects.chapters.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteChapterResponseModel",
        "docstring": "Deletes a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteChapterResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.delete(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 505
      },
      {
        "path": "async_client.studio.projects.chapters.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ChapterWithContentResponseModel",
        "docstring": "Returns information about a specific chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nChapterWithContentResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.get(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 401
      },
      {
        "path": "async_client.studio.projects.chapters.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetChaptersResponse",
        "docstring": "Returns a list of a Studio project's chapters.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetChaptersResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.list(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 305
      },
      {
        "path": "async_client.studio.projects.chapters.snapshots.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ChapterSnapshotExtendedResponseModel",
        "docstring": "Returns the chapter snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nchapter_id : str\n    The ID of the chapter.\n\nchapter_snapshot_id : str\n    The ID of the chapter snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nChapterSnapshotExtendedResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.snapshots.get(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n        chapter_snapshot_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/client.py",
        "source_line": 230
      },
      {
        "path": "async_client.studio.projects.chapters.snapshots.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ChapterSnapshotsResponse",
        "docstring": "Gets information about all the snapshots of a chapter. Each snapshot can be downloaded as audio. Whenever a chapter is converted a snapshot will automatically be created.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nChapterSnapshotsResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.snapshots.list(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/client.py",
        "source_line": 185
      },
      {
        "path": "async_client.studio.projects.chapters.snapshots.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "convert_to_mpeg",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream the audio from a chapter snapshot. Use `GET /v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots` to return the snapshots of a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nchapter_snapshot_id : str\n    The ID of the chapter snapshot to be used. You can use the [List project chapter snapshots](/docs/api-reference/studio/get-snapshots) endpoint to list all the available snapshots.\n\nconvert_to_mpeg : typing.Optional[bool]\n    Whether to convert the audio to mpeg format.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.snapshots.stream(\n        project_id=\"project_id\",\n        chapter_id=\"chapter_id\",\n        chapter_snapshot_id=\"chapter_snapshot_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/client.py",
        "source_line": 286
      },
      {
        "path": "async_client.studio.projects.chapters.snapshots.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns the chapter snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nchapter_id : str\n    The ID of the chapter.\n\nchapter_snapshot_id : str\n    The ID of the chapter snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ChapterSnapshotExtendedResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/raw_client.py",
        "source_line": 274
      },
      {
        "path": "async_client.studio.projects.chapters.snapshots.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets information about all the snapshots of a chapter. Each snapshot can be downloaded as audio. Whenever a chapter is converted a snapshot will automatically be created.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ChapterSnapshotsResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/snapshots/raw_client.py",
        "source_line": 221
      },
      {
        "path": "async_client.studio.projects.chapters.snapshots.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "convert_to_mpeg",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream the audio from a chapter snapshot. Use `GET /v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots` to return the snapshots of a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nchapter_snapshot_id : str\n    The ID of the chapter snapshot to be used. You can use the [List project chapter snapshots](/docs/api-reference/studio/get-snapshots) endpoint to list all the available snapshots.\n\nconvert_to_mpeg : typing.Optional[bool]\n    Whether to convert the audio to mpeg format.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 335
      },
      {
        "path": "async_client.studio.projects.chapters.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "content",
            "type": "Optional[ChapterContentInputModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditChapterResponseModel",
        "docstring": "Updates a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nname : typing.Optional[str]\n    The name of the chapter, used for identification only.\n\ncontent : typing.Optional[ChapterContentInputModel]\n    The chapter content to use.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditChapterResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.chapters.update(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        chapter_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/client.py",
        "source_line": 446
      },
      {
        "path": "async_client.studio.projects.chapters.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Starts conversion of a specific chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ConvertChapterResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 689
      },
      {
        "path": "async_client.studio.projects.chapters.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Creates a new chapter either as blank or from a URL.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nname : str\n    The name of the chapter, used for identification only.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddChapterResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 439
      },
      {
        "path": "async_client.studio.projects.chapters.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Deletes a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteChapterResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 636
      },
      {
        "path": "async_client.studio.projects.chapters.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns information about a specific chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ChapterWithContentResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 508
      },
      {
        "path": "async_client.studio.projects.chapters.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns a list of a Studio project's chapters.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetChaptersResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 389
      },
      {
        "path": "async_client.studio.projects.chapters.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "chapter_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "content",
            "type": "Optional[ChapterContentInputModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Updates a chapter.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nchapter_id : str\n    The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n\nname : typing.Optional[str]\n    The name of the chapter, used for identification only.\n\ncontent : typing.Optional[ChapterContentInputModel]\n    The chapter content to use.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[EditChapterResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/chapters/raw_client.py",
        "source_line": 561
      },
      {
        "path": "async_client.studio.projects.content.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_document",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_content_json",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditProjectResponseModel",
        "docstring": "Updates Studio project content.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nfrom_document : typing.Optional[core.File]\n    See core.File for more documentation\n\nfrom_content_json : typing.Optional[str]\n\n        An optional content to initialize the Studio project with. If this is set, 'from_url' and 'from_document' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\n        Example:\n        [{\"name\": \"Chapter A\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"A\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"B\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h1\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"C\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"D\", \"type\": \"tts_node\"}]}]}, {\"name\": \"Chapter B\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"E\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"F\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h2\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"G\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"H\", \"type\": \"tts_node\"}]}]}]\n\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the Studio project to audio or not.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditProjectResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.content.update(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/content/client.py",
        "source_line": 110
      },
      {
        "path": "async_client.studio.projects.content.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_document",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_content_json",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Updates Studio project content.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nfrom_document : typing.Optional[core.File]\n    See core.File for more documentation\n\nfrom_content_json : typing.Optional[str]\n\n        An optional content to initialize the Studio project with. If this is set, 'from_url' and 'from_document' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\n        Example:\n        [{\"name\": \"Chapter A\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"A\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"B\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h1\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"C\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"D\", \"type\": \"tts_node\"}]}]}, {\"name\": \"Chapter B\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"E\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"F\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h2\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"G\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"H\", \"type\": \"tts_node\"}]}]}]\n\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the Studio project to audio or not.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[EditProjectResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/content/raw_client.py",
        "source_line": 114
      },
      {
        "path": "async_client.studio.projects.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ConvertProjectResponseModel",
        "docstring": "Starts conversion of a Studio project and all of its chapters.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nConvertProjectResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.convert(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 1023
      },
      {
        "path": "async_client.studio.projects.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_title_voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_paragraph_voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_document",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_content_json",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality_preset",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "genres",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_audience",
            "type": "Optional[ProjectsCreateRequestTargetAudience]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "content_type",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "original_publication_date",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mature_content",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "isbn_number",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "acx_volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "callback_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "fiction",
            "type": "Optional[ProjectsCreateRequestFiction]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Optional[ProjectsCreateRequestApplyTextNormalization]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_assign_voices",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_type",
            "type": "Optional[ProjectsCreateRequestSourceType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddProjectResponseModel",
        "docstring": "Creates a new Studio project, it can be either initialized as blank, from a document or from a URL.\n\nParameters\n----------\nname : str\n    The name of the Studio project, used for identification only.\n\ndefault_title_voice_id : typing.Optional[str]\n    The voice_id that corresponds to the default voice used for new titles.\n\ndefault_paragraph_voice_id : typing.Optional[str]\n    The voice_id that corresponds to the default voice used for new paragraphs.\n\ndefault_model_id : typing.Optional[str]\n    The ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nfrom_document : typing.Optional[core.File]\n    See core.File for more documentation\n\nfrom_content_json : typing.Optional[str]\n\n        An optional content to initialize the Studio project with. If this is set, 'from_url' and 'from_document' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\n        Example:\n        [{\"name\": \"Chapter A\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"A\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"B\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h1\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"C\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"D\", \"type\": \"tts_node\"}]}]}, {\"name\": \"Chapter B\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"E\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"F\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h2\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"G\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"H\", \"type\": \"tts_node\"}]}]}]\n\n\nquality_preset : typing.Optional[str]\n    Output quality of the generated audio. Must be one of:\n    standard - standard output format, 128kbps with 44.1kHz sample rate.\n    high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. Using this setting increases the credit cost by 20%.\n    ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. Using this setting increases the credit cost by 50%.\n    ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format. Using this setting increases the credit cost by 100%.\n\ntitle : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nauthor : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\ndescription : typing.Optional[str]\n    An optional description of the Studio project.\n\ngenres : typing.Optional[typing.List[str]]\n    An optional list of genres associated with the Studio project.\n\ntarget_audience : typing.Optional[ProjectsCreateRequestTargetAudience]\n    An optional target audience of the Studio project.\n\nlanguage : typing.Optional[str]\n    An optional language of the Studio project. Two-letter language code (ISO 639-1).\n\ncontent_type : typing.Optional[str]\n    An optional content type of the Studio project.\n\noriginal_publication_date : typing.Optional[str]\n    An optional original publication date of the Studio project, in the format YYYY-MM-DD or YYYY.\n\nmature_content : typing.Optional[bool]\n    An optional specification of whether this Studio project contains mature content.\n\nisbn_number : typing.Optional[str]\n    An optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nacx_volume_normalization : typing.Optional[bool]\n    [Deprecated] When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\nvolume_normalization : typing.Optional[bool]\n    When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\npronunciation_dictionary_locators : typing.Optional[typing.List[str]]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\ncallback_url : typing.Optional[str]\n\n        A url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion\n        Messages:\n        1. When project was converted successfully:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"success\",\n            project_snapshot_id: \"22m00Tcm4TlvDq8ikMAT\",\n            error_details: None,\n          }\n        }\n        2. When project conversion failed:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"error\",\n            project_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n        3. When chapter was converted successfully:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"success\",\n            chapter_snapshot_id: \"23m00Tcm4TlvDq8ikMAV\",\n            error_details: None,\n          }\n        }\n        4. When chapter conversion failed:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"error\",\n            chapter_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n\nfiction : typing.Optional[ProjectsCreateRequestFiction]\n    An optional specification of whether the content of this Studio project is fiction.\n\napply_text_normalization : typing.Optional[ProjectsCreateRequestApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the Studio project to audio or not.\n\nauto_assign_voices : typing.Optional[bool]\n    [Alpha Feature] Whether automatically assign voices to phrases in the create Project.\n\nsource_type : typing.Optional[ProjectsCreateRequestSourceType]\n    The type of Studio project to create.\n\nvoice_settings : typing.Optional[typing.List[str]]\n        Optional voice settings overrides for the project, encoded as a list of JSON strings.\n\n        Example:\n        [\"{\\\"voice_id\\\": \\\"21m00Tcm4TlvDq8ikWAM\\\", \\\"stability\\\": 0.7, \\\"similarity_boost\\\": 0.8, \\\"style\\\": 0.5, \\\"speed\\\": 1.0, \\\"use_speaker_boost\\\": true}\"]\n\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddProjectResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.create(\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 594
      },
      {
        "path": "async_client.studio.projects.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteProjectResponseModel",
        "docstring": "Deletes a Studio project.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteProjectResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.delete(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 982
      },
      {
        "path": "async_client.studio.projects.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "share_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ProjectExtendedResponse",
        "docstring": "Returns information about a specific Studio project. This endpoint returns more detailed information about a project than `GET /v1/studio`.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nshare_id : typing.Optional[str]\n    The share ID of the project\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nProjectExtendedResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.get(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        share_id=\"share_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 848
      },
      {
        "path": "async_client.studio.projects.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetProjectsResponse",
        "docstring": "Returns a list of your Studio projects with metadata.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetProjectsResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.list()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 560
      },
      {
        "path": "async_client.studio.projects.pronunciation_dictionaries.create",
        "name": "create",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "invalidate_affected_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "CreatePronunciationDictionaryResponseModel",
        "docstring": "Create a set of pronunciation dictionaries acting on a project. This will automatically mark text within this project as requiring reconverting where the new dictionary would apply or the old one no longer does.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\npronunciation_dictionary_locators : typing.Sequence[PronunciationDictionaryVersionLocator]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\ninvalidate_affected_text : typing.Optional[bool]\n    This will automatically mark text in this project for reconversion when the new dictionary applies or the old one no longer does.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nCreatePronunciationDictionaryResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, PronunciationDictionaryVersionLocator\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.pronunciation_dictionaries.create(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        pronunciation_dictionary_locators=[\n            PronunciationDictionaryVersionLocator(\n                pronunciation_dictionary_id=\"pronunciation_dictionary_id\",\n            )\n        ],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/pronunciation_dictionaries/client.py",
        "source_line": 100
      },
      {
        "path": "async_client.studio.projects.pronunciation_dictionaries.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "invalidate_affected_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a set of pronunciation dictionaries acting on a project. This will automatically mark text within this project as requiring reconverting where the new dictionary would apply or the old one no longer does.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\npronunciation_dictionary_locators : typing.Sequence[PronunciationDictionaryVersionLocator]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\ninvalidate_affected_text : typing.Optional[bool]\n    This will automatically mark text in this project for reconversion when the new dictionary applies or the old one no longer does.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[CreatePronunciationDictionaryResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/pronunciation_dictionaries/raw_client.py",
        "source_line": 104
      },
      {
        "path": "async_client.studio.projects.snapshots.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ProjectSnapshotExtendedResponseModel",
        "docstring": "Returns the project snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nProjectSnapshotExtendedResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.snapshots.get(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        project_snapshot_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/client.py",
        "source_line": 241
      },
      {
        "path": "async_client.studio.projects.snapshots.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ProjectSnapshotsResponse",
        "docstring": "Retrieves a list of snapshots for a Studio project.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nProjectSnapshotsResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.snapshots.list(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/client.py",
        "source_line": 200
      },
      {
        "path": "async_client.studio.projects.snapshots.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "convert_to_mpeg",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream the audio from a Studio project snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nconvert_to_mpeg : typing.Optional[bool]\n    Whether to convert the audio to mpeg format.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.snapshots.stream(\n        project_id=\"project_id\",\n        project_snapshot_id=\"project_snapshot_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/client.py",
        "source_line": 286
      },
      {
        "path": "async_client.studio.projects.snapshots.stream_archive",
        "name": "stream_archive",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Returns a compressed archive of the Studio project's audio.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Streaming archive data\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.snapshots.stream_archive(\n        project_id=\"project_id\",\n        project_snapshot_id=\"project_snapshot_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/client.py",
        "source_line": 342
      },
      {
        "path": "async_client.studio.projects.snapshots.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns the project snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ProjectSnapshotExtendedResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/raw_client.py",
        "source_line": 313
      },
      {
        "path": "async_client.studio.projects.snapshots.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieves a list of snapshots for a Studio project.\n\nParameters\n----------\nproject_id : str\n    The ID of the Studio project.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ProjectSnapshotsResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/snapshots/raw_client.py",
        "source_line": 263
      },
      {
        "path": "async_client.studio.projects.snapshots.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "convert_to_mpeg",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream the audio from a Studio project snapshot.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nconvert_to_mpeg : typing.Optional[bool]\n    Whether to convert the audio to mpeg format.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 366
      },
      {
        "path": "async_client.studio.projects.snapshots.with_raw_response.stream_archive",
        "name": "stream_archive",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "project_snapshot_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Returns a compressed archive of the Studio project's audio.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nproject_snapshot_id : str\n    The ID of the Studio project snapshot.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Streaming archive data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 439
      },
      {
        "path": "async_client.studio.projects.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_title_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_paragraph_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "isbn_number",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditProjectResponseModel",
        "docstring": "Updates the specified Studio project by setting the values of the parameters passed.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nname : str\n    The name of the Studio project, used for identification only.\n\ndefault_title_voice_id : str\n    The voice_id that corresponds to the default voice used for new titles.\n\ndefault_paragraph_voice_id : str\n    The voice_id that corresponds to the default voice used for new paragraphs.\n\ntitle : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nauthor : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nisbn_number : typing.Optional[str]\n    An optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nvolume_normalization : typing.Optional[bool]\n    When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditProjectResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.studio.projects.update(\n        project_id=\"21m00Tcm4TlvDq8ikWAM\",\n        name=\"Project 1\",\n        default_title_voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        default_paragraph_voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/client.py",
        "source_line": 897
      },
      {
        "path": "async_client.studio.projects.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Starts conversion of a Studio project and all of its chapters.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ConvertProjectResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 1123
      },
      {
        "path": "async_client.studio.projects.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_title_voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_paragraph_voice_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_document",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "from_content_json",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality_preset",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "genres",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "target_audience",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "content_type",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "original_publication_date",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mature_content",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "isbn_number",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "acx_volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "callback_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "fiction",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_convert",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_assign_voices",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[List[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Creates a new Studio project, it can be either initialized as blank, from a document or from a URL.\n\nParameters\n----------\nname : str\n    The name of the Studio project, used for identification only.\n\ndefault_title_voice_id : typing.Optional[str]\n    The voice_id that corresponds to the default voice used for new titles.\n\ndefault_paragraph_voice_id : typing.Optional[str]\n    The voice_id that corresponds to the default voice used for new paragraphs.\n\ndefault_model_id : typing.Optional[str]\n    The ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\n\nfrom_url : typing.Optional[str]\n    An optional URL from which we will extract content to initialize the Studio project. If this is set, 'from_url' and 'from_content' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\nfrom_document : typing.Optional[core.File]\n    See core.File for more documentation\n\nfrom_content_json : typing.Optional[str]\n\n        An optional content to initialize the Studio project with. If this is set, 'from_url' and 'from_document' must be null. If neither 'from_url', 'from_document', 'from_content' are provided we will initialize the Studio project as blank.\n\n        Example:\n        [{\"name\": \"Chapter A\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"A\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"B\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h1\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"C\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"D\", \"type\": \"tts_node\"}]}]}, {\"name\": \"Chapter B\", \"blocks\": [{\"sub_type\": \"p\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"E\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"F\", \"type\": \"tts_node\"}]}, {\"sub_type\": \"h2\", \"nodes\": [{\"voice_id\": \"6lCwbsX1yVjD49QmpkT0\", \"text\": \"G\", \"type\": \"tts_node\"}, {\"voice_id\": \"6lCwbsX1yVjD49QmpkT1\", \"text\": \"H\", \"type\": \"tts_node\"}]}]}]\n\n\nquality_preset : typing.Optional[str]\n    Output quality of the generated audio. Must be one of:\n    standard - standard output format, 128kbps with 44.1kHz sample rate.\n    high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. Using this setting increases the credit cost by 20%.\n    ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. Using this setting increases the credit cost by 50%.\n    ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format. Using this setting increases the credit cost by 100%.\n\ntitle : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nauthor : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\ndescription : typing.Optional[str]\n    An optional description of the Studio project.\n\ngenres : typing.Optional[typing.List[str]]\n    An optional list of genres associated with the Studio project.\n\ntarget_audience : typing.Optional[ProjectsCreateRequestTargetAudience]\n    An optional target audience of the Studio project.\n\nlanguage : typing.Optional[str]\n    An optional language of the Studio project. Two-letter language code (ISO 639-1).\n\ncontent_type : typing.Optional[str]\n    An optional content type of the Studio project.\n\noriginal_publication_date : typing.Optional[str]\n    An optional original publication date of the Studio project, in the format YYYY-MM-DD or YYYY.\n\nmature_content : typing.Optional[bool]\n    An optional specification of whether this Studio project contains mature content.\n\nisbn_number : typing.Optional[str]\n    An optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nacx_volume_normalization : typing.Optional[bool]\n    [Deprecated] When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\nvolume_normalization : typing.Optional[bool]\n    When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\npronunciation_dictionary_locators : typing.Optional[typing.List[str]]\n    A list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple --form lines in your curl, such as --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"Vmd4Zor6fplcA7WrINey\\\",\\\"version_id\\\":\\\"hRPaxjlTdR7wFMhV4w0b\\\"}\"' --form 'pronunciation_dictionary_locators=\"{\\\"pronunciation_dictionary_id\\\":\\\"JzWtcGQMJ6bnlWwyMo7e\\\",\\\"version_id\\\":\\\"lbmwxiLu4q6txYxgdZqn\\\"}\"'.\n\ncallback_url : typing.Optional[str]\n\n        A url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion\n        Messages:\n        1. When project was converted successfully:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"success\",\n            project_snapshot_id: \"22m00Tcm4TlvDq8ikMAT\",\n            error_details: None,\n          }\n        }\n        2. When project conversion failed:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"error\",\n            project_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n        3. When chapter was converted successfully:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"success\",\n            chapter_snapshot_id: \"23m00Tcm4TlvDq8ikMAV\",\n            error_details: None,\n          }\n        }\n        4. When chapter conversion failed:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"error\",\n            chapter_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n\nfiction : typing.Optional[ProjectsCreateRequestFiction]\n    An optional specification of whether the content of this Studio project is fiction.\n\napply_text_normalization : typing.Optional[ProjectsCreateRequestApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\nauto_convert : typing.Optional[bool]\n    Whether to auto convert the Studio project to audio or not.\n\nauto_assign_voices : typing.Optional[bool]\n    [Alpha Feature] Whether automatically assign voices to phrases in the create Project.\n\nsource_type : typing.Optional[ProjectsCreateRequestSourceType]\n    The type of Studio project to create.\n\nvoice_settings : typing.Optional[typing.List[str]]\n        Optional voice settings overrides for the project, encoded as a list of JSON strings.\n\n        Example:\n        [\"{\\\"voice_id\\\": \\\"21m00Tcm4TlvDq8ikWAM\\\", \\\"stability\\\": 0.7, \\\"similarity_boost\\\": 0.8, \\\"style\\\": 0.5, \\\"speed\\\": 1.0, \\\"use_speaker_boost\\\": true}\"]\n\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddProjectResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 652
      },
      {
        "path": "async_client.studio.projects.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Deletes a Studio project.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteProjectResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 1073
      },
      {
        "path": "async_client.studio.projects.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "share_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns information about a specific Studio project. This endpoint returns more detailed information about a project than `GET /v1/studio`.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nshare_id : typing.Optional[str]\n    The share ID of the project\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ProjectExtendedResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 919
      },
      {
        "path": "async_client.studio.projects.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns a list of your Studio projects with metadata.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetProjectsResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 605
      },
      {
        "path": "async_client.studio.projects.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "project_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_title_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "default_paragraph_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "title",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "author",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "isbn_number",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "volume_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Updates the specified Studio project by setting the values of the parameters passed.\n\nParameters\n----------\nproject_id : str\n    The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n\nname : str\n    The name of the Studio project, used for identification only.\n\ndefault_title_voice_id : str\n    The voice_id that corresponds to the default voice used for new titles.\n\ndefault_paragraph_voice_id : str\n    The voice_id that corresponds to the default voice used for new paragraphs.\n\ntitle : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nauthor : typing.Optional[str]\n    An optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nisbn_number : typing.Optional[str]\n    An optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\n\nvolume_normalization : typing.Optional[bool]\n    When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[EditProjectResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/projects/raw_client.py",
        "source_line": 979
      },
      {
        "path": "async_client.studio.with_raw_response.create_podcast",
        "name": "create_podcast",
        "parameters": [
          {
            "name": "model_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "mode",
            "type": "Annotated",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "source",
            "type": "Union[PodcastTextSource, PodcastUrlSource, List[Annotated]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "safety_identifier",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality_preset",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "duration_scale",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "intro",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "outro",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "instructions_prompt",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "highlights",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "callback_url",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create and auto-convert a podcast project. Currently, the LLM cost is covered by us but you will still be charged for the audio generation. In the future, you will be charged for both the LLM and audio generation costs.\n\nParameters\n----------\nmodel_id : str\n    The ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\n\nmode : BodyCreatePodcastV1StudioPodcastsPostMode\n    The type of podcast to generate. Can be 'conversation', an interaction between two voices, or 'bulletin', a monologue.\n\nsource : BodyCreatePodcastV1StudioPodcastsPostSource\n    The source content for the Podcast.\n\nsafety_identifier : typing.Optional[str]\n    Used for moderation. Your workspace must be allowlisted to use this feature.\n\nquality_preset : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostQualityPreset]\n    Output quality of the generated audio. Must be one of:\n    standard - standard output format, 128kbps with 44.1kHz sample rate.\n    high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. Using this setting increases the credit cost by 20%.\n    ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. Using this setting increases the credit cost by 50%.\n    ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format. Using this setting increases the credit cost by 100%.\n\nduration_scale : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostDurationScale]\n    Duration of the generated podcast. Must be one of:\n    short - produces podcasts shorter than 3 minutes.\n    default - produces podcasts roughly between 3-7 minutes.\n    long - produces podcasts longer than 7 minutes.\n\nlanguage : typing.Optional[str]\n    An optional language of the Studio project. Two-letter language code (ISO 639-1).\n\nintro : typing.Optional[str]\n    The intro text that will always be added to the beginning of the podcast.\n\noutro : typing.Optional[str]\n    The outro text that will always be added to the end of the podcast.\n\ninstructions_prompt : typing.Optional[str]\n    Additional instructions prompt for the podcast generation used to adjust the podcast's style and tone.\n\nhighlights : typing.Optional[typing.Sequence[str]]\n    A brief summary or highlights of the Studio project's content, providing key points or themes. This should be between 10 and 70 characters.\n\ncallback_url : typing.Optional[str]\n\n        A url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion\n        Messages:\n        1. When project was converted successfully:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"success\",\n            project_snapshot_id: \"22m00Tcm4TlvDq8ikMAT\",\n            error_details: None,\n          }\n        }\n        2. When project conversion failed:\n        {\n          type: \"project_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            conversion_status: \"error\",\n            project_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n        3. When chapter was converted successfully:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"success\",\n            chapter_snapshot_id: \"23m00Tcm4TlvDq8ikMAV\",\n            error_details: None,\n          }\n        }\n        4. When chapter conversion failed:\n        {\n          type: \"chapter_conversion_status\",\n          event_timestamp: 1234567890,\n          data: {\n            request_id: \"1234567890\",\n            project_id: \"21m00Tcm4TlvDq8ikWAM\",\n            chapter_id: \"22m00Tcm4TlvDq8ikMAT\",\n            conversion_status: \"error\",\n            chapter_snapshot_id: None,\n            error_details: \"Error details if conversion failed\"\n          }\n        }\n\n\napply_text_normalization : typing.Optional[BodyCreatePodcastV1StudioPodcastsPostApplyTextNormalization]\n\n        This parameter controls text normalization with four modes: 'auto', 'on', 'apply_english' and 'off'.\n        When set to 'auto', the system will automatically decide whether to apply text normalization\n        (e.g., spelling out numbers). With 'on', text normalization will always be applied, while\n        with 'off', it will be skipped. 'apply_english' is the same as 'on' but will assume that text is in English.\n\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PodcastProjectResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/studio/raw_client.py",
        "source_line": 230
      },
      {
        "path": "async_client.text_to_dialogue.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns audio.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueMultiVoiceV1TextToDialoguePostApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The generated audio file\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, DialogueInput\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_dialogue.convert(\n        inputs=[\n            DialogueInput(\n                text=\"Knock knock\",\n                voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n            ),\n            DialogueInput(\n                text=\"Who is there?\",\n                voice_id=\"Aw4FAjKCGjjNkVhN1Xmq\",\n            ),\n        ],\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/client.py",
        "source_line": 421
      },
      {
        "path": "async_client.text_to_dialogue.convert_with_timestamps",
        "name": "convert_with_timestamps",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AudioWithTimestampsAndVoiceSegmentsResponseModel",
        "docstring": "Generate dialogue from text with precise character-level timing information for audio-text synchronization.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueConvertWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueFullWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAudioWithTimestampsAndVoiceSegmentsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, DialogueInput\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_dialogue.convert_with_timestamps(\n        output_format=\"mp3_22050_32\",\n        inputs=[\n            DialogueInput(\n                text=\"Hello, how are you?\",\n                voice_id=\"bYTqZQo3Jz7LQtmGTgwi\",\n            ),\n            DialogueInput(\n                text=\"I'm doing well, thank you!\",\n                voice_id=\"6lCwbsX1yVjD49QmpkTR\",\n            ),\n        ],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/client.py",
        "source_line": 710
      },
      {
        "path": "async_client.text_to_dialogue.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns an audio stream.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueMultiVoiceStreamingV1TextToDialogueStreamPostApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, DialogueInput\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_dialogue.stream(\n        inputs=[\n            DialogueInput(\n                text=\"Knock knock\",\n                voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n            ),\n            DialogueInput(\n                text=\"Who is there?\",\n                voice_id=\"Aw4FAjKCGjjNkVhN1Xmq\",\n            ),\n        ],\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/client.py",
        "source_line": 517
      },
      {
        "path": "async_client.text_to_dialogue.stream_with_timestamps",
        "name": "stream_with_timestamps",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns a stream of JSON blobs containing audio as a base64 encoded string and timestamps\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueStreamWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueStreamWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nYields\n------\ntyping.AsyncIterator[StreamingAudioChunkWithTimestampsAndVoiceSegmentsResponseModel]\n    Stream of transcription chunks\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, DialogueInput\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    response = await client.text_to_dialogue.stream_with_timestamps(\n        output_format=\"mp3_22050_32\",\n        inputs=[\n            DialogueInput(\n                text=\"Hello, how are you?\",\n                voice_id=\"bYTqZQo3Jz7LQtmGTgwi\",\n            ),\n            DialogueInput(\n                text=\"I'm doing well, thank you!\",\n                voice_id=\"6lCwbsX1yVjD49QmpkTR\",\n            ),\n        ],\n    )\n    async for chunk in response:\n        yield chunk\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/client.py",
        "source_line": 613
      },
      {
        "path": "async_client.text_to_dialogue.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns audio.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueMultiVoiceV1TextToDialoguePostApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The generated audio file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 519
      },
      {
        "path": "async_client.text_to_dialogue.with_raw_response.convert_with_timestamps",
        "name": "convert_with_timestamps",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Generate dialogue from text with precise character-level timing information for audio-text synchronization.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueConvertWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueFullWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AudioWithTimestampsAndVoiceSegmentsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_dialogue/raw_client.py",
        "source_line": 876
      },
      {
        "path": "async_client.text_to_dialogue.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns an audio stream.\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueMultiVoiceStreamingV1TextToDialogueStreamPostApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 633
      },
      {
        "path": "async_client.text_to_dialogue.with_raw_response.stream_with_timestamps",
        "name": "stream_with_timestamps",
        "parameters": [
          {
            "name": "inputs",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "settings",
            "type": "Optional[ModelSettingsResponseModel]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts a list of text and voice ID pairs into speech (dialogue) and returns a stream of JSON blobs containing audio as a base64 encoded string and timestamps\n\nParameters\n----------\ninputs : typing.Sequence[DialogueInput]\n    A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\n\noutput_format : typing.Optional[TextToDialogueStreamWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nsettings : typing.Optional[ModelSettingsResponseModel]\n    Settings controlling the dialogue generation.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\napply_text_normalization : typing.Optional[BodyTextToDialogueStreamWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nYields\n------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[StreamingAudioChunkWithTimestampsAndVoiceSegmentsResponseModel]]]\n    Stream of transcription chunks",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 747
      },
      {
        "path": "async_client.text_to_sound_effects.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loop",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "duration_seconds",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_influence",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Turn text into sound effects for your videos, voice-overs or video games using the most advanced sound effects models in the world.\n\nParameters\n----------\ntext : str\n    The text that will get converted into a sound effect.\n\noutput_format : typing.Optional[TextToSoundEffectsConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nloop : typing.Optional[bool]\n    Whether to create a sound effect that loops smoothly. Only available for the 'eleven_text_to_sound_v2 model'.\n\nduration_seconds : typing.Optional[float]\n    The duration of the sound which will be generated in seconds. Must be at least 0.5 and at most 30. If set to None we will guess the optimal duration using the prompt. Defaults to None.\n\nprompt_influence : typing.Optional[float]\n    A higher prompt influence makes your generation follow the prompt more closely while also making generations less variable. Must be a value between 0 and 1. Defaults to 0.3.\n\nmodel_id : typing.Optional[str]\n    The model ID to use for the sound generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The generated sound effect as an MP3 file\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_sound_effects.convert(\n        text=\"Spacious braam suitable for high-impact movie trailer moments\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_sound_effects/client.py",
        "source_line": 109
      },
      {
        "path": "async_client.text_to_sound_effects.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loop",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "duration_seconds",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_influence",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Turn text into sound effects for your videos, voice-overs or video games using the most advanced sound effects models in the world.\n\nParameters\n----------\ntext : str\n    The text that will get converted into a sound effect.\n\noutput_format : typing.Optional[TextToSoundEffectsConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nloop : typing.Optional[bool]\n    Whether to create a sound effect that loops smoothly. Only available for the 'eleven_text_to_sound_v2 model'.\n\nduration_seconds : typing.Optional[float]\n    The duration of the sound which will be generated in seconds. Must be at least 0.5 and at most 30. If set to None we will guess the optimal duration using the prompt. Defaults to None.\n\nprompt_influence : typing.Optional[float]\n    A higher prompt influence makes your generation follow the prompt more closely while also making generations less variable. Must be a value between 0 and 1. Defaults to 0.3.\n\nmodel_id : typing.Optional[str]\n    The model ID to use for the sound generation.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The generated sound effect as an MP3 file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 120
      },
      {
        "path": "async_client.text_to_speech.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechFullApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    The generated audio file\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_speech.convert(\n        voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n        output_format=\"mp3_44100_128\",\n        text=\"The first move is what sets everything in motion.\",\n        model_id=\"eleven_multilingual_v2\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/client.py",
        "source_line": 591
      },
      {
        "path": "async_client.text_to_speech.convert_with_timestamps",
        "name": "convert_with_timestamps",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AudioWithTimestampsResponse",
        "docstring": "Generate speech from text with precise character-level timing information for audio-text synchronization.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechConvertWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechFullWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAudioWithTimestampsResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_speech.convert_with_timestamps(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        enable_logging=True,\n        optimize_streaming_latency=1,\n        output_format=\"mp3_22050_32\",\n        text=\"This is a test for the API of ElevenLabs.\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/client.py",
        "source_line": 731
      },
      {
        "path": "async_client.text_to_speech.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio as an audio stream.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechStreamApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_speech.stream(\n        voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n        output_format=\"mp3_44100_128\",\n        text=\"The first move is what sets everything in motion.\",\n        model_id=\"eleven_multilingual_v2\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/client.py",
        "source_line": 871
      },
      {
        "path": "async_client.text_to_speech.stream_with_timestamps",
        "name": "stream_with_timestamps",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts text into speech using a voice of your choice and returns a stream of JSONs containing audio as a base64 encoded string together with information on when which character was spoken.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechStreamWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechStreamWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nYields\n------\ntyping.AsyncIterator[StreamingAudioChunkWithTimestampsResponse]\n    Stream of transcription chunks\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    response = await client.text_to_speech.stream_with_timestamps(\n        voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n        output_format=\"mp3_44100_128\",\n        text=\"The first move is what sets everything in motion.\",\n        model_id=\"eleven_multilingual_v2\",\n    )\n    async for chunk in response:\n        yield chunk\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/client.py",
        "source_line": 1011
      },
      {
        "path": "async_client.text_to_speech.with_raw_response.convert",
        "name": "convert",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechConvertRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechFullApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    The generated audio file",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 701
      },
      {
        "path": "async_client.text_to_speech.with_raw_response.convert_with_timestamps",
        "name": "convert_with_timestamps",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Generate speech from text with precise character-level timing information for audio-text synchronization.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechConvertWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechFullWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AudioWithTimestampsResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_speech/raw_client.py",
        "source_line": 862
      },
      {
        "path": "async_client.text_to_speech.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts text into speech using a voice of your choice and returns audio as an audio stream.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechStreamRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechStreamApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 1018
      },
      {
        "path": "async_client.text_to_speech.with_raw_response.stream_with_timestamps",
        "name": "stream_with_timestamps",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "text",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "enable_logging",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "optimize_streaming_latency",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language_code",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_settings",
            "type": "Optional[VoiceSettings]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "pronunciation_dictionary_locators",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "previous_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "next_request_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_pvc_as_ivc",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_text_normalization",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "apply_language_text_normalization",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Converts text into speech using a voice of your choice and returns a stream of JSONs containing audio as a base64 encoded string together with information on when which character was spoken.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\ntext : str\n    The text that will get converted into speech.\n\nenable_logging : typing.Optional[bool]\n    When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\n\noptimize_streaming_latency : typing.Optional[int]\n    You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:\n    0 - default mode (no latency optimizations)\n    1 - normal latency optimizations (about 50% of possible latency improvement of option 3)\n    2 - strong latency optimizations (about 75% of possible latency improvement of option 3)\n    3 - max latency optimizations\n    4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\n\n    Defaults to None.\n\noutput_format : typing.Optional[TextToSpeechStreamWithTimestampsRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[str]\n    Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\n\nlanguage_code : typing.Optional[str]\n    Language code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\n\nvoice_settings : typing.Optional[VoiceSettings]\n    Voice settings overriding stored settings for the given voice. They are applied only on the given request.\n\npronunciation_dictionary_locators : typing.Optional[typing.Sequence[PronunciationDictionaryVersionLocator]]\n    A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\n\nseed : typing.Optional[int]\n    If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\n\nprevious_text : typing.Optional[str]\n    The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nnext_text : typing.Optional[str]\n    The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\n\nprevious_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that were generated before this generation. Can be used to improve the speech's continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\n\nnext_request_ids : typing.Optional[typing.Sequence[str]]\n    A list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech's continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\n\nuse_pvc_as_ivc : typing.Optional[bool]\n    If true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n\napply_text_normalization : typing.Optional[BodyTextToSpeechStreamWithTimestampsApplyTextNormalization]\n    This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.\n\napply_language_text_normalization : typing.Optional[bool]\n    This parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nYields\n------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[StreamingAudioChunkWithTimestampsResponse]]]\n    Stream of transcription chunks",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 1179
      },
      {
        "path": "async_client.text_to_voice.create",
        "name": "create",
        "parameters": [
          {
            "name": "voice_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "generated_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "played_not_selected_voice_ids",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Voice",
        "docstring": "Create a voice from previously generated voice preview. This endpoint should be called after you fetched a generated_voice_id using POST /v1/text-to-voice/design or POST /v1/text-to-voice/:voice_id/remix.\n\nParameters\n----------\nvoice_name : str\n    Name to use for the created voice.\n\nvoice_description : str\n    Description to use for the created voice.\n\ngenerated_voice_id : str\n    The generated_voice_id to create, call POST /v1/text-to-voice/create-previews and fetch the generated_voice_id from the response header if don't have one yet.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Optional, metadata to add to the created voice. Defaults to None.\n\nplayed_not_selected_voice_ids : typing.Optional[typing.Sequence[str]]\n    List of voice ids that the user has played but not selected. Used for RLHF.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoice\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_voice.create(\n        voice_name=\"Sassy squeaky mouse\",\n        voice_description=\"A sassy squeaky mouse\",\n        generated_voice_id=\"37HceQefKmEi3bGovXjL\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/client.py",
        "source_line": 486
      },
      {
        "path": "async_client.text_to_voice.create_previews",
        "name": "create_previews",
        "parameters": [
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[TextToVoiceCreatePreviewsRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceDesignPreviewResponse",
        "docstring": "Create a voice from a text prompt.\n\nParameters\n----------\nvoice_description : str\n    Description to use for the created voice.\n\noutput_format : typing.Optional[TextToVoiceCreatePreviewsRequestOutputFormat]\n    The output format of the generated audio.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nquality : typing.Optional[float]\n    Higher quality results in better voice output but less variety.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceDesignPreviewResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_voice.create_previews(\n        output_format=\"mp3_22050_32\",\n        voice_description=\"A sassy squeaky mouse\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/client.py",
        "source_line": 403
      },
      {
        "path": "async_client.text_to_voice.design",
        "name": "design",
        "parameters": [
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[TextToVoiceDesignRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Optional[VoiceDesignRequestModelModelId]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stream_previews",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_iteration_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "reference_audio_base_64",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_strength",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceDesignPreviewResponse",
        "docstring": "Design a voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n\nParameters\n----------\nvoice_description : str\n    Description to use for the created voice.\n\noutput_format : typing.Optional[TextToVoiceDesignRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[VoiceDesignRequestModelModelId]\n    Model to use for the voice generation. Possible values: eleven_multilingual_ttv_v2, eleven_ttv_v3.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nstream_previews : typing.Optional[bool]\n    Determines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\n\nremixing_session_id : typing.Optional[str]\n    The remixing session id.\n\nremixing_session_iteration_id : typing.Optional[str]\n    The id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\n\nquality : typing.Optional[float]\n    Higher quality results in better voice output but less variety.\n\nreference_audio_base_64 : typing.Optional[str]\n    Reference audio to use for the voice generation. The audio should be base64 encoded. Only supported when using the  eleven_ttv_v3 model.\n\nprompt_strength : typing.Optional[float]\n    Controls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceDesignPreviewResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_voice.design(\n        output_format=\"mp3_22050_32\",\n        voice_description=\"A sassy squeaky mouse\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/client.py",
        "source_line": 555
      },
      {
        "path": "async_client.text_to_voice.preview.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "generated_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream a voice preview that was created via the /v1/text-to-voice/design endpoint.\n\nParameters\n----------\ngenerated_voice_id : str\n    The generated_voice_id to stream.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Streaming audio data\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_voice.preview.stream(\n        generated_voice_id=\"generated_voice_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/preview/client.py",
        "source_line": 74
      },
      {
        "path": "async_client.text_to_voice.preview.with_raw_response.stream",
        "name": "stream",
        "parameters": [
          {
            "name": "generated_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Stream a voice preview that was created via the /v1/text-to-voice/design endpoint.\n\nParameters\n----------\ngenerated_voice_id : str\n    The generated_voice_id to stream.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Streaming audio data",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 80
      },
      {
        "path": "async_client.text_to_voice.remix",
        "name": "remix",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Optional[TextToVoiceRemixRequestOutputFormat]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stream_previews",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_iteration_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_strength",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceDesignPreviewResponse",
        "docstring": "Remix an existing voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nvoice_description : str\n    Description of the changes to make to the voice.\n\noutput_format : typing.Optional[TextToVoiceRemixRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nstream_previews : typing.Optional[bool]\n    Determines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\n\nremixing_session_id : typing.Optional[str]\n    The remixing session id.\n\nremixing_session_iteration_id : typing.Optional[str]\n    The id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\n\nprompt_strength : typing.Optional[float]\n    Controls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceDesignPreviewResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.text_to_voice.remix(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        output_format=\"mp3_22050_32\",\n        voice_description=\"Make the voice have a higher pitch.\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/client.py",
        "source_line": 668
      },
      {
        "path": "async_client.text_to_voice.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "voice_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "generated_voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "played_not_selected_voice_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a voice from previously generated voice preview. This endpoint should be called after you fetched a generated_voice_id using POST /v1/text-to-voice/design or POST /v1/text-to-voice/:voice_id/remix.\n\nParameters\n----------\nvoice_name : str\n    Name to use for the created voice.\n\nvoice_description : str\n    Description to use for the created voice.\n\ngenerated_voice_id : str\n    The generated_voice_id to create, call POST /v1/text-to-voice/create-previews and fetch the generated_voice_id from the response header if don't have one yet.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Optional, metadata to add to the created voice. Defaults to None.\n\nplayed_not_selected_voice_ids : typing.Optional[typing.Sequence[str]]\n    List of voice ids that the user has played but not selected. Used for RLHF.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[Voice]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/raw_client.py",
        "source_line": 551
      },
      {
        "path": "async_client.text_to_voice.with_raw_response.create_previews",
        "name": "create_previews",
        "parameters": [
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a voice from a text prompt.\n\nParameters\n----------\nvoice_description : str\n    Description to use for the created voice.\n\noutput_format : typing.Optional[TextToVoiceCreatePreviewsRequestOutputFormat]\n    The output format of the generated audio.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nquality : typing.Optional[float]\n    Higher quality results in better voice output but less variety.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[VoiceDesignPreviewResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/raw_client.py",
        "source_line": 454
      },
      {
        "path": "async_client.text_to_voice.with_raw_response.design",
        "name": "design",
        "parameters": [
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "model_id",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stream_previews",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_iteration_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "quality",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "reference_audio_base_64",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_strength",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Design a voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n\nParameters\n----------\nvoice_description : str\n    Description to use for the created voice.\n\noutput_format : typing.Optional[TextToVoiceDesignRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\nmodel_id : typing.Optional[VoiceDesignRequestModelModelId]\n    Model to use for the voice generation. Possible values: eleven_multilingual_ttv_v2, eleven_ttv_v3.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nstream_previews : typing.Optional[bool]\n    Determines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\n\nremixing_session_id : typing.Optional[str]\n    The remixing session id.\n\nremixing_session_iteration_id : typing.Optional[str]\n    The id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\n\nquality : typing.Optional[float]\n    Higher quality results in better voice output but less variety.\n\nreference_audio_base_64 : typing.Optional[str]\n    Reference audio to use for the voice generation. The audio should be base64 encoded. Only supported when using the  eleven_ttv_v3 model.\n\nprompt_strength : typing.Optional[float]\n    Controls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[VoiceDesignPreviewResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/raw_client.py",
        "source_line": 631
      },
      {
        "path": "async_client.text_to_voice.with_raw_response.remix",
        "name": "remix",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "voice_description",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "output_format",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "auto_generate_text",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "loudness",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "seed",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "guidance_scale",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "stream_previews",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remixing_session_iteration_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "prompt_strength",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Remix an existing voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nvoice_description : str\n    Description of the changes to make to the voice.\n\noutput_format : typing.Optional[TextToVoiceRemixRequestOutputFormat]\n    Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the -law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\n\ntext : typing.Optional[str]\n    Text to generate, text length has to be between 100 and 1000.\n\nauto_generate_text : typing.Optional[bool]\n    Whether to automatically generate a text suitable for the voice description.\n\nloudness : typing.Optional[float]\n    Controls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\n\nseed : typing.Optional[int]\n    Random number that controls the voice generation. Same seed with same inputs produces same voice.\n\nguidance_scale : typing.Optional[float]\n    Controls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\n\nstream_previews : typing.Optional[bool]\n    Determines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\n\nremixing_session_id : typing.Optional[str]\n    The remixing session id.\n\nremixing_session_iteration_id : typing.Optional[str]\n    The id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\n\nprompt_strength : typing.Optional[float]\n    Controls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[VoiceDesignPreviewResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/text_to_voice/raw_client.py",
        "source_line": 758
      },
      {
        "path": "async_client.tokens.single_use.create",
        "name": "create",
        "parameters": [
          {
            "name": "token_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SingleUseTokenResponseModel",
        "docstring": "Generate a time limited single-use token with embedded authentication for frontend clients.\n\nParameters\n----------\ntoken_type : SingleUseTokenType\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSingleUseTokenResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.tokens.single_use.create(\n        token_type=\"realtime_scribe\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/tokens/single_use/client.py",
        "source_line": 75
      },
      {
        "path": "async_client.tokens.single_use.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "token_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Generate a time limited single-use token with embedded authentication for frontend clients.\n\nParameters\n----------\ntoken_type : SingleUseTokenType\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SingleUseTokenResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/tokens/single_use/raw_client.py",
        "source_line": 76
      },
      {
        "path": "async_client.usage.get",
        "name": "get",
        "parameters": [
          {
            "name": "start_unix",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_unix",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_workspace_metrics",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "breakdown_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "aggregation_interval",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "aggregation_bucket_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "metric",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "UsageCharactersResponseModel",
        "docstring": "Returns the usage metrics for the current user or the entire workspace they are part of. The response provides a time axis based on the specified aggregation interval (default: day), with usage values for each interval along that axis. Usage is broken down by the selected breakdown type. For example, breakdown type \"voice\" will return the usage of each voice for each interval along the time axis.\n\nParameters\n----------\nstart_unix : int\n    UTC Unix timestamp for the start of the usage window, in milliseconds. To include the first day of the window, the timestamp should be at 00:00:00 of that day.\n\nend_unix : int\n    UTC Unix timestamp for the end of the usage window, in milliseconds. To include the last day of the window, the timestamp should be at 23:59:59 of that day.\n\ninclude_workspace_metrics : typing.Optional[bool]\n    Whether or not to include the statistics of the entire workspace.\n\nbreakdown_type : typing.Optional[BreakdownTypes]\n    How to break down the information. Cannot be \"user\" if include_workspace_metrics is False.\n\naggregation_interval : typing.Optional[UsageAggregationInterval]\n    How to aggregate usage data over time. Can be \"hour\", \"day\", \"week\", \"month\", or \"cumulative\".\n\naggregation_bucket_size : typing.Optional[int]\n    Aggregation bucket size in seconds. Overrides the aggregation interval.\n\nmetric : typing.Optional[MetricType]\n    Which metric to aggregate.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nUsageCharactersResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.usage.get(\n        start_unix=1,\n        end_unix=1,\n        include_workspace_metrics=True,\n        breakdown_type=\"none\",\n        aggregation_interval=\"hour\",\n        aggregation_bucket_size=1,\n        metric=\"credits\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/usage/client.py",
        "source_line": 120
      },
      {
        "path": "async_client.usage.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "start_unix",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "end_unix",
            "type": "int",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_workspace_metrics",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "breakdown_type",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "aggregation_interval",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "aggregation_bucket_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "metric",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns the usage metrics for the current user or the entire workspace they are part of. The response provides a time axis based on the specified aggregation interval (default: day), with usage values for each interval along that axis. Usage is broken down by the selected breakdown type. For example, breakdown type \"voice\" will return the usage of each voice for each interval along the time axis.\n\nParameters\n----------\nstart_unix : int\n    UTC Unix timestamp for the start of the usage window, in milliseconds. To include the first day of the window, the timestamp should be at 00:00:00 of that day.\n\nend_unix : int\n    UTC Unix timestamp for the end of the usage window, in milliseconds. To include the last day of the window, the timestamp should be at 23:59:59 of that day.\n\ninclude_workspace_metrics : typing.Optional[bool]\n    Whether or not to include the statistics of the entire workspace.\n\nbreakdown_type : typing.Optional[BreakdownTypes]\n    How to break down the information. Cannot be \"user\" if include_workspace_metrics is False.\n\naggregation_interval : typing.Optional[UsageAggregationInterval]\n    How to aggregate usage data over time. Can be \"hour\", \"day\", \"week\", \"month\", or \"cumulative\".\n\naggregation_bucket_size : typing.Optional[int]\n    Aggregation bucket size in seconds. Overrides the aggregation interval.\n\nmetric : typing.Optional[MetricType]\n    Which metric to aggregate.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[UsageCharactersResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/usage/raw_client.py",
        "source_line": 114
      },
      {
        "path": "async_client.user.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "User",
        "docstring": "Gets information about the user\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nUser\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.user.get()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/user/client.py",
        "source_line": 85
      },
      {
        "path": "async_client.user.subscription.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Subscription",
        "docstring": "Gets extended information about the users subscription\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSubscription\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.user.subscription.get()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/user/subscription/client.py",
        "source_line": 68
      },
      {
        "path": "async_client.user.subscription.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets extended information about the users subscription\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[Subscription]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/user/subscription/raw_client.py",
        "source_line": 70
      },
      {
        "path": "async_client.user.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets information about the user\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[User]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/user/raw_client.py",
        "source_line": 70
      },
      {
        "path": "async_client.voices.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteVoiceResponseModel",
        "docstring": "Deletes a voice by its ID.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.delete(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 799
      },
      {
        "path": "async_client.voices.find_similar_voices",
        "name": "find_similar_voices",
        "parameters": [
          {
            "name": "audio_file",
            "type": "Optional[core.File]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "similarity_threshold",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "top_k",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetLibraryVoicesResponse",
        "docstring": "Returns a list of shared voices similar to the provided audio sample. If neither similarity_threshold nor top_k is provided, we will apply default values.\n\nParameters\n----------\naudio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nsimilarity_threshold : typing.Optional[float]\n    Threshold for voice similarity between provided sample and library voices. Values range from 0 to 2. The smaller the value the more similar voices will be returned.\n\ntop_k : typing.Optional[int]\n    Number of most similar voices to return. If similarity_threshold is provided, less than this number of voices may be returned. Values range from 1 to 100.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetLibraryVoicesResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.find_similar_voices()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 1115
      },
      {
        "path": "async_client.voices.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "with_settings",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Voice",
        "docstring": "Returns metadata about a specific voice.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nwith_settings : typing.Optional[bool]\n    This parameter is now deprecated. It is ignored and will be removed in a future version.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoice\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.get(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        with_settings=True,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 750
      },
      {
        "path": "async_client.voices.get_all",
        "name": "get_all",
        "parameters": [
          {
            "name": "show_legacy",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetVoicesResponse",
        "docstring": "Returns a list of all available voices for a user.\n\nParameters\n----------\nshow_legacy : typing.Optional[bool]\n    If set to true, legacy premade voices will be included in responses from /v1/voices\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetVoicesResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.get_all(\n        show_legacy=True,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 603
      },
      {
        "path": "async_client.voices.get_shared",
        "name": "get_shared",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "category",
            "type": "Optional[VoicesGetSharedRequestCategory]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "gender",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "age",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "accent",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "locale",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_cases",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "descriptives",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "featured",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "min_notice_period_days",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_custom_rates",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_live_moderated",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "reader_app_enabled",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "owner_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetLibraryVoicesResponse",
        "docstring": "Retrieves a list of shared voices.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many shared voices to return at maximum. Can not exceed 100, defaults to 30.\n\ncategory : typing.Optional[VoicesGetSharedRequestCategory]\n    Voice category used for filtering\n\ngender : typing.Optional[str]\n    Gender used for filtering\n\nage : typing.Optional[str]\n    Age used for filtering\n\naccent : typing.Optional[str]\n    Accent used for filtering\n\nlanguage : typing.Optional[str]\n    Language used for filtering\n\nlocale : typing.Optional[str]\n    Locale used for filtering\n\nsearch : typing.Optional[str]\n    Search term used for filtering\n\nuse_cases : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Use-case used for filtering\n\ndescriptives : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Search term used for filtering\n\nfeatured : typing.Optional[bool]\n    Filter featured voices\n\nmin_notice_period_days : typing.Optional[int]\n    Filter voices with a minimum notice period of the given number of days.\n\ninclude_custom_rates : typing.Optional[bool]\n    Include/exclude voices with custom rates\n\ninclude_live_moderated : typing.Optional[bool]\n    Include/exclude voices that are live moderated\n\nreader_app_enabled : typing.Optional[bool]\n    Filter voices that are enabled for the reader app\n\nowner_id : typing.Optional[str]\n    Filter voices by public owner ID\n\nsort : typing.Optional[str]\n    Sort criteria\n\npage : typing.Optional[int]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetLibraryVoicesResponse\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.get_shared(\n        page_size=1,\n        category=\"professional\",\n        gender=\"gender\",\n        age=\"age\",\n        accent=\"accent\",\n        language=\"language\",\n        locale=\"locale\",\n        search=\"search\",\n        featured=True,\n        min_notice_period_days=1,\n        include_custom_rates=True,\n        include_live_moderated=True,\n        reader_app_enabled=True,\n        owner_id=\"owner_id\",\n        sort=\"sort\",\n        page=1,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 969
      },
      {
        "path": "async_client.voices.ivc.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "files",
            "type": "List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceIvcResponseModel",
        "docstring": "Create a voice clone and add it to your Voices\n\nParameters\n----------\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\ndescription : typing.Optional[str]\n    A description of the voice.\n\nlabels : typing.Optional[str]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceIvcResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.ivc.create(\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/ivc/client.py",
        "source_line": 105
      },
      {
        "path": "async_client.voices.ivc.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "files",
            "type": "List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a voice clone and add it to your Voices\n\nParameters\n----------\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\ndescription : typing.Optional[str]\n    A description of the voice.\n\nlabels : typing.Optional[str]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddVoiceIvcResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/ivc/raw_client.py",
        "source_line": 109
      },
      {
        "path": "async_client.voices.pvc.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceResponseModel",
        "docstring": "Creates a new PVC voice with metadata but no samples\n\nParameters\n----------\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nlanguage : str\n    Language used in the samples.\n\ndescription : typing.Optional[str]\n    Description to use for the created voice.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.create(\n        name=\"John Smith\",\n        language=\"en\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/client.py",
        "source_line": 223
      },
      {
        "path": "async_client.voices.pvc.samples.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceSamplePreviewResponseModel",
        "docstring": "Retrieve the first 30 seconds of voice sample audio with or without noise removal.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceSamplePreviewResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.samples.audio.get(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n        remove_background_noise=True,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/audio/client.py",
        "source_line": 90
      },
      {
        "path": "async_client.voices.pvc.samples.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve the first 30 seconds of voice sample audio with or without noise removal.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[VoiceSamplePreviewResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/audio/raw_client.py",
        "source_line": 90
      },
      {
        "path": "async_client.voices.pvc.samples.create",
        "name": "create",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "files",
            "type": "List[core.File]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "List[VoiceSample]",
        "docstring": "Add audio samples to a PVC voice\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.List[VoiceSample]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.samples.create(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/client.py",
        "source_line": 239
      },
      {
        "path": "async_client.voices.pvc.samples.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteVoiceSampleResponseModel",
        "docstring": "Delete a sample from a PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteVoiceSampleResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.samples.delete(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/client.py",
        "source_line": 371
      },
      {
        "path": "async_client.voices.pvc.samples.speakers.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeakerAudioResponseModel",
        "docstring": "Retrieve the separated audio for a specific speaker.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nspeaker_id : str\n    Speaker ID to be used, you can use GET https://api.elevenlabs.io/v1/voices/{voice_id}/samples/{sample_id}/speakers to list all the available speakers for a sample.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeakerAudioResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.samples.speakers.audio.get(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n        speaker_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/audio/client.py",
        "source_line": 83
      },
      {
        "path": "async_client.voices.pvc.samples.speakers.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "speaker_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve the separated audio for a specific speaker.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nspeaker_id : str\n    Speaker ID to be used, you can use GET https://api.elevenlabs.io/v1/voices/{voice_id}/samples/{sample_id}/speakers to list all the available speakers for a sample.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SpeakerAudioResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/audio/raw_client.py",
        "source_line": 82
      },
      {
        "path": "async_client.voices.pvc.samples.speakers.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "SpeakerSeparationResponseModel",
        "docstring": "Retrieve the status of the speaker separation process and the list of detected speakers if complete.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nSpeakerSeparationResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.samples.speakers.get(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/client.py",
        "source_line": 134
      },
      {
        "path": "async_client.voices.pvc.samples.speakers.separate",
        "name": "separate",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "StartSpeakerSeparationResponseModel",
        "docstring": "Start speaker separation process for a sample\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nStartSpeakerSeparationResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.samples.speakers.separate(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/client.py",
        "source_line": 179
      },
      {
        "path": "async_client.voices.pvc.samples.speakers.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve the status of the speaker separation process and the list of detected speakers if complete.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[SpeakerSeparationResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/raw_client.py",
        "source_line": 133
      },
      {
        "path": "async_client.voices.pvc.samples.speakers.with_raw_response.separate",
        "name": "separate",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Start speaker separation process for a sample\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[StartSpeakerSeparationResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/speakers/raw_client.py",
        "source_line": 186
      },
      {
        "path": "async_client.voices.pvc.samples.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "selected_speaker_ids",
            "type": "Optional[Sequence[str]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "trim_start_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "trim_end_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceResponseModel",
        "docstring": "Update a PVC voice sample - apply noise removal, select speaker, change trim times or file name.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nselected_speaker_ids : typing.Optional[typing.Sequence[str]]\n    Speaker IDs to be used for PVC training. Make sure you send all the speaker IDs you want to use for PVC training in one request because the last request will override the previous ones.\n\ntrim_start_time : typing.Optional[int]\n    The start time of the audio to be used for PVC training. Time should be in milliseconds\n\ntrim_end_time : typing.Optional[int]\n    The end time of the audio to be used for PVC training. Time should be in milliseconds\n\nfile_name : typing.Optional[str]\n    The name of the audio file to be used for PVC training.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.samples.update(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/client.py",
        "source_line": 293
      },
      {
        "path": "async_client.voices.pvc.samples.waveform.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceSampleVisualWaveformResponseModel",
        "docstring": "Retrieve the visual waveform of a voice sample.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceSampleVisualWaveformResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.samples.waveform.get(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        sample_id=\"VW7YKqPnjY4h39yTbx2L\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/waveform/client.py",
        "source_line": 79
      },
      {
        "path": "async_client.voices.pvc.samples.waveform.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieve the visual waveform of a voice sample.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[VoiceSampleVisualWaveformResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/waveform/raw_client.py",
        "source_line": 79
      },
      {
        "path": "async_client.voices.pvc.samples.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "files",
            "type": "List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Add audio samples to a PVC voice\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.List[VoiceSample]]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/raw_client.py",
        "source_line": 242
      },
      {
        "path": "async_client.voices.pvc.samples.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete a sample from a PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteVoiceSampleResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/raw_client.py",
        "source_line": 399
      },
      {
        "path": "async_client.voices.pvc.samples.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "selected_speaker_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "trim_start_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "trim_end_time",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "file_name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update a PVC voice sample - apply noise removal, select speaker, change trim times or file name.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nsample_id : str\n    Sample ID to be used\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\nselected_speaker_ids : typing.Optional[typing.Sequence[str]]\n    Speaker IDs to be used for PVC training. Make sure you send all the speaker IDs you want to use for PVC training in one request because the last request will override the previous ones.\n\ntrim_start_time : typing.Optional[int]\n    The start time of the audio to be used for PVC training. Time should be in milliseconds\n\ntrim_end_time : typing.Optional[int]\n    The end time of the audio to be used for PVC training. Time should be in milliseconds\n\nfile_name : typing.Optional[str]\n    The name of the audio file to be used for PVC training.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddVoiceResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/samples/raw_client.py",
        "source_line": 311
      },
      {
        "path": "async_client.voices.pvc.train",
        "name": "train",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "StartPvcVoiceTrainingResponseModel",
        "docstring": "Start PVC training process for a voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nmodel_id : typing.Optional[str]\n    The model ID to use for the conversion.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nStartPvcVoiceTrainingResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.train(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/client.py",
        "source_line": 349
      },
      {
        "path": "async_client.voices.pvc.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceResponseModel",
        "docstring": "Edit PVC voice metadata\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nname : typing.Optional[str]\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nlanguage : typing.Optional[str]\n    Language used in the samples.\n\ndescription : typing.Optional[str]\n    Description to use for the created voice.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.update(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/client.py",
        "source_line": 282
      },
      {
        "path": "async_client.voices.pvc.verification.captcha.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Get captcha for PVC voice verification.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nNone\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.verification.captcha.get(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/captcha/client.py",
        "source_line": 112
      },
      {
        "path": "async_client.voices.pvc.verification.captcha.verify",
        "name": "verify",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "recording",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VerifyPvcVoiceCaptchaResponseModel",
        "docstring": "Submit captcha verification for PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrecording : core.File\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVerifyPvcVoiceCaptchaResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.verification.captcha.verify(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/captcha/client.py",
        "source_line": 150
      },
      {
        "path": "async_client.voices.pvc.verification.captcha.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Get captcha for PVC voice verification.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[None]",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/captcha/raw_client.py",
        "source_line": 129
      },
      {
        "path": "async_client.voices.pvc.verification.captcha.with_raw_response.verify",
        "name": "verify",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "recording",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Submit captcha verification for PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrecording : core.File\n    See core.File for more documentation\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[VerifyPvcVoiceCaptchaResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/captcha/raw_client.py",
        "source_line": 171
      },
      {
        "path": "async_client.voices.pvc.verification.request",
        "name": "request",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "files",
            "type": "List[core.File]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "RequestPvcManualVerificationResponseModel",
        "docstring": "Request manual verification for a PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nextra_text : typing.Optional[str]\n    Extra text to be used in the manual verification process.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nRequestPvcManualVerificationResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.pvc.verification.request(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/client.py",
        "source_line": 108
      },
      {
        "path": "async_client.voices.pvc.verification.with_raw_response.request",
        "name": "request",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "files",
            "type": "List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "extra_text",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Request manual verification for a PVC voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nfiles : typing.List[core.File]\n    See core.File for more documentation\n\nextra_text : typing.Optional[str]\n    Extra text to be used in the manual verification process.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[RequestPvcManualVerificationResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/verification/raw_client.py",
        "source_line": 99
      },
      {
        "path": "async_client.voices.pvc.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Creates a new PVC voice with metadata but no samples\n\nParameters\n----------\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nlanguage : str\n    Language used in the samples.\n\ndescription : typing.Optional[str]\n    Description to use for the created voice.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddVoiceResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/raw_client.py",
        "source_line": 248
      },
      {
        "path": "async_client.voices.pvc.with_raw_response.train",
        "name": "train",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "model_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Start PVC training process for a voice.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nmodel_id : typing.Optional[str]\n    The model ID to use for the conversion.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[StartPvcVoiceTrainingResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/raw_client.py",
        "source_line": 402
      },
      {
        "path": "async_client.voices.pvc.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[Dict[str, Optional[str]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Edit PVC voice metadata\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nname : typing.Optional[str]\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nlanguage : typing.Optional[str]\n    Language used in the samples.\n\ndescription : typing.Optional[str]\n    Description to use for the created voice.\n\nlabels : typing.Optional[typing.Dict[str, typing.Optional[str]]]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddVoiceResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/pvc/raw_client.py",
        "source_line": 323
      },
      {
        "path": "async_client.voices.samples.audio.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Returns the audio corresponding to a sample attached to a voice.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nsample_id : str\n    ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[bytes]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.samples.audio.get(\n        voice_id=\"voice_id\",\n        sample_id=\"sample_id\",\n    )\n\n\nasyncio.run(main())",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/samples/audio/client.py",
        "source_line": 78
      },
      {
        "path": "async_client.voices.samples.audio.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sample_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncIterator",
        "docstring": "Returns the audio corresponding to a sample attached to a voice.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nsample_id : str\n    ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.\n\nReturns\n-------\ntyping.AsyncIterator[AsyncHttpResponse[typing.AsyncIterator[bytes]]]\n    Successful Response",
        "is_async": false,
        "source_file": "/home/mbp/.local/share/uv/python/cpython-3.13.1-linux-x86_64-gnu/lib/python3.13/contextlib.py",
        "source_line": 83
      },
      {
        "path": "async_client.voices.search",
        "name": "search",
        "parameters": [
          {
            "name": "next_page_token",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_type",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "category",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "fine_tuning_state",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "collection_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_total_count",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_ids",
            "type": "Optional[Union[str, Sequence[str]]]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "GetVoicesV2Response",
        "docstring": "Gets a list of all available voices for a user with search, filtering and pagination.\n\nParameters\n----------\nnext_page_token : typing.Optional[str]\n    The next page token to use for pagination. Returned from the previous request. Use this in combination with the has_more flag for reliable pagination.\n\npage_size : typing.Optional[int]\n    How many voices to return at maximum. Can not exceed 100, defaults to 10. Page 0 may include more voices due to default voices being included.\n\nsearch : typing.Optional[str]\n    Search term to filter voices by. Searches in name, description, labels, category.\n\nsort : typing.Optional[str]\n    Which field to sort by, one of 'created_at_unix' or 'name'. 'created_at_unix' may not be available for older voices.\n\nsort_direction : typing.Optional[str]\n    Which direction to sort the voices in. 'asc' or 'desc'.\n\nvoice_type : typing.Optional[str]\n    Type of the voice to filter by. One of 'personal', 'community', 'default', 'workspace', 'non-default'. 'non-default' is equal to all but 'default'.\n\ncategory : typing.Optional[str]\n    Category of the voice to filter by. One of 'premade', 'cloned', 'generated', 'professional'\n\nfine_tuning_state : typing.Optional[str]\n    State of the voice's fine tuning to filter by. Applicable only to professional voices clones. One of 'draft', 'not_verified', 'not_started', 'queued', 'fine_tuning', 'fine_tuned', 'failed', 'delayed'\n\ncollection_id : typing.Optional[str]\n    Collection ID to filter voices by.\n\ninclude_total_count : typing.Optional[bool]\n    Whether to include the total count of voices found in the response. NOTE: The total_count value is a live snapshot and may change between requests as users create, modify, or delete voices. For pagination, rely on the has_more flag instead. Only enable this when you actually need the total count (e.g., for display purposes), as it incurs a performance cost.\n\nvoice_ids : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Voice IDs to lookup by. Maximum 100 voice IDs.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nGetVoicesV2Response\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.search(\n        next_page_token=\"next_page_token\",\n        page_size=1,\n        search=\"search\",\n        sort=\"sort\",\n        sort_direction=\"sort_direction\",\n        voice_type=\"voice_type\",\n        category=\"category\",\n        fine_tuning_state=\"fine_tuning_state\",\n        collection_id=\"collection_id\",\n        include_total_count=True,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 644
      },
      {
        "path": "async_client.voices.settings.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceSettings",
        "docstring": "Returns the settings for a specific voice. \"similarity_boost\" corresponds to\"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceSettings\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.settings.get(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/client.py",
        "source_line": 179
      },
      {
        "path": "async_client.voices.settings.get_default",
        "name": "get_default",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "VoiceSettings",
        "docstring": "Gets the default settings for voices. \"similarity_boost\" corresponds to\"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nVoiceSettings\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.settings.get_default()\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/client.py",
        "source_line": 145
      },
      {
        "path": "async_client.voices.settings.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request",
            "type": "VoiceSettings",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditVoiceSettingsResponseModel",
        "docstring": "Edit your settings for a specific voice. \"similarity_boost\" corresponds to \"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nrequest : VoiceSettings\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditVoiceSettingsResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, VoiceSettings\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.settings.update(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        request=VoiceSettings(\n            stability=1.0,\n            use_speaker_boost=True,\n            similarity_boost=1.0,\n            style=0.0,\n            speed=1.0,\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/client.py",
        "source_line": 218
      },
      {
        "path": "async_client.voices.settings.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns the settings for a specific voice. \"similarity_boost\" corresponds to\"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nvoice_id : str\n    Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[VoiceSettings]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/raw_client.py",
        "source_line": 208
      },
      {
        "path": "async_client.voices.settings.with_raw_response.get_default",
        "name": "get_default",
        "parameters": [
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets the default settings for voices. \"similarity_boost\" corresponds to\"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[VoiceSettings]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/raw_client.py",
        "source_line": 172
      },
      {
        "path": "async_client.voices.settings.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request",
            "type": "VoiceSettings",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Edit your settings for a specific voice. \"similarity_boost\" corresponds to \"Clarity + Similarity Enhancement\" in the web app and \"stability\" corresponds to \"Stability\" slider in the web app.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nrequest : VoiceSettings\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[EditVoiceSettingsResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/settings/raw_client.py",
        "source_line": 258
      },
      {
        "path": "async_client.voices.share",
        "name": "share",
        "parameters": [
          {
            "name": "public_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "new_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddVoiceResponseModel",
        "docstring": "Add a shared voice to your collection of Voices\n\nParameters\n----------\npublic_user_id : str\n    Public user ID used to publicly identify ElevenLabs users.\n\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nnew_name : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.share(\n        public_user_id=\"63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca\",\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        new_name=\"John Smith\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 913
      },
      {
        "path": "async_client.voices.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "files",
            "type": "Optional[List[core.File]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "EditVoiceResponseModel",
        "docstring": "Edit a voice created by you.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nfiles : typing.Optional[typing.List[core.File]]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\ndescription : typing.Optional[str]\n    A description of the voice.\n\nlabels : typing.Optional[str]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nEditVoiceResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.voices.update(\n        voice_id=\"21m00Tcm4TlvDq8ikWAM\",\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/client.py",
        "source_line": 840
      },
      {
        "path": "async_client.voices.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Deletes a voice by its ID.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteVoiceResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 887
      },
      {
        "path": "async_client.voices.with_raw_response.find_similar_voices",
        "name": "find_similar_voices",
        "parameters": [
          {
            "name": "audio_file",
            "type": "Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping], NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "similarity_threshold",
            "type": "Optional[float]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "top_k",
            "type": "Optional[int]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns a list of shared voices similar to the provided audio sample. If neither similarity_threshold nor top_k is provided, we will apply default values.\n\nParameters\n----------\naudio_file : typing.Optional[core.File]\n    See core.File for more documentation\n\nsimilarity_threshold : typing.Optional[float]\n    Threshold for voice similarity between provided sample and library voices. Values range from 0 to 2. The smaller the value the more similar voices will be returned.\n\ntop_k : typing.Optional[int]\n    Number of most similar voices to return. If similarity_threshold is provided, less than this number of voices may be returned. Values range from 1 to 100.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetLibraryVoicesResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 1229
      },
      {
        "path": "async_client.voices.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "with_settings",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns metadata about a specific voice.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nwith_settings : typing.Optional[bool]\n    This parameter is now deprecated. It is ignored and will be removed in a future version.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[Voice]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 827
      },
      {
        "path": "async_client.voices.with_raw_response.get_all",
        "name": "get_all",
        "parameters": [
          {
            "name": "show_legacy",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Returns a list of all available voices for a user.\n\nParameters\n----------\nshow_legacy : typing.Optional[bool]\n    If set to true, legacy premade voices will be included in responses from /v1/voices\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetVoicesResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 668
      },
      {
        "path": "async_client.voices.with_raw_response.get_shared",
        "name": "get_shared",
        "parameters": [
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "category",
            "type": "Union[Literal, Any, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "gender",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "age",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "accent",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "language",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "locale",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "use_cases",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "descriptives",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "featured",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "min_notice_period_days",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_custom_rates",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_live_moderated",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "reader_app_enabled",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "owner_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Retrieves a list of shared voices.\n\nParameters\n----------\npage_size : typing.Optional[int]\n    How many shared voices to return at maximum. Can not exceed 100, defaults to 30.\n\ncategory : typing.Optional[VoicesGetSharedRequestCategory]\n    Voice category used for filtering\n\ngender : typing.Optional[str]\n    Gender used for filtering\n\nage : typing.Optional[str]\n    Age used for filtering\n\naccent : typing.Optional[str]\n    Accent used for filtering\n\nlanguage : typing.Optional[str]\n    Language used for filtering\n\nlocale : typing.Optional[str]\n    Locale used for filtering\n\nsearch : typing.Optional[str]\n    Search term used for filtering\n\nuse_cases : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Use-case used for filtering\n\ndescriptives : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Search term used for filtering\n\nfeatured : typing.Optional[bool]\n    Filter featured voices\n\nmin_notice_period_days : typing.Optional[int]\n    Filter voices with a minimum notice period of the given number of days.\n\ninclude_custom_rates : typing.Optional[bool]\n    Include/exclude voices with custom rates\n\ninclude_live_moderated : typing.Optional[bool]\n    Include/exclude voices that are live moderated\n\nreader_app_enabled : typing.Optional[bool]\n    Filter voices that are enabled for the reader app\n\nowner_id : typing.Optional[str]\n    Filter voices by public owner ID\n\nsort : typing.Optional[str]\n    Sort criteria\n\npage : typing.Optional[int]\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetLibraryVoicesResponse]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 1089
      },
      {
        "path": "async_client.voices.with_raw_response.search",
        "name": "search",
        "parameters": [
          {
            "name": "next_page_token",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "page_size",
            "type": "Optional[int]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "search",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "sort_direction",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_type",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "category",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "fine_tuning_state",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "collection_id",
            "type": "Optional[str]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "include_total_count",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "voice_ids",
            "type": "Union[str, Sequence, NoneType]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets a list of all available voices for a user with search, filtering and pagination.\n\nParameters\n----------\nnext_page_token : typing.Optional[str]\n    The next page token to use for pagination. Returned from the previous request. Use this in combination with the has_more flag for reliable pagination.\n\npage_size : typing.Optional[int]\n    How many voices to return at maximum. Can not exceed 100, defaults to 10. Page 0 may include more voices due to default voices being included.\n\nsearch : typing.Optional[str]\n    Search term to filter voices by. Searches in name, description, labels, category.\n\nsort : typing.Optional[str]\n    Which field to sort by, one of 'created_at_unix' or 'name'. 'created_at_unix' may not be available for older voices.\n\nsort_direction : typing.Optional[str]\n    Which direction to sort the voices in. 'asc' or 'desc'.\n\nvoice_type : typing.Optional[str]\n    Type of the voice to filter by. One of 'personal', 'community', 'default', 'workspace', 'non-default'. 'non-default' is equal to all but 'default'.\n\ncategory : typing.Optional[str]\n    Category of the voice to filter by. One of 'premade', 'cloned', 'generated', 'professional'\n\nfine_tuning_state : typing.Optional[str]\n    State of the voice's fine tuning to filter by. Applicable only to professional voices clones. One of 'draft', 'not_verified', 'not_started', 'queued', 'fine_tuning', 'fine_tuned', 'failed', 'delayed'\n\ncollection_id : typing.Optional[str]\n    Collection ID to filter voices by.\n\ninclude_total_count : typing.Optional[bool]\n    Whether to include the total count of voices found in the response. NOTE: The total_count value is a live snapshot and may change between requests as users create, modify, or delete voices. For pagination, rely on the has_more flag instead. Only enable this when you actually need the total count (e.g., for display purposes), as it incurs a performance cost.\n\nvoice_ids : typing.Optional[typing.Union[str, typing.Sequence[str]]]\n    Voice IDs to lookup by. Maximum 100 voice IDs.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[GetVoicesV2Response]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 721
      },
      {
        "path": "async_client.voices.with_raw_response.share",
        "name": "share",
        "parameters": [
          {
            "name": "public_user_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "new_name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Add a shared voice to your collection of Voices\n\nParameters\n----------\npublic_user_id : str\n    Public user ID used to publicly identify ElevenLabs users.\n\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nnew_name : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddVoiceResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 1021
      },
      {
        "path": "async_client.voices.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "voice_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "files",
            "type": "Optional[List[Union[IO, bytes, str, Tuple[Optional[str], Union[IO, bytes, str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str]], Tuple[Optional[str], Union[IO, bytes, str], Optional[str], Mapping]]]]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "remove_background_noise",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "description",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "labels",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Edit a voice created by you.\n\nParameters\n----------\nvoice_id : str\n    ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/search) endpoint list all the available voices.\n\nname : str\n    The name that identifies this voice. This will be displayed in the dropdown of the website.\n\nfiles : typing.Optional[typing.List[core.File]]\n    See core.File for more documentation\n\nremove_background_noise : typing.Optional[bool]\n    If set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n\ndescription : typing.Optional[str]\n    A description of the voice.\n\nlabels : typing.Optional[str]\n    Serialized labels dictionary for the voice.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[EditVoiceResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/voices/raw_client.py",
        "source_line": 937
      },
      {
        "path": "async_client.webhooks.construct_event",
        "name": "construct_event",
        "parameters": [
          {
            "name": "rawBody",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "sig_header",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "secret",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          }
        ],
        "return_type": "Dict",
        "docstring": "Constructs a webhook event object from a payload and signature.\nVerifies the webhook signature to ensure the event came from ElevenLabs.\n\nArgs:\n    rawBody: The webhook request body. Must be the raw body, not a JSON object\n    sig_header: The signature header from the request\n    secret: Your webhook secret\n\nReturns:\n    The verified webhook event\n\nRaises:\n    BadRequestError: If the signature is invalid or missing",
        "is_async": false,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks_custom.py",
        "source_line": 81
      },
      {
        "path": "async_client.webhooks.create",
        "name": "create",
        "parameters": [
          {
            "name": "settings",
            "type": "WebhookHmacSettings",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceCreateWebhookResponseModel",
        "docstring": "Create a new webhook for the workspace with the specified authentication type.\n\nParameters\n----------\nsettings : WebhookHmacSettings\n    Webhook settings object containing auth_type and corresponding configuration\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceCreateWebhookResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs, WebhookHmacSettings\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.webhooks.create(\n        settings=WebhookHmacSettings(\n            name=\"name\",\n            webhook_url=\"webhook_url\",\n        ),\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/client.py",
        "source_line": 235
      },
      {
        "path": "async_client.webhooks.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "webhook_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteWorkspaceWebhookResponseModel",
        "docstring": "Delete the specified workspace webhook\n\nParameters\n----------\nwebhook_id : str\n    The unique ID for the webhook\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteWorkspaceWebhookResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.webhooks.delete(\n        webhook_id=\"G007vmtq9uWYl7SUW9zGS8GZZa1K\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/client.py",
        "source_line": 279
      },
      {
        "path": "async_client.webhooks.list",
        "name": "list",
        "parameters": [
          {
            "name": "include_usages",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "WorkspaceWebhookListResponseModel",
        "docstring": "List all webhooks for a workspace\n\nParameters\n----------\ninclude_usages : typing.Optional[bool]\n    Whether to include active usages of the webhook, only usable by admins\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nWorkspaceWebhookListResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.webhooks.list(\n        include_usages=False,\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/client.py",
        "source_line": 194
      },
      {
        "path": "async_client.webhooks.update",
        "name": "update",
        "parameters": [
          {
            "name": "webhook_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "is_disabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "PatchWorkspaceWebhookResponseModel",
        "docstring": "Update the specified workspace webhook\n\nParameters\n----------\nwebhook_id : str\n    The unique ID for the webhook\n\nis_disabled : bool\n    Whether to disable or enable the webhook\n\nname : str\n    The display name of the webhook (used for display purposes only).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nPatchWorkspaceWebhookResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.webhooks.update(\n        webhook_id=\"G007vmtq9uWYl7SUW9zGS8GZZa1K\",\n        is_disabled=True,\n        name=\"My Callback Webhook\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/client.py",
        "source_line": 320
      },
      {
        "path": "async_client.webhooks.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "settings",
            "type": "WebhookHmacSettings",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Create a new webhook for the workspace with the specified authentication type.\n\nParameters\n----------\nsettings : WebhookHmacSettings\n    Webhook settings object containing auth_type and corresponding configuration\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[WorkspaceCreateWebhookResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/raw_client.py",
        "source_line": 313
      },
      {
        "path": "async_client.webhooks.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "webhook_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Delete the specified workspace webhook\n\nParameters\n----------\nwebhook_id : str\n    The unique ID for the webhook\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteWorkspaceWebhookResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/raw_client.py",
        "source_line": 372
      },
      {
        "path": "async_client.webhooks.with_raw_response.list",
        "name": "list",
        "parameters": [
          {
            "name": "include_usages",
            "type": "Optional[bool]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "List all webhooks for a workspace\n\nParameters\n----------\ninclude_usages : typing.Optional[bool]\n    Whether to include active usages of the webhook, only usable by admins\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[WorkspaceWebhookListResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/raw_client.py",
        "source_line": 260
      },
      {
        "path": "async_client.webhooks.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "webhook_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "is_disabled",
            "type": "bool",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Update the specified workspace webhook\n\nParameters\n----------\nwebhook_id : str\n    The unique ID for the webhook\n\nis_disabled : bool\n    Whether to disable or enable the webhook\n\nname : str\n    The display name of the webhook (used for display purposes only).\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[PatchWorkspaceWebhookResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/webhooks/raw_client.py",
        "source_line": 422
      },
      {
        "path": "async_client.workspace.groups.members.add",
        "name": "add",
        "parameters": [
          {
            "name": "group_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddWorkspaceGroupMemberResponseModel",
        "docstring": "Adds a member of your workspace to the specified group. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\ngroup_id : str\n    The ID of the target group.\n\nemail : str\n    The email of the target workspace member.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddWorkspaceGroupMemberResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.groups.members.add(\n        group_id=\"group_id\",\n        email=\"email\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/members/client.py",
        "source_line": 165
      },
      {
        "path": "async_client.workspace.groups.members.remove",
        "name": "remove",
        "parameters": [
          {
            "name": "group_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteWorkspaceGroupMemberResponseModel",
        "docstring": "Removes a member from the specified group. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\ngroup_id : str\n    The ID of the target group.\n\nemail : str\n    The email of the target workspace member.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteWorkspaceGroupMemberResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.groups.members.remove(\n        group_id=\"group_id\",\n        email=\"email\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/members/client.py",
        "source_line": 120
      },
      {
        "path": "async_client.workspace.groups.members.with_raw_response.add",
        "name": "add",
        "parameters": [
          {
            "name": "group_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Adds a member of your workspace to the specified group. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\ngroup_id : str\n    The ID of the target group.\n\nemail : str\n    The email of the target workspace member.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddWorkspaceGroupMemberResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/members/raw_client.py",
        "source_line": 210
      },
      {
        "path": "async_client.workspace.groups.members.with_raw_response.remove",
        "name": "remove",
        "parameters": [
          {
            "name": "group_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Removes a member from the specified group. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\ngroup_id : str\n    The ID of the target group.\n\nemail : str\n    The email of the target workspace member.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteWorkspaceGroupMemberResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/members/raw_client.py",
        "source_line": 150
      },
      {
        "path": "async_client.workspace.groups.search",
        "name": "search",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "List[WorkspaceGroupByNameResponseModel]",
        "docstring": "Searches for user groups in the workspace. Multiple or no groups may be returned.\n\nParameters\n----------\nname : str\n    Name of the target group.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.List[WorkspaceGroupByNameResponseModel]\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.groups.search(\n        name=\"name\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/client.py",
        "source_line": 92
      },
      {
        "path": "async_client.workspace.groups.with_raw_response.search",
        "name": "search",
        "parameters": [
          {
            "name": "name",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Searches for user groups in the workspace. Multiple or no groups may be returned.\n\nParameters\n----------\nname : str\n    Name of the target group.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.List[WorkspaceGroupByNameResponseModel]]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/groups/raw_client.py",
        "source_line": 78
      },
      {
        "path": "async_client.workspace.invites.create",
        "name": "create",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_permission",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddWorkspaceInviteResponseModel",
        "docstring": "Sends an email invitation to join your workspace to the provided email. If the user doesn't have an account they will be prompted to create one. If the user accepts this invite they will be added as a user to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators. If the user is already in the workspace a 400 error will be returned.\n\nParameters\n----------\nemail : str\n    The email of the customer\n\ngroup_ids : typing.Optional[typing.Sequence[str]]\n    The group ids of the user\n\nworkspace_permission : typing.Optional[BodyInviteUserV1WorkspaceInvitesAddPostWorkspacePermission]\n    The workspace permission of the user\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddWorkspaceInviteResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.invites.create(\n        email=\"john.doe@testmail.com\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/client.py",
        "source_line": 168
      },
      {
        "path": "async_client.workspace.invites.create_batch",
        "name": "create_batch",
        "parameters": [
          {
            "name": "emails",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AddWorkspaceInviteResponseModel",
        "docstring": "Sends email invitations to join your workspace to the provided emails. Requires all email addresses to be part of a verified domain. If the users don't have an account they will be prompted to create one. If the users accept these invites they will be added as users to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemails : typing.Sequence[str]\n    The email of the customer\n\ngroup_ids : typing.Optional[typing.Sequence[str]]\n    The group ids of the user\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAddWorkspaceInviteResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.invites.create_batch(\n        emails=[\"emails\"],\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/client.py",
        "source_line": 222
      },
      {
        "path": "async_client.workspace.invites.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "DeleteWorkspaceInviteResponseModel",
        "docstring": "Invalidates an existing email invitation. The invitation will still show up in the inbox it has been delivered to, but activating it to join the workspace won't work. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemail : str\n    The email of the customer\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nDeleteWorkspaceInviteResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.invites.delete(\n        email=\"john.doe@testmail.com\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/client.py",
        "source_line": 272
      },
      {
        "path": "async_client.workspace.invites.with_raw_response.create",
        "name": "create",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_permission",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Sends an email invitation to join your workspace to the provided email. If the user doesn't have an account they will be prompted to create one. If the user accepts this invite they will be added as a user to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators. If the user is already in the workspace a 400 error will be returned.\n\nParameters\n----------\nemail : str\n    The email of the customer\n\ngroup_ids : typing.Optional[typing.Sequence[str]]\n    The group ids of the user\n\nworkspace_permission : typing.Optional[BodyInviteUserV1WorkspaceInvitesAddPostWorkspacePermission]\n    The workspace permission of the user\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddWorkspaceInviteResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/raw_client.py",
        "source_line": 224
      },
      {
        "path": "async_client.workspace.invites.with_raw_response.create_batch",
        "name": "create_batch",
        "parameters": [
          {
            "name": "emails",
            "type": "Sequence",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_ids",
            "type": "Optional[Sequence]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Sends email invitations to join your workspace to the provided emails. Requires all email addresses to be part of a verified domain. If the users don't have an account they will be prompted to create one. If the users accept these invites they will be added as users to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemails : typing.Sequence[str]\n    The email of the customer\n\ngroup_ids : typing.Optional[typing.Sequence[str]]\n    The group ids of the user\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[AddWorkspaceInviteResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/raw_client.py",
        "source_line": 294
      },
      {
        "path": "async_client.workspace.invites.with_raw_response.delete",
        "name": "delete",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Invalidates an existing email invitation. The invitation will still show up in the inbox it has been delivered to, but activating it to join the workspace won't work. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemail : str\n    The email of the customer\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[DeleteWorkspaceInviteResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/invites/raw_client.py",
        "source_line": 359
      },
      {
        "path": "async_client.workspace.members.update",
        "name": "update",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "is_locked",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_role",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "UpdateWorkspaceMemberResponseModel",
        "docstring": "Updates attributes of a workspace member. Apart from the email identifier, all parameters will remain unchanged unless specified. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemail : str\n    Email of the target user.\n\nis_locked : typing.Optional[bool]\n    Whether to lock or unlock the user account.\n\nworkspace_role : typing.Optional[BodyUpdateMemberV1WorkspaceMembersPostWorkspaceRole]\n    Role dictating permissions in the workspace.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nUpdateWorkspaceMemberResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.members.update(\n        email=\"email\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/members/client.py",
        "source_line": 94
      },
      {
        "path": "async_client.workspace.members.with_raw_response.update",
        "name": "update",
        "parameters": [
          {
            "name": "email",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "is_locked",
            "type": "Optional[bool]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_role",
            "type": "Union[Literal, Any, NoneType]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Updates attributes of a workspace member. Apart from the email identifier, all parameters will remain unchanged unless specified. This endpoint may only be called by workspace administrators.\n\nParameters\n----------\nemail : str\n    Email of the target user.\n\nis_locked : typing.Optional[bool]\n    Whether to lock or unlock the user account.\n\nworkspace_role : typing.Optional[BodyUpdateMemberV1WorkspaceMembersPostWorkspaceRole]\n    Role dictating permissions in the workspace.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[UpdateWorkspaceMemberResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/members/raw_client.py",
        "source_line": 101
      },
      {
        "path": "async_client.workspace.resources.get",
        "name": "get",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "ResourceMetadataResponseModel",
        "docstring": "Gets the metadata of a resource by ID.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nResourceMetadataResponseModel\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.resources.get(\n        resource_id=\"resource_id\",\n        resource_type=\"voice\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/client.py",
        "source_line": 216
      },
      {
        "path": "async_client.workspace.resources.share",
        "name": "share",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "role",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_email",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_api_key_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Grants a role on a workspace resource to a user or a group. It overrides any existing role this user/service account/group/workspace api key has on the resource. To target a user or service account, pass only the user email. The user must be in your workspace. To target a group, pass only the group id. To target a workspace api key, pass the api key id. The resource will be shared with the service account associated with the api key. You must have admin access to the resource to share it.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nrole : BodyShareWorkspaceResourceV1WorkspaceResourcesResourceIdSharePostRole\n    Role to update the target principal with.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nuser_email : typing.Optional[str]\n    The email of the user or service account.\n\ngroup_id : typing.Optional[str]\n    The ID of the target group. To target the permissions principals have by default on this resource, use the value 'default'.\n\nworkspace_api_key_id : typing.Optional[str]\n    The ID of the target workspace API key. This isn't the same as the key itself that would you pass in the header for authentication. Workspace admins can find this in the workspace settings UI.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.resources.share(\n        resource_id=\"resource_id\",\n        role=\"admin\",\n        resource_type=\"voice\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/client.py",
        "source_line": 267
      },
      {
        "path": "async_client.workspace.resources.unshare",
        "name": "unshare",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_email",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_api_key_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "Any",
        "docstring": "Removes any existing role on a workspace resource from a user, service account, group or workspace api key. To target a user or service account, pass only the user email. The user must be in your workspace. To target a group, pass only the group id. To target a workspace api key, pass the api key id. The resource will be unshared from the service account associated with the api key. You must have admin access to the resource to unshare it. You cannot remove permissions from the user who created the resource.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nuser_email : typing.Optional[str]\n    The email of the user or service account.\n\ngroup_id : typing.Optional[str]\n    The ID of the target group. To target the permissions principals have by default on this resource, use the value 'default'.\n\nworkspace_api_key_id : typing.Optional[str]\n    The ID of the target workspace API key. This isn't the same as the key itself that would you pass in the header for authentication. Workspace admins can find this in the workspace settings UI.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\ntyping.Any\n    Successful Response\n\nExamples\n--------\nimport asyncio\n\nfrom elevenlabs import AsyncElevenLabs\n\nclient = AsyncElevenLabs(\n    api_key=\"YOUR_API_KEY\",\n)\n\n\nasync def main() -> None:\n    await client.workspace.resources.unshare(\n        resource_id=\"resource_id\",\n        resource_type=\"voice\",\n    )\n\n\nasyncio.run(main())",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/client.py",
        "source_line": 341
      },
      {
        "path": "async_client.workspace.resources.with_raw_response.get",
        "name": "get",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Gets the metadata of a resource by ID.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[ResourceMetadataResponseModel]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/raw_client.py",
        "source_line": 260
      },
      {
        "path": "async_client.workspace.resources.with_raw_response.share",
        "name": "share",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "role",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_email",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_api_key_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Grants a role on a workspace resource to a user or a group. It overrides any existing role this user/service account/group/workspace api key has on the resource. To target a user or service account, pass only the user email. The user must be in your workspace. To target a group, pass only the group id. To target a workspace api key, pass the api key id. The resource will be shared with the service account associated with the api key. You must have admin access to the resource to share it.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nrole : BodyShareWorkspaceResourceV1WorkspaceResourcesResourceIdSharePostRole\n    Role to update the target principal with.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nuser_email : typing.Optional[str]\n    The email of the user or service account.\n\ngroup_id : typing.Optional[str]\n    The ID of the target group. To target the permissions principals have by default on this resource, use the value 'default'.\n\nworkspace_api_key_id : typing.Optional[str]\n    The ID of the target workspace API key. This isn't the same as the key itself that would you pass in the header for authentication. Workspace admins can find this in the workspace settings UI.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/raw_client.py",
        "source_line": 320
      },
      {
        "path": "async_client.workspace.resources.with_raw_response.unshare",
        "name": "unshare",
        "parameters": [
          {
            "name": "resource_id",
            "type": "str",
            "default": null,
            "required": true,
            "kind": "POSITIONAL_OR_KEYWORD"
          },
          {
            "name": "resource_type",
            "type": "Union[Literal, Any]",
            "default": null,
            "required": true,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "user_email",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "group_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "workspace_api_key_id",
            "type": "Optional[str]",
            "default": "Ellipsis",
            "required": false,
            "kind": "KEYWORD_ONLY"
          },
          {
            "name": "request_options",
            "type": "Optional[RequestOptions]",
            "default": null,
            "required": false,
            "kind": "KEYWORD_ONLY"
          }
        ],
        "return_type": "AsyncHttpResponse",
        "docstring": "Removes any existing role on a workspace resource from a user, service account, group or workspace api key. To target a user or service account, pass only the user email. The user must be in your workspace. To target a group, pass only the group id. To target a workspace api key, pass the api key id. The resource will be unshared from the service account associated with the api key. You must have admin access to the resource to unshare it. You cannot remove permissions from the user who created the resource.\n\nParameters\n----------\nresource_id : str\n    The ID of the target resource.\n\nresource_type : WorkspaceResourceType\n    Resource type of the target resource.\n\nuser_email : typing.Optional[str]\n    The email of the user or service account.\n\ngroup_id : typing.Optional[str]\n    The ID of the target group. To target the permissions principals have by default on this resource, use the value 'default'.\n\nworkspace_api_key_id : typing.Optional[str]\n    The ID of the target workspace API key. This isn't the same as the key itself that would you pass in the header for authentication. Workspace admins can find this in the workspace settings UI.\n\nrequest_options : typing.Optional[RequestOptions]\n    Request-specific configuration.\n\nReturns\n-------\nAsyncHttpResponse[typing.Any]\n    Successful Response",
        "is_async": true,
        "source_file": "/home/mbp/Dropbox/Projects/speech-cli/.venv/lib/python3.13/site-packages/elevenlabs/workspace/resources/raw_client.py",
        "source_line": 406
      }
    ]
  }
}